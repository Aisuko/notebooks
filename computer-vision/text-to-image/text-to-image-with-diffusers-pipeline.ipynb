{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30512,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aisuko/text-to-image-with-diffusers-pipeline?scriptVersionId=164200404\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Overview\n\nIn this notebook, we are going to use text to generate an image by using pipeline from diffusers.","metadata":{}},{"cell_type":"code","source":"# %%capture\n!pip install diffusers==0.26.3\n!pip install transformers==4.38.1","metadata":{"execution":{"iopub.status.busy":"2024-02-25T05:25:34.937527Z","iopub.execute_input":"2024-02-25T05:25:34.937996Z","iopub.status.idle":"2024-02-25T05:26:22.204843Z","shell.execute_reply.started":"2024-02-25T05:25:34.937959Z","shell.execute_reply":"2024-02-25T05:26:22.20368Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting diffusers==0.26.3\n  Downloading diffusers-0.26.3-py3-none-any.whl (1.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers==0.26.3) (5.2.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from diffusers==0.26.3) (3.12.0)\nCollecting huggingface-hub>=0.20.2 (from diffusers==0.26.3)\n  Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from diffusers==0.26.3) (1.23.5)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from diffusers==0.26.3) (2023.5.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from diffusers==0.26.3) (2.28.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from diffusers==0.26.3) (0.3.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from diffusers==0.26.3) (9.5.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers==0.26.3) (2023.6.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers==0.26.3) (4.64.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers==0.26.3) (5.4.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers==0.26.3) (4.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers==0.26.3) (21.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->diffusers==0.26.3) (3.15.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers==0.26.3) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers==0.26.3) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers==0.26.3) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers==0.26.3) (2023.5.7)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.2->diffusers==0.26.3) (3.0.9)\nInstalling collected packages: huggingface-hub, diffusers\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.15.1\n    Uninstalling huggingface-hub-0.15.1:\n      Successfully uninstalled huggingface-hub-0.15.1\nSuccessfully installed diffusers-0.26.3 huggingface-hub-0.20.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting transformers==4.38.1\n  Downloading transformers-4.38.1-py3-none-any.whl (8.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (3.12.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (5.4.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (2023.5.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (2.28.2)\nCollecting tokenizers<0.19,>=0.14 (from transformers==4.38.1)\n  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting safetensors>=0.4.1 (from transformers==4.38.1)\n  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (4.64.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.1) (2023.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.1) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.38.1) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.1) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.1) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.1) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.1) (2023.5.7)\nInstalling collected packages: safetensors, tokenizers, transformers\n  Attempting uninstall: safetensors\n    Found existing installation: safetensors 0.3.1\n    Uninstalling safetensors-0.3.1:\n      Successfully uninstalled safetensors-0.3.1\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.13.3\n    Uninstalling tokenizers-0.13.3:\n      Successfully uninstalled tokenizers-0.13.3\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.30.1\n    Uninstalling transformers-4.30.1:\n      Successfully uninstalled transformers-4.30.1\nSuccessfully installed safetensors-0.4.2 tokenizers-0.15.2 transformers-4.38.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting accelerate==0.27.2\n  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (5.4.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (2.0.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (0.20.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (0.4.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.27.2) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2) (3.1.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.27.2) (2023.6.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.27.2) (2.28.2)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.27.2) (4.64.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.27.2) (2.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.27.2) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.27.2) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.27.2) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.27.2) (1.3.0)\nInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.12.0\n    Uninstalling accelerate-0.12.0:\n      Successfully uninstalled accelerate-0.12.0\nSuccessfully installed accelerate-0.27.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport torch\n\nos.environ['MODEL_NAME']='CompVis/stable-diffusion-v1-4'\n\nif torch.cuda.is_available():\n    torch_device = 'cuda'\nelse:\n    torch_device = 'cpu'\n\nprint(torch_device)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T05:26:22.206955Z","iopub.execute_input":"2024-02-25T05:26:22.207307Z","iopub.status.idle":"2024-02-25T05:26:22.213379Z","shell.execute_reply.started":"2024-02-25T05:26:22.207275Z","shell.execute_reply":"2024-02-25T05:26:22.212483Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# !diffusers-cli env","metadata":{"execution":{"iopub.status.busy":"2024-02-25T05:26:22.214537Z","iopub.execute_input":"2024-02-25T05:26:22.214794Z","iopub.status.idle":"2024-02-25T05:26:22.224888Z","shell.execute_reply.started":"2024-02-25T05:26:22.214772Z","shell.execute_reply":"2024-02-25T05:26:22.224116Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Loading the Components\n\nLoad all these components with the `from_pretrained()` method.","metadata":{}},{"cell_type":"code","source":"from PIL import Image\n\nfrom diffusers import AutoencoderKL\n\nvae = AutoencoderKL.from_pretrained(os.getenv('MODEL_NAME'), subfolder=\"vae\")\nvae.to(torch_device)\nprint(vae)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T05:26:22.225991Z","iopub.execute_input":"2024-02-25T05:26:22.226334Z","iopub.status.idle":"2024-02-25T05:26:23.215961Z","shell.execute_reply.started":"2024-02-25T05:26:22.226303Z","shell.execute_reply":"2024-02-25T05:26:23.213335Z"},"trusted":true},"execution_count":4,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoencoderKL\n\u001b[1;32m      5\u001b[0m vae \u001b[38;5;241m=\u001b[39m AutoencoderKL\u001b[38;5;241m.\u001b[39mfrom_pretrained(os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMODEL_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m), subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvae\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m vae\u001b[38;5;241m.\u001b[39mto(torch_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/diffusers/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.26.3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m     DIFFUSERS_SLOW_IMPORT,\n\u001b[1;32m      7\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m      8\u001b[0m     _LazyModule,\n\u001b[1;32m      9\u001b[0m     is_flax_available,\n\u001b[1;32m     10\u001b[0m     is_k_diffusion_available,\n\u001b[1;32m     11\u001b[0m     is_librosa_available,\n\u001b[1;32m     12\u001b[0m     is_note_seq_available,\n\u001b[1;32m     13\u001b[0m     is_onnx_available,\n\u001b[1;32m     14\u001b[0m     is_scipy_available,\n\u001b[1;32m     15\u001b[0m     is_torch_available,\n\u001b[1;32m     16\u001b[0m     is_torchsde_available,\n\u001b[1;32m     17\u001b[0m     is_transformers_available,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Lazy Import based on\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# https://github.com/huggingface/transformers/blob/main/src/transformers/__init__.py\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# When adding a new object to this init, please add it to `_import_structure`. The `_import_structure` is a dictionary submodule to list of object names,\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# and is used to defer the actual importing for when the objects are requested.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# This way `import diffusers` provides the names in the namespace without actually importing anything (and especially none of the backends).\u001b[39;00m\n\u001b[1;32m     28\u001b[0m _import_structure \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfiguration_utils\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfigMixin\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     ],\n\u001b[1;32m     51\u001b[0m }\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/diffusers/utils/__init__.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     CONFIG_NAME,\n\u001b[1;32m     23\u001b[0m     DEPRECATED_REVISION_ARGS,\n\u001b[1;32m     24\u001b[0m     DIFFUSERS_DYNAMIC_MODULE_NAME,\n\u001b[1;32m     25\u001b[0m     FLAX_WEIGHTS_NAME,\n\u001b[1;32m     26\u001b[0m     HF_MODULES_CACHE,\n\u001b[1;32m     27\u001b[0m     HUGGINGFACE_CO_RESOLVE_ENDPOINT,\n\u001b[1;32m     28\u001b[0m     MIN_PEFT_VERSION,\n\u001b[1;32m     29\u001b[0m     ONNX_EXTERNAL_WEIGHTS_NAME,\n\u001b[1;32m     30\u001b[0m     ONNX_WEIGHTS_NAME,\n\u001b[1;32m     31\u001b[0m     SAFETENSORS_FILE_EXTENSION,\n\u001b[1;32m     32\u001b[0m     SAFETENSORS_WEIGHTS_NAME,\n\u001b[1;32m     33\u001b[0m     USE_PEFT_BACKEND,\n\u001b[1;32m     34\u001b[0m     WEIGHTS_NAME,\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecate\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m replace_example_docstring\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/diffusers/utils/constants.py:17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HF_HOME\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_check\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dep_version_check\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'HF_HOME' from 'huggingface_hub.constants' (/opt/conda/lib/python3.10/site-packages/huggingface_hub/constants.py)"],"ename":"ImportError","evalue":"cannot import name 'HF_HOME' from 'huggingface_hub.constants' (/opt/conda/lib/python3.10/site-packages/huggingface_hub/constants.py)","output_type":"error"}]},{"cell_type":"code","source":"from transformers import CLIPTokenizer\n\ntokenizer = CLIPTokenizer.from_pretrained(os.getenv('MODEL_NAME'), subfolder=\"tokenizer\")\nprint(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T05:26:23.216766Z","iopub.status.idle":"2024-02-25T05:26:23.21709Z","shell.execute_reply.started":"2024-02-25T05:26:23.216929Z","shell.execute_reply":"2024-02-25T05:26:23.216944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import CLIPTextModel\n\ntext_encoder = CLIPTextModel.from_pretrained(os.getenv('MODEL_NAME'), subfolder = \"text_encoder\")\ntext_encoder.to(torch_device)\nprint(text_encoder)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T05:26:23.21886Z","iopub.status.idle":"2024-02-25T05:26:23.219222Z","shell.execute_reply.started":"2024-02-25T05:26:23.219032Z","shell.execute_reply":"2024-02-25T05:26:23.219048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from diffusers import UNet2DConditionModel\n\nunet = UNet2DConditionModel.from_pretrained(os.getenv('MODEL_NAME'), subfolder = \"unet\")\nunet.to(torch_device)\nprint(unet)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T05:26:23.220441Z","iopub.status.idle":"2024-02-25T05:26:23.220751Z","shell.execute_reply.started":"2024-02-25T05:26:23.220598Z","shell.execute_reply":"2024-02-25T05:26:23.220613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exchange to UniPCMultistepScheduler\n\nIt is easy to change to other schedulers","metadata":{}},{"cell_type":"code","source":"from diffusers import UniPCMultistepScheduler\n\nscheduler = UniPCMultistepScheduler.from_pretrained(os.getenv('MODEL_NAME'), subfolder=\"scheduler\")\nprint(scheduler)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T05:26:23.221695Z","iopub.status.idle":"2024-02-25T05:26:23.222008Z","shell.execute_reply.started":"2024-02-25T05:26:23.221851Z","shell.execute_reply":"2024-02-25T05:26:23.221867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create text embeddings\n\n**Tokenizing** the text to generate embeddings. The text is used to condition the UNet model and steer the diffusion process towards something that resembles the input prompt.","metadata":{}},{"cell_type":"code","source":"prompt =[\"a photograph of an astronaut riding a horse\"]\n# default weight of Stable Diffusion\nheight = 512\nwidth = 512\n# Number of denoising steps\nnum_inference_steps = 5\n# Scale for classifier-free guidance\nguidance_scale = 7.5\n# Seed generator to create the initial latent noise\nseed = torch.manual_seed(0)\nbatch_size=len(prompt)\n\ntext_input = tokenizer(\n    prompt, \n    padding=\"max_length\", \n    max_length=tokenizer.model_max_length, \n    truncation=True,\n    return_tensors=\"pt\"\n)\n\nprint(text_input)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T05:26:23.223696Z","iopub.status.idle":"2024-02-25T05:26:23.223999Z","shell.execute_reply.started":"2024-02-25T05:26:23.223849Z","shell.execute_reply":"2024-02-25T05:26:23.223863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    text_embeddings = text_encoder(text_input.input_ids.to(torch_device))[0]\n    \nprint(text_embeddings)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T05:26:23.225257Z","iopub.status.idle":"2024-02-25T05:26:23.225571Z","shell.execute_reply.started":"2024-02-25T05:26:23.225416Z","shell.execute_reply":"2024-02-25T05:26:23.22543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generate the Unconditional Text Embeddings\n\nGenerate the unconditional text embeddings for the padding token. These need to have the same shape(batch-size and seq_length) as the conditional text_embeddings:","metadata":{}},{"cell_type":"code","source":"max_length=text_input.input_ids.shape[-1]\nuncond_input =tokenizer([\"\"] * batch_size, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\")\nuncond_embeddings = text_encoder(uncond_input.input_ids.to(torch_device))[0]\nprint(uncond_embeddings)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T05:26:23.227653Z","iopub.status.idle":"2024-02-25T05:26:23.22798Z","shell.execute_reply.started":"2024-02-25T05:26:23.227818Z","shell.execute_reply":"2024-02-25T05:26:23.227834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Concatenation embeddings\n\nConcatenate the condifitional and unconditional embeddings into a batch to avoid doing two forward passes","metadata":{}},{"cell_type":"code","source":"text_embeddings = torch.cat([uncond_embeddings, text_embeddings])\nprint(text_embeddings)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T05:26:23.228969Z","iopub.status.idle":"2024-02-25T05:26:23.229312Z","shell.execute_reply.started":"2024-02-25T05:26:23.229146Z","shell.execute_reply":"2024-02-25T05:26:23.229165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create random noise\n\n**Generating some initial random noise as a starting point for the diffusion process.** This is the latent representation of the image, and it'll be gradually denoised. At this point, the latent image is snaller than the final image size but that's okay though because the model will transform it into the final 512x512 image dimensions later.","metadata":{}},{"cell_type":"code","source":"latents= torch.randn(\n    batch_size,\n    unet.in_channels,\n    height // 8,\n    width // 8,\n    generator=seed,\n)\n\nlatents =latents.to(torch_device)\nprint(latents)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T05:26:23.230896Z","iopub.status.idle":"2024-02-25T05:26:23.23127Z","shell.execute_reply.started":"2024-02-25T05:26:23.231071Z","shell.execute_reply":"2024-02-25T05:26:23.231098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Denoise the image\n\nStart by scaling the input with the inital noise distribution ***sigma*** the noise scale value, which is required for improved schedulers like UniPCMultistepScheduler:","metadata":{}},{"cell_type":"code","source":"latents = latents * scheduler.init_noise_sigma\nprint(latents)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T05:26:23.232199Z","iopub.status.idle":"2024-02-25T05:26:23.232513Z","shell.execute_reply.started":"2024-02-25T05:26:23.232354Z","shell.execute_reply":"2024-02-25T05:26:23.232369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The last step is to create the ***denoising loop*** that'll progressively transform the pure noise in latents to an image described by the prompt.\n\nThe denoising loop:\n* Setting the scheduler's timesteps to use during denoising\n* Iterating over the timesteps\n* At each timestep, call the UNet model to predict the noise residual and pass it to the scheduler to compute the previous noisy sample","metadata":{}},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\nscheduler.set_timesteps(num_inference_steps)\n\nfor t in tqdm(scheduler.timesteps):\n    latent_model_input=torch.cat([latents]*2)\n    latent_model_input=scheduler.scale_model_input(latent_model_input, timesteps=t)\n\n    # predict the noise residual\n    with torch.no_grad():\n        noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample\n    \n    # perform guidance\n    noise_pred_uncond, noise_pred_text =noise_pred.chunk(2)\n    noise_pred= noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n\n    # compute the previous noisy sample x_t-> x_t-1\n    latents=scheduler.step(noise_pred, t, latents).prev_sample","metadata":{"execution":{"iopub.status.busy":"2024-02-25T05:26:23.234372Z","iopub.status.idle":"2024-02-25T05:26:23.234684Z","shell.execute_reply.started":"2024-02-25T05:26:23.234529Z","shell.execute_reply":"2024-02-25T05:26:23.234543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decode the image\n\nThe final step is to use the vae to decode the latent representation into an image and get the decoded output with sample:","metadata":{}},{"cell_type":"code","source":"# scale and decode the image latents with vae\n\nlatents = 1/0.18215* latents\nwith torch.no_grad():\n    image =vae.decode(latents).sample\n    \nimage = (image /2+0.5).clamp(0, 1)\nimage = image.detach().cpu().permute(0,2,3,1).numpy()\nimages= (image*255).round().astype(\"uint8\")\npil_images = [Image.fromarray(image) for image in images]\npil_images[0]","metadata":{"execution":{"iopub.status.busy":"2024-02-25T05:26:23.236333Z","iopub.status.idle":"2024-02-25T05:26:23.23667Z","shell.execute_reply.started":"2024-02-25T05:26:23.236501Z","shell.execute_reply":"2024-02-25T05:26:23.236516Z"},"trusted":true},"execution_count":null,"outputs":[]}]}