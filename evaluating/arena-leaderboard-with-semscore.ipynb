{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview\n\nWe are going to implement a Arena leaderboard with SemScore.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"%%capture\n!pip install transformers==4.38.2\n!pip install accelerate==0.27.2\n!pip install datasets==2.18.0\n!pip install peft==0.9.0\n!pip install bitsandbytes==0.42.0\n!pip install sentence-transformers==2.5.1","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:09:30.854615Z","iopub.execute_input":"2024-03-17T11:09:30.854948Z","iopub.status.idle":"2024-03-17T11:11:12.965324Z","shell.execute_reply.started":"2024-03-17T11:09:30.854918Z","shell.execute_reply":"2024-03-17T11:11:12.964205Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nlogin(token=user_secrets.get_secret(\"HUGGINGFACE_TOKEN\"))\n\nos.environ[\"MODEL_NAME\"] = \"\"\nos.environ[\"DATASET\"]=\"lmsys/chatbot_arena_conversations\"","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:11:12.967627Z","iopub.execute_input":"2024-03-17T11:11:12.967920Z","iopub.status.idle":"2024-03-17T11:11:17.220863Z","shell.execute_reply.started":"2024-03-17T11:11:12.967892Z","shell.execute_reply":"2024-03-17T11:11:17.220001Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Loading the Dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset=load_dataset(os.getenv(\"DATASET\"), split=\"train\")\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:11:17.222170Z","iopub.execute_input":"2024-03-17T11:11:17.222826Z","iopub.status.idle":"2024-03-17T11:11:27.908381Z","shell.execute_reply.started":"2024-03-17T11:11:17.222791Z","shell.execute_reply":"2024-03-17T11:11:27.907427Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/7.00k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ded70c6074b94aa4803c4ba33fbde7a2"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 41.6M/41.6M [00:05<00:00, 7.05MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/33000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbeae86a21b94159a662455e7b83ea10"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['question_id', 'model_a', 'model_b', 'winner', 'judge', 'conversation_a', 'conversation_b', 'turn', 'anony', 'language', 'tstamp', 'openai_moderation', 'toxic_chat_tag'],\n    num_rows: 33000\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Conversations per Model","metadata":{}},{"cell_type":"code","source":"model_conv_count={}\nfor d in dataset:\n    for k in [\"model_a\",\"model_b\"]:\n        model=d[k]\n        if not model in model_conv_count:\n            model_conv_count[model]=1\n        else:\n            model_conv_count[model]+=1\nmodel_conv_count","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:11:27.909940Z","iopub.execute_input":"2024-03-17T11:11:27.910420Z","iopub.status.idle":"2024-03-17T11:11:37.891935Z","shell.execute_reply.started":"2024-03-17T11:11:27.910393Z","shell.execute_reply":"2024-03-17T11:11:37.891063Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'chatglm-6b': 3322,\n 'koala-13b': 5573,\n 'oasst-pythia-12b': 4890,\n 'alpaca-13b': 4453,\n 'vicuna-13b': 5931,\n 'dolly-v2-12b': 2786,\n 'stablelm-tuned-alpha-7b': 2795,\n 'llama-13b': 2009,\n 'fastchat-t5-3b': 3210,\n 'gpt-3.5-turbo': 4654,\n 'gpt-4': 4217,\n 'RWKV-4-Raven-14B': 3682,\n 'claude-v1': 3927,\n 'mpt-7b-chat': 2854,\n 'palm-2': 2955,\n 'claude-instant-v1': 2626,\n 'vicuna-7b': 2869,\n 'wizardlm-13b': 1116,\n 'gpt4all-13b-snoozy': 1097,\n 'guanaco-33b': 1034}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Extracting Conversations that GPT4 Gave One of the Two Answers","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n\nreference_model=\"gpt-4\"\nanswers={}\n\nfor judgement in tqdm(dataset):\n    models_involved=judgement[\"model_a\"]+judgement[\"model_b\"]\n    if not reference_model in models_involved:\n        continue\n    # get answers for GPT-4 and other model\n    reference_label, other_label=(\"a\",\"b\")  if judgement[\"model_a\"]==reference_model else(\"b\", \"a\")\n    answers_ref=[msg[\"content\"] for msg in judgement[f\"conversation_{reference_label}\"] if msg[\"role\"]==\"assistant\"]\n    answers_other=[msg[\"content\"] for msg in judgement[f\"conversation_{other_label}\"] if msg[\"role\"]==\"assistant\"]\n    \n    # store answers in answes dict\n    other_model=judgement[f\"model_{other_label}\"]\n    if not other_model in answers:\n        answers[other_model]=dict(answers_model=[], answers_ref=[])\n    answers[other_model][\"answers_model\"].extend(answers_other)\n    answers[other_model][\"answers_ref\"].extend(answers_ref)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:11:37.894649Z","iopub.execute_input":"2024-03-17T11:11:37.895267Z","iopub.status.idle":"2024-03-17T11:11:48.176412Z","shell.execute_reply.started":"2024-03-17T11:11:37.895233Z","shell.execute_reply":"2024-03-17T11:11:48.175536Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"100%|██████████| 33000/33000 [00:10<00:00, 3213.21it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\ndata={\"Model\": answers.keys(), 'num_answers':[len(answers[m][\"answers_model\"]) for m in answers]}\n\ndf=pd.DataFrame(data)\ndf=df.sort_values(by=[\"num_answers\"], ascending=False)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:11:48.177730Z","iopub.execute_input":"2024-03-17T11:11:48.178047Z","iopub.status.idle":"2024-03-17T11:11:48.204060Z","shell.execute_reply.started":"2024-03-17T11:11:48.178022Z","shell.execute_reply":"2024-03-17T11:11:48.203119Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"               Model  num_answers\n0         vicuna-13b          448\n3      gpt-3.5-turbo          436\n2          koala-13b          417\n1   oasst-pythia-12b          395\n10         claude-v1          366","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>num_answers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>vicuna-13b</td>\n      <td>448</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>gpt-3.5-turbo</td>\n      <td>436</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>koala-13b</td>\n      <td>417</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>oasst-pythia-12b</td>\n      <td>395</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>claude-v1</td>\n      <td>366</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\n\nmodel=SentenceTransformer('all-MiniLM-L6-v2', device='cuda')\nmodel.max_seq_length=200\nmodel.device","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:13:16.717916Z","iopub.execute_input":"2024-03-17T11:13:16.718334Z","iopub.status.idle":"2024-03-17T11:13:24.819987Z","shell.execute_reply.started":"2024-03-17T11:13:16.718302Z","shell.execute_reply":"2024-03-17T11:13:24.818993Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48eadad3a94b4a02a40e1518a4d6b4a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08bef4217abc47d18b8b90c7130fd62b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bddfad03c7e046dd8138ebca28df4590"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"161b6e39531040ffa51572cab2a25e95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aba292e7b2574b10ae13bbca691756bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4822808f18354d14a8f8571943886ca6"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc492bd443f34b71a15f4ec9c2a42c11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7ef298d48a14de0b39ad11330db5ecb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87c15f3e8c8b4d7994b030f4c13aa93a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30828d83ea1c4fa599fbadc514af178c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b330933b2b584283a23db2dfabcd4eaf"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom sentence_transformers import util\nfrom sentence_transformers.util import normalize_embeddings\n\n\ndef get_embeddings(sentences):\n    corpus_embeddings=model.encode(sentences, convert_to_tensor=True)\n#     corpus_embeddings=normalize_embeddings(corpus_embeddings)\n    return corpus_embeddings\n\n\ndef get_similarities(emd1, emd2):\n    cosine_scores=util.pytorch_cos_sim(emd1, emd2)\n    return cosine_scores\n\n\ndef mean_pooling(model_output, attention_mask):\n    \"\"\"\n    Need tokenizer\n    \"\"\"\n    # The first element of model_output contains all token embeddings\n    token_embeddings=model_output[0]\n    input_mask_expanded=attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    sum_embeddings=torch.sum(token_embeddings*input_mask_expanded,1)\n    sum_mask=torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n    return sum_embeddings/sum_mask\n\n\nemd_ans=get_embeddings(answers[\"vicuna-13b\"][\"answers_model\"][6])\nemd_ref=get_embeddings(answers[\"vicuna-13b\"][\"answers_ref\"][6])\n\nsimilarities=get_similarities(emd_ans, emd_ref)\nprint(similarities)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:23:42.633955Z","iopub.execute_input":"2024-03-17T11:23:42.634861Z","iopub.status.idle":"2024-03-17T11:23:42.692465Z","shell.execute_reply.started":"2024-03-17T11:23:42.634829Z","shell.execute_reply":"2024-03-17T11:23:42.691526Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3598a0d5e63b4e1fbd00a8c2dd7a9d05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a000bbcb3e964cf5b66a8f830a6326ef"}},"metadata":{}},{"name":"stdout","text":"tensor([[0.9201]], device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"from statistics import mean\nimport torch.nn as nn\n\ndef nn_cos(emd1,emd2):\n    cos=nn.CosineSimilarity(dim=1, eps=1e-6)\n    return cos(emd_ans, emd_ref).tolist()\n\nemd_ans=get_embeddings(answers[\"vicuna-13b\"][\"answers_model\"])\nemd_ans=normalize_embeddings(emd_ans)\nemd_ref=get_embeddings(answers[\"vicuna-13b\"][\"answers_ref\"])\nemd_ref=normalize_embeddings(emd_ref)\n\nprint(mean(nn_cos(emd_ans, emd_ref)))","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:47:59.450477Z","iopub.execute_input":"2024-03-17T11:47:59.451322Z","iopub.status.idle":"2024-03-17T11:48:00.461229Z","shell.execute_reply.started":"2024-03-17T11:47:59.451291Z","shell.execute_reply":"2024-03-17T11:48:00.460106Z"},"trusted":true},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"140e1481027e453d816831a15696b239"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a8e0f0bdc0c4dd499ced523fae8ae39"}},"metadata":{}},{"name":"stdout","text":"0.7271350175724365\n","output_type":"stream"}]},{"cell_type":"code","source":"from sentence_transformers.util import cos_sim\n\ncos_scores=cos_sim(emd_ans, emd_ref)\nprint(cos_scores)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:48:10.275710Z","iopub.execute_input":"2024-03-17T11:48:10.276094Z","iopub.status.idle":"2024-03-17T11:48:10.285046Z","shell.execute_reply.started":"2024-03-17T11:48:10.276062Z","shell.execute_reply":"2024-03-17T11:48:10.283993Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"tensor([[ 0.8245,  0.0437,  0.0380,  ...,  0.0598,  0.0732, -0.0286],\n        [ 0.0250,  0.9121,  0.3769,  ...,  0.0310,  0.0327,  0.0995],\n        [-0.0018,  0.2686,  0.7807,  ...,  0.0469,  0.1310,  0.1541],\n        ...,\n        [ 0.0264,  0.0147,  0.0789,  ...,  0.9540,  0.0722,  0.0518],\n        [ 0.0917,  0.0592,  0.1052,  ...,  0.0482,  0.7334,  0.0316],\n        [-0.0721,  0.0493,  0.1054,  ...,  0.0535,  0.0528,  0.9089]],\n       device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Calculating Similarity for all Answers","metadata":{}},{"cell_type":"code","source":"models=list(answers.keys())\nmodels_similarites=[]\n\nfor model in tqdm(models):\n    pass","metadata":{},"execution_count":null,"outputs":[]}]}