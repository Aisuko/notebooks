{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae514a5e",
   "metadata": {
    "papermill": {
     "duration": 0.006949,
     "end_time": "2023-07-20T04:55:13.134102",
     "exception": false,
     "start_time": "2023-07-20T04:55:13.127153",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We have seen that complex network require significant resources, such as GPU, for training, and also for fast inference. However, it turns out that a model with significantly smaller number of parameters in most cases can still be trained to perform reasonably well. In other worlds, increase in the model complexity typically results in small(non-proportional) increase in the model performance.\n",
    "\n",
    "According the previously notebooks, we can see that the accuracy of simple dense model was not significantly worse than that of a poweful CNN. **Increasing the number of CNN layer and/or number of neurons in the classifier allowed us to gain a few percents of accuracy at most**.\n",
    "\n",
    "This leads us to the idea that we can experiment with `Lightweight network architectures` in order to train faster models. This is especially important if we want to be able to execute our models on mobile devices.\n",
    "\n",
    "This module will rely on the Cats and Dogs dataset. First we will make sure that the dataset is available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c93e72e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T04:55:13.148651Z",
     "iopub.status.busy": "2023-07-20T04:55:13.147839Z",
     "iopub.status.idle": "2023-07-20T04:55:26.551361Z",
     "shell.execute_reply": "2023-07-20T04:55:26.550083Z"
    },
    "papermill": {
     "duration": 13.413326,
     "end_time": "2023-07-20T04:55:26.553600",
     "exception": false,
     "start_time": "2023-07-20T04:55:13.140274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.1)\r\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.0.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.6.3)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.23.5)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2023.5.7)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfab4dbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T04:55:26.567986Z",
     "iopub.status.busy": "2023-07-20T04:55:26.567662Z",
     "iopub.status.idle": "2023-07-20T04:55:29.990943Z",
     "shell.execute_reply": "2023-07-20T04:55:29.989868Z"
    },
    "papermill": {
     "duration": 3.433251,
     "end_time": "2023-07-20T04:55:29.993405",
     "exception": false,
     "start_time": "2023-07-20T04:55:26.560154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "import os, glob, zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27397bfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T04:55:30.008231Z",
     "iopub.status.busy": "2023-07-20T04:55:30.007696Z",
     "iopub.status.idle": "2023-07-20T04:55:30.013109Z",
     "shell.execute_reply": "2023-07-20T04:55:30.012072Z"
    },
    "papermill": {
     "duration": 0.01533,
     "end_time": "2023-07-20T04:55:30.015545",
     "exception": false,
     "start_time": "2023-07-20T04:55:30.000215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check the paltform, Apple Silicon or Linux\n",
    "import os, platform\n",
    "\n",
    "torch_device=\"cpu\"\n",
    "\n",
    "if 'kaggle' in os.environ.get('KAGGLE_URL_BASE','localhost'):\n",
    "    torch_device = 'cuda'\n",
    "else:\n",
    "    torch_device = 'mps' if platform.system() == 'Darwin' else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88dd4f24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T04:55:30.029905Z",
     "iopub.status.busy": "2023-07-20T04:55:30.029427Z",
     "iopub.status.idle": "2023-07-20T04:55:30.033944Z",
     "shell.execute_reply": "2023-07-20T04:55:30.032984Z"
    },
    "papermill": {
     "duration": 0.014004,
     "end_time": "2023-07-20T04:55:30.035952",
     "exception": false,
     "start_time": "2023-07-20T04:55:30.021948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64a34af7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T04:55:30.050510Z",
     "iopub.status.busy": "2023-07-20T04:55:30.049740Z",
     "iopub.status.idle": "2023-07-20T04:55:30.056805Z",
     "shell.execute_reply": "2023-07-20T04:55:30.055842Z"
    },
    "papermill": {
     "duration": 0.016525,
     "end_time": "2023-07-20T04:55:30.058886",
     "exception": false,
     "start_time": "2023-07-20T04:55:30.042361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6c51a3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T04:55:30.072882Z",
     "iopub.status.busy": "2023-07-20T04:55:30.072621Z",
     "iopub.status.idle": "2023-07-20T04:55:37.226228Z",
     "shell.execute_reply": "2023-07-20T04:55:37.225017Z"
    },
    "papermill": {
     "duration": 7.163519,
     "end_time": "2023-07-20T04:55:37.228922",
     "exception": false,
     "start_time": "2023-07-20T04:55:30.065403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-07-20 04:55:30--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\r\n",
      "Resolving download.microsoft.com (download.microsoft.com)... 104.119.101.9, 2600:1415:2000:195::317f, 2600:1415:2000:1a5::317f\r\n",
      "Connecting to download.microsoft.com (download.microsoft.com)|104.119.101.9|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 824887076 (787M) [application/octet-stream]\r\n",
      "Saving to: ‘data/kagglecatsanddogs_5340.zip’\r\n",
      "\r\n",
      "kagglecatsanddogs_5 100%[===================>] 786.67M   150MB/s    in 5.9s    \r\n",
      "\r\n",
      "2023-07-20 04:55:37 (134 MB/s) - ‘data/kagglecatsanddogs_5340.zip’ saved [824887076/824887076]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('data/kagglecatsanddogs_5340.zip'):\n",
    "    !wget -P data https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b75655d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T04:55:37.249164Z",
     "iopub.status.busy": "2023-07-20T04:55:37.248730Z",
     "iopub.status.idle": "2023-07-20T04:55:37.261619Z",
     "shell.execute_reply": "2023-07-20T04:55:37.260675Z"
    },
    "papermill": {
     "duration": 0.025475,
     "end_time": "2023-07-20T04:55:37.263720",
     "exception": false,
     "start_time": "2023-07-20T04:55:37.238245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def check_image(fn):\n",
    "    try:\n",
    "        im = Image.open(fn)\n",
    "        im.verify()\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def check_image_dir(path):\n",
    "    for fn in glob.glob(path):\n",
    "        if not check_image(fn):\n",
    "            print(\"Corrupt image: {}\".format(fn))\n",
    "            os.remove(fn)\n",
    "\n",
    "def common_transform():\n",
    "    # torchvision.transforms.Normalize is used to normalize a tensor image with mean and standard deviation.\n",
    "    std_normalize = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                     std=[0.229, 0.224, 0.225])\n",
    "    # torchvision.transforms.Compose is used to compose several transforms together in order to do data augmentation.\n",
    "    trans = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(256), # resize the image to 256x256\n",
    "        torchvision.transforms.CenterCrop(224), # crop the image to 224x224 about the center\n",
    "        torchvision.transforms.ToTensor(), # convert the image to a tensor with pixel values in the range [0, 1]\n",
    "        std_normalize])\n",
    "    return trans\n",
    "\n",
    "def load_cats_dogs_dataset():\n",
    "    if not os.path.exists('data/PetImages'):\n",
    "        with zipfile.ZipFile('data/kagglecatsanddogs_5340.zip', 'r') as zip_ref:\n",
    "            zip_ref.extractall('data')\n",
    "    \n",
    "    check_image_dir('data/PetImages/Cat/*.jpg')\n",
    "    check_image_dir('data/PetImages/Dog/*.jpg')\n",
    "\n",
    "    dataset = torchvision.datasets.ImageFolder('data/PetImages', transform=common_transform())\n",
    "    trainset, testset = torch.utils.data.random_split(dataset, [20000, len(dataset) - 20000])\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2) # num_workers: how many subprocesses to use for data loading\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
    "    return dataset, trainloader, testloader \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99f65a5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T04:55:37.283559Z",
     "iopub.status.busy": "2023-07-20T04:55:37.282704Z",
     "iopub.status.idle": "2023-07-20T04:55:48.429274Z",
     "shell.execute_reply": "2023-07-20T04:55:48.428211Z"
    },
    "papermill": {
     "duration": 11.159166,
     "end_time": "2023-07-20T04:55:48.431882",
     "exception": false,
     "start_time": "2023-07-20T04:55:37.272716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrupt image: data/PetImages/Cat/666.jpg\n",
      "Corrupt image: data/PetImages/Dog/11702.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:864: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "dataset, trainloader, testloader = load_cats_dogs_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8592a12a",
   "metadata": {
    "papermill": {
     "duration": 0.009231,
     "end_time": "2023-07-20T04:55:48.450864",
     "exception": false,
     "start_time": "2023-07-20T04:55:48.441633",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MobileNet\n",
    "\n",
    "In the previous notebook, we habve seen [**ResNet** architecture](https://www.kaggle.com/code/aisuko/pre-trained-models-and-transfer-learning) for image classification. More lightweight analog of ResNet is **MobileNet**, which uses so-called *Inverted Residual Blocks*. Let's load pre-trained mobilenet and see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1624aad5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T04:55:48.471381Z",
     "iopub.status.busy": "2023-07-20T04:55:48.471092Z",
     "iopub.status.idle": "2023-07-20T04:55:52.182916Z",
     "shell.execute_reply": "2023-07-20T04:55:52.177678Z"
    },
    "papermill": {
     "duration": 3.726257,
     "end_time": "2023-07-20T04:55:52.186655",
     "exception": false,
     "start_time": "2023-07-20T04:55:48.460398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
      "100%|██████████| 13.6M/13.6M [00:00<00:00, 62.6MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): Conv2dNormActivation(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "# https://pytorch.org/hub/pytorch_vision_mobilenet_v2/\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
    "model.eval()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a8056e",
   "metadata": {
    "papermill": {
     "duration": 0.010738,
     "end_time": "2023-07-20T04:55:52.208373",
     "exception": false,
     "start_time": "2023-07-20T04:55:52.197635",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Apply the model to the dataset and visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d042588",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T04:55:52.231731Z",
     "iopub.status.busy": "2023-07-20T04:55:52.230791Z",
     "iopub.status.idle": "2023-07-20T04:55:52.462373Z",
     "shell.execute_reply": "2023-07-20T04:55:52.461082Z"
    },
    "papermill": {
     "duration": 0.245143,
     "end_time": "2023-07-20T04:55:52.464549",
     "exception": false,
     "start_time": "2023-07-20T04:55:52.219406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(281)\n"
     ]
    }
   ],
   "source": [
    "sample_image = dataset[0][0].unsqueeze(0) # unsqueeze(0): add a dimension of size 1 at the 0th position\n",
    "res = model(sample_image) # apply the model to the sample image\n",
    "print(res[0].argmax()) # get the index of the highest probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b321340a",
   "metadata": {
    "papermill": {
     "duration": 0.010699,
     "end_time": "2023-07-20T04:55:52.486560",
     "exception": false,
     "start_time": "2023-07-20T04:55:52.475861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Using MobileNet for transfer learning\n",
    "\n",
    "Now let's perform the same transfer learning process as in previous notebook, but using MobileNet as a base model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1be66a7",
   "metadata": {
    "papermill": {
     "duration": 0.013829,
     "end_time": "2023-07-20T04:55:52.511275",
     "exception": false,
     "start_time": "2023-07-20T04:55:52.497446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Freeze all parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f9f76b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T04:55:52.537106Z",
     "iopub.status.busy": "2023-07-20T04:55:52.535991Z",
     "iopub.status.idle": "2023-07-20T04:55:52.552917Z",
     "shell.execute_reply": "2023-07-20T04:55:52.547973Z"
    },
    "papermill": {
     "duration": 0.032967,
     "end_time": "2023-07-20T04:55:52.555215",
     "exception": false,
     "start_time": "2023-07-20T04:55:52.522248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in model.parameters():\n",
    "    x.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa27fae9",
   "metadata": {
    "papermill": {
     "duration": 0.010434,
     "end_time": "2023-07-20T04:55:52.576425",
     "exception": false,
     "start_time": "2023-07-20T04:55:52.565991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Replace the final classifier\n",
    "\n",
    "We also transfer the model to our default training device (GPU or CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64a583df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T04:55:52.599340Z",
     "iopub.status.busy": "2023-07-20T04:55:52.598528Z",
     "iopub.status.idle": "2023-07-20T04:55:52.604465Z",
     "shell.execute_reply": "2023-07-20T04:55:52.603593Z"
    },
    "papermill": {
     "duration": 0.019895,
     "end_time": "2023-07-20T04:55:52.606593",
     "exception": false,
     "start_time": "2023-07-20T04:55:52.586698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check the paltform, Apple Silicon or Linux\n",
    "import os, platform\n",
    "\n",
    "torch_device=\"cpu\"\n",
    "\n",
    "if 'kaggle' in os.environ.get('KAGGLE_URL_BASE','localhost'):\n",
    "    torch_device = 'cuda'\n",
    "else:\n",
    "    torch_device = 'mps' if platform.system() == 'Darwin' else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9c05ea8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T04:55:52.629563Z",
     "iopub.status.busy": "2023-07-20T04:55:52.629221Z",
     "iopub.status.idle": "2023-07-20T04:55:52.633815Z",
     "shell.execute_reply": "2023-07-20T04:55:52.632802Z"
    },
    "papermill": {
     "duration": 0.018641,
     "end_time": "2023-07-20T04:55:52.635853",
     "exception": false,
     "start_time": "2023-07-20T04:55:52.617212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bcb1388",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T04:55:52.658702Z",
     "iopub.status.busy": "2023-07-20T04:55:52.657954Z",
     "iopub.status.idle": "2023-07-20T04:55:52.669063Z",
     "shell.execute_reply": "2023-07-20T04:55:52.663280Z"
    },
    "papermill": {
     "duration": 0.03,
     "end_time": "2023-07-20T04:55:52.676304",
     "exception": false,
     "start_time": "2023-07-20T04:55:52.646304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97ede491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T04:55:52.722783Z",
     "iopub.status.busy": "2023-07-20T04:55:52.721137Z",
     "iopub.status.idle": "2023-07-20T04:55:59.924908Z",
     "shell.execute_reply": "2023-07-20T04:55:59.923945Z"
    },
    "papermill": {
     "duration": 7.231091,
     "end_time": "2023-07-20T04:55:59.927257",
     "exception": false,
     "start_time": "2023-07-20T04:55:52.696166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "MobileNetV2                                        [1, 2]                    --\n",
       "├─Sequential: 1-1                                  [1, 1280, 7, 7]           --\n",
       "│    └─Conv2dNormActivation: 2-1                   [1, 32, 112, 112]         --\n",
       "│    │    └─Conv2d: 3-1                            [1, 32, 112, 112]         (864)\n",
       "│    │    └─BatchNorm2d: 3-2                       [1, 32, 112, 112]         (64)\n",
       "│    │    └─ReLU6: 3-3                             [1, 32, 112, 112]         --\n",
       "│    └─InvertedResidual: 2-2                       [1, 16, 112, 112]         --\n",
       "│    │    └─Sequential: 3-4                        [1, 16, 112, 112]         (896)\n",
       "│    └─InvertedResidual: 2-3                       [1, 24, 56, 56]           --\n",
       "│    │    └─Sequential: 3-5                        [1, 24, 56, 56]           (5,136)\n",
       "│    └─InvertedResidual: 2-4                       [1, 24, 56, 56]           --\n",
       "│    │    └─Sequential: 3-6                        [1, 24, 56, 56]           (8,832)\n",
       "│    └─InvertedResidual: 2-5                       [1, 32, 28, 28]           --\n",
       "│    │    └─Sequential: 3-7                        [1, 32, 28, 28]           (10,000)\n",
       "│    └─InvertedResidual: 2-6                       [1, 32, 28, 28]           --\n",
       "│    │    └─Sequential: 3-8                        [1, 32, 28, 28]           (14,848)\n",
       "│    └─InvertedResidual: 2-7                       [1, 32, 28, 28]           --\n",
       "│    │    └─Sequential: 3-9                        [1, 32, 28, 28]           (14,848)\n",
       "│    └─InvertedResidual: 2-8                       [1, 64, 14, 14]           --\n",
       "│    │    └─Sequential: 3-10                       [1, 64, 14, 14]           (21,056)\n",
       "│    └─InvertedResidual: 2-9                       [1, 64, 14, 14]           --\n",
       "│    │    └─Sequential: 3-11                       [1, 64, 14, 14]           (54,272)\n",
       "│    └─InvertedResidual: 2-10                      [1, 64, 14, 14]           --\n",
       "│    │    └─Sequential: 3-12                       [1, 64, 14, 14]           (54,272)\n",
       "│    └─InvertedResidual: 2-11                      [1, 64, 14, 14]           --\n",
       "│    │    └─Sequential: 3-13                       [1, 64, 14, 14]           (54,272)\n",
       "│    └─InvertedResidual: 2-12                      [1, 96, 14, 14]           --\n",
       "│    │    └─Sequential: 3-14                       [1, 96, 14, 14]           (66,624)\n",
       "│    └─InvertedResidual: 2-13                      [1, 96, 14, 14]           --\n",
       "│    │    └─Sequential: 3-15                       [1, 96, 14, 14]           (118,272)\n",
       "│    └─InvertedResidual: 2-14                      [1, 96, 14, 14]           --\n",
       "│    │    └─Sequential: 3-16                       [1, 96, 14, 14]           (118,272)\n",
       "│    └─InvertedResidual: 2-15                      [1, 160, 7, 7]            --\n",
       "│    │    └─Sequential: 3-17                       [1, 160, 7, 7]            (155,264)\n",
       "│    └─InvertedResidual: 2-16                      [1, 160, 7, 7]            --\n",
       "│    │    └─Sequential: 3-18                       [1, 160, 7, 7]            (320,000)\n",
       "│    └─InvertedResidual: 2-17                      [1, 160, 7, 7]            --\n",
       "│    │    └─Sequential: 3-19                       [1, 160, 7, 7]            (320,000)\n",
       "│    └─InvertedResidual: 2-18                      [1, 320, 7, 7]            --\n",
       "│    │    └─Sequential: 3-20                       [1, 320, 7, 7]            (473,920)\n",
       "│    └─Conv2dNormActivation: 2-19                  [1, 1280, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-21                           [1, 1280, 7, 7]           (409,600)\n",
       "│    │    └─BatchNorm2d: 3-22                      [1, 1280, 7, 7]           (2,560)\n",
       "│    │    └─ReLU6: 3-23                            [1, 1280, 7, 7]           --\n",
       "├─Linear: 1-2                                      [1, 2]                    2,562\n",
       "====================================================================================================\n",
       "Total params: 2,226,434\n",
       "Trainable params: 2,562\n",
       "Non-trainable params: 2,223,872\n",
       "Total mult-adds (M): 299.53\n",
       "====================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 106.85\n",
       "Params size (MB): 8.91\n",
       "Estimated Total Size (MB): 116.36\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier = nn.Linear(1280,2)  # change the last layer to a linear layer with 2 outputs\n",
    "model = model.to(torch_device)\n",
    "summary(model, input_size=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4256f5d",
   "metadata": {
    "papermill": {
     "duration": 0.011057,
     "end_time": "2023-07-20T04:55:59.950433",
     "exception": false,
     "start_time": "2023-07-20T04:55:59.939376",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Doing the actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69b4cad7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T04:55:59.973906Z",
     "iopub.status.busy": "2023-07-20T04:55:59.973570Z",
     "iopub.status.idle": "2023-07-20T04:57:36.507874Z",
     "shell.execute_reply": "2023-07-20T04:57:36.506649Z"
    },
    "papermill": {
     "duration": 96.548995,
     "end_time": "2023-07-20T04:57:36.510426",
     "exception": false,
     "start_time": "2023-07-20T04:55:59.961431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, iter 0, loss=0.024, acc=0.375\n",
      "Epoch 0, iter 90, loss=0.007, acc=0.926\n",
      "Epoch 0, iter 180, loss=0.007, acc=0.936\n",
      "Epoch 0, iter 270, loss=0.006, acc=0.945\n",
      "Epoch 0, iter 360, loss=0.007, acc=0.943\n",
      "Epoch 0, iter 450, loss=0.007, acc=0.946\n",
      "Epoch 0, iter 540, loss=0.007, acc=0.945\n",
      "Epoch 0, val_loss=0.003, val_acc=0.980\n"
     ]
    }
   ],
   "source": [
    "def validate(net, dataloader, loss_fn=nn.NLLLoss()):\n",
    "    net.eval() # put the network into evaluation mode to deactivate the dropout layers\n",
    "    count,acc,loss =0,0,0\n",
    "    with torch.no_grad(): # deactivate autograd to save memory and speed up computations\n",
    "        for features, labels in dataloader:\n",
    "            features,labels = features.to(torch_device), labels.to(torch_device)\n",
    "            out=net(features) # forward pass of the mini-batch through the network to obtain the outputs\n",
    "            loss += loss_fn(out,labels) # compute the loss\n",
    "            preds=torch.max(out,dim=1)[1] # compute the predictions to obtain the accuracy\n",
    "            acc+=(preds==labels).sum() # accumulate the correct predictions\n",
    "            count+=len(labels) # accumulate the total number of examples\n",
    "    return loss.item()/count, acc.item()/count # return the loss and accuracy\n",
    "\n",
    "def train_long(net, train_loader, test_loader, epochs=5, lr=0.01, optimizer=None, loss_fn=nn.NLLLoss(), print_freq=10):\n",
    "    optimizer = optimizer or torch.optim.Adam(net.parameters(), lr=lr) # use Adam optimizer if not provided\n",
    "    for epoch in range(epochs):\n",
    "        net.train() # put the network into training mode make sure the parameters are trainable\n",
    "        total_loss,acc,count =0,0,0\n",
    "        for i, (features, labels) in enumerate(train_loader):\n",
    "            lbls = labels.to(torch_device)\n",
    "            optimizer.zero_grad() # reset the gradients to zero before each batch to avoid accumulation\n",
    "            out=net(features.to(torch_device)) # forward pass of the mini-batch through the network to obtain the outputs\n",
    "            loss = loss_fn(out, lbls) # compute the loss\n",
    "            loss.backward() # compute the gradients of the loss with respect to all the parameters of the network\n",
    "            optimizer.step() # update the parameters of the network using the gradients to minimize the loss\n",
    "            total_loss+=loss # accumulate the loss for inspection\n",
    "            _,preds=torch.max(out,dim=1) # compute the predictions to obtain the accuracy\n",
    "            acc+=(preds==lbls).sum() # accumulate the correct predictions\n",
    "            count+=len(lbls) # accumulate the total number of examples\n",
    "            if i%print_freq==0:\n",
    "                print(f'Epoch {epoch}, iter {i}, loss={total_loss.item()/count:.3f}, acc={acc.item()/count:.3f}')\n",
    "        vl, va = validate(net, test_loader, loss_fn=loss_fn)\n",
    "        print(f'Epoch {epoch}, val_loss={vl:.3f}, val_acc={va:.3f}')\n",
    "\n",
    "train_long(model, trainloader, testloader, loss_fn=torch.nn.CrossEntropyLoss(),epochs=1, print_freq=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b8c676",
   "metadata": {
    "papermill": {
     "duration": 0.011287,
     "end_time": "2023-07-20T04:57:36.533084",
     "exception": false,
     "start_time": "2023-07-20T04:57:36.521797",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Summary\n",
    "\n",
    "Notice that MobileNet results in almost the same accuracy as VGG-16, and just slightly lower than full-scale ResNet.\n",
    "\n",
    "The main advantage of small models, such as MobileNet or ResNet-18 is that they can be used on mobile devices, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 155.748181,
   "end_time": "2023-07-20T04:57:39.228771",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-20T04:55:03.480590",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
