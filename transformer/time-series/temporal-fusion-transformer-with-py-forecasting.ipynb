{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":85723,"databundleVersionId":10652996,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U pytorch-lightning==2.5.0\n!pip install -q -U pytorch-forecasting==1.2.0\n!pip install -q -U pytorch_optimizer==3.3.4","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-01T07:25:12.332216Z","iopub.execute_input":"2025-02-01T07:25:12.332679Z","iopub.status.idle":"2025-02-01T07:25:28.517627Z","shell.execute_reply.started":"2025-02-01T07:25:12.332643Z","shell.execute_reply":"2025-02-01T07:25:28.516562Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.4/819.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.9/181.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.9/221.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\nfrom pytorch_lightning.loggers import TensorBoardLogger\n\nfrom pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\nfrom pytorch_forecasting.data import GroupNormalizer\nfrom pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss\nfrom pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T07:25:28.519103Z","iopub.execute_input":"2025-02-01T07:25:28.519399Z","iopub.status.idle":"2025-02-01T07:25:44.028012Z","shell.execute_reply.started":"2025-02-01T07:25:28.519374Z","shell.execute_reply":"2025-02-01T07:25:44.027018Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/playground-series-s5e1/test.csv', index_col = 0)\ntest = pd.read_csv('/kaggle/input/playground-series-s5e1/train.csv', index_col = 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T07:25:44.029762Z","iopub.execute_input":"2025-02-01T07:25:44.030279Z","iopub.status.idle":"2025-02-01T07:25:44.492285Z","shell.execute_reply.started":"2025-02-01T07:25:44.030253Z","shell.execute_reply":"2025-02-01T07:25:44.491212Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Preprocessing data\n\nFill the missing value and remove value `Nans`.\n\nGroup the filtered DataFrame by 'country', 'store', and 'product'. Within each group, apply the ffill() method to the 'num_sold' column to propagate the last valid observation forward.","metadata":{}},{"cell_type":"code","source":"condition = (\n    (train['country'] == 'Canada') & \n    (train['store'] == 'Discount Stickers') & \n    (train['product'] == 'Kerneler' )\n)\n\ntrain.loc[condition, 'num_sold'] = train.loc[condition, 'num_sold'].ffill() # \n\ncondition = (\n    (train['country'] == 'Kenya') & \n    (train['store'] == 'Discount Stickers') & \n    (train['product'] == 'Kerneler' )\n)\n\ntrain.loc[condition, 'num_sold'] = train.loc[condition, 'num_sold'].ffill()\n\ncondition = (\n    (train['country'] == 'Kenya') & \n    (train['store'] == 'Discount Stickers') & \n    (train['product'] == 'Kerneler Dark Mode' )\n)\n\ntrain.loc[condition, 'num_sold'] = train.loc[condition, 'num_sold'].ffill()\n\ntrain = train.dropna() # Handle any straggling Nans","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create Pytorch Model Ready TimeSeriesDataset","metadata":{}},{"cell_type":"code","source":"# Converting dataset to a Standardized Format\ntrain['date']=pd.to_datetime(train['date'])\ntest['date'] = pd.to_datetime(test['date'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T07:25:44.803231Z","iopub.status.idle":"2025-02-01T07:25:44.803592Z","shell.execute_reply":"2025-02-01T07:25:44.803449Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Creating a Time Index for Sequential Ordering\n\nTemporal Fusion Transformer models require a numerical time index(time_idx) for their architecture to recognize the temporal sequence of data points.\n\n* **max_prediction_length**: Defines the forecast horizon(number of future time steps to predict)\n* **max_encoder_length**: Determines the maximum historical time steps used as input\n* **training_cutoff**: Seperaets the training data from the validation period by reserving the last **max_prediction_length** time steps for validation.","metadata":{}},{"cell_type":"code","source":"train[\"time_idx\"]=train[\"date\"].dt.year*12+train[\"date\"].dt.month\ntrain[\"time_idx\"]-=train[\"time_idx\"].min()\n\ntest[\"time_idx\"]=test[\"date\"].dt.year*12+test[\"date\"].dt.month\ntest[\"time_idx\"]-=test[\"time_idx\"].min()\n\nmax_prediction_length=6\nmax_encoder_length=train.date.nunique()\ntraining_cutoff=train[\"time_idx\"].max()- max_prediction_length","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T07:25:44.804667Z","iopub.status.idle":"2025-02-01T07:25:44.805088Z","shell.execute_reply":"2025-02-01T07:25:44.804905Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature Engineer\n\nTemporal patterns often vary by month. TFT can leverage this information when months are provided as categorical variables.","metadata":{}},{"cell_type":"code","source":"train[\"month\"] = train.date.dt.month.astype(str).astype(\"category\")\ntest[\"month\"] = test.date.dt.month.astype(str).astype(\"category\")\n\ntrain[\"log_num_sold\"] = np.log(train.num_sold + 1e-8)\ntrain[\"avg_num_sold_by_country\"] = train.groupby([\"time_idx\", \"country\"], observed=True).num_sold.transform(\"mean\")\ntrain[\"avg_num_sold_by_store\"] = train.groupby([\"time_idx\", \"store\"], observed=True).num_sold.transform(\"mean\")\ntrain[\"avg_num_sold_by_product\"] = train.groupby([\"time_idx\", \"product\"], observed=True).num_sold.transform(\"mean\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T07:25:44.805973Z","iopub.status.idle":"2025-02-01T07:25:44.806396Z","shell.execute_reply":"2025-02-01T07:25:44.806210Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Set up the TimeSeriesDataSet\n\n* **Static Categoricals**: Group-level identifiers (country, store, product).\n* **Time-Varying Features**\n    * **Known**: Features available for all time steps (e.g., month, time_idx).\n    * **Unknown**: Features only known for historical data (e.g., num_sold, averages).\n* **Normalization**: GroupNormalizer normalizes the target variable within each group using the softplus transformation.","metadata":{}},{"cell_type":"code","source":"training=TimeSeriesDataSet(\n    train[lambda x:x.time_idx <= training_cutoff],\n    time_idx=\"time_idx\",\n    target=\"num_sold\",\n    group_ids=[\"country\", \"store\", \"product\"],\n    min_encoder_length=1,\n    max_encoder_length=max_encoder_length,\n    min_prediction_length=1,\n    max_prediction_length=max_prediction_length,\n    static_categoricals=[\"country\", \"store\", \"product\"],\n    time_varying_known_categoricals=[\"month\"],\n    time_varying_known_reals=[\"time_idx\"],\n    time_varying_unknown_categoricals=[],\n    time_varying_unknown_reals=[\n        \"num_sold\",\n        \"log_num_sold\",\n        \"avg_num_sold_by_country\",\n        \"avg_num_sold_by_store\",\n        \"avg_num_sold_by_product\",\n    ],\n    allow_missing_timesteps=True,\n    target_normalizer=GroupNormalizer(\n        groups=[\"country\", \"store\", \"product\"], transformation=\"softplus\"\n    ),\n    add_relative_time_idx=True,\n    add_target_scales=True,\n    add_encoder_length=True,\n)\n\n\n# Creating the Validation Dataset\nvalidation = TimeSeriesDataSet.from_dataset(training, train, predict=True, stop_randomization=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T07:25:44.807357Z","iopub.status.idle":"2025-02-01T07:25:44.807785Z","shell.execute_reply":"2025-02-01T07:25:44.807584Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Creating Dataloaders","metadata":{}},{"cell_type":"code","source":"batch_size = 128\ntrain_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\nval_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T07:25:44.808580Z","iopub.status.idle":"2025-02-01T07:25:44.808980Z","shell.execute_reply":"2025-02-01T07:25:44.808782Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training the TFT Model","metadata":{}},{"cell_type":"code","source":"early_stop_callback=EarlyStopping(\n    monitor=\"val_loss\", # monitors validation loss\n    min_delta=1e-4, # minimum change in the monitored quantity to qualify as an improvement\n    patience=10,  # stops training if no improvement is seen after 10 epochs\n    verbose=False,\n    mode=\"min\" # lower validation loss is better\n)\n\nlr_logger=LearningRateMonitor() # tracks learning rate during training\n\n# Initiate the trainer\ntrainer=Trainer(\n    max_epochs=50, # train the model for a maximum of 50 epochs\n    accelerator=\"gpu\",\n    enable_model_summary=True, # prints a summary of the model architecture\n    gradient_clip_val=0.1, # clips gradients to prevent exploading gradients\n    limit_train_batches=50, # limits the number of trianing batches per epoch\n    callbacks=[lr_logger, early_stop_callback], # include callbacks for logging and early stopping\n)\n\n# compile the model\ntft=TemporalFusionTransformer.from_dataset(\n    training, # the training dataset\n    learning_rate=0.03,\n    hidden_size=16, # size of hidden layers in the model\n    attention_head_size=2, # number of attention heads\n    dropout=0.1, # dropout for regulatization\n    hidden_continuous_size=8, # size of hidden layers for continuous variables\n    loss=QuantileLoss(), # uses Quantile Loss for probabilistic forecasting\n    log_interval=10, # logs metrics every 10 batches\n    optimizer=\"adam\", # uses the Adam optimizer\n    reduce_on_plateau_patience=4, # reduces learning rate if validation performance plateaus\n)\n\ntrainer.fit(\n    tft,\n    train_dataloaders=train_dataloader,\n    val_dataloaders=val_dataloader,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T07:25:44.809821Z","iopub.status.idle":"2025-02-01T07:25:44.810098Z","shell.execute_reply":"2025-02-01T07:25:44.809985Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Forecast with the model","metadata":{}},{"cell_type":"code","source":"best_model_path=trainer.checkpoint_callback.best_model_path\nbest_tft=TemporalFusionTransformer.load_from_checkpoint(best_model_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T07:25:44.810809Z","iopub.status.idle":"2025-02-01T07:25:44.811252Z","shell.execute_reply":"2025-02-01T07:25:44.811054Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions = best_tft.predict(val_dataloader, return_y=True, trainer_kwargs=dict(accelerator=\"gpu\"))\nMAE()(predictions.output, predictions.y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T07:25:44.812121Z","iopub.status.idle":"2025-02-01T07:25:44.812498Z","shell.execute_reply":"2025-02-01T07:25:44.812370Z"}},"outputs":[],"execution_count":null}]}