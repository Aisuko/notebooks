{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aisuko/multi-head-attention-plus-data-loading?scriptVersionId=164079402\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"95a68ca0","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.003037,"end_time":"2024-02-24T05:37:34.214402","exception":false,"start_time":"2024-02-24T05:37:34.211365","status":"completed"},"tags":[]},"source":["# Overview\n","\n","In this notebook, we implement `multihead-attention` and `Dataloader`."]},{"cell_type":"code","execution_count":1,"id":"c000c9fd","metadata":{"execution":{"iopub.execute_input":"2024-02-24T05:37:34.221803Z","iopub.status.busy":"2024-02-24T05:37:34.22124Z","iopub.status.idle":"2024-02-24T05:37:44.736082Z","shell.execute_reply":"2024-02-24T05:37:44.735097Z"},"papermill":{"duration":10.521116,"end_time":"2024-02-24T05:37:44.738623","exception":false,"start_time":"2024-02-24T05:37:34.217507","status":"completed"},"tags":[]},"outputs":[],"source":["%%capture\n","# BPE(Byte pair encoding) also named diagram coding: is an algorithem,with an ability to combine both tokens that encode single characters (including single digits or single punctuation marks) and those that encode whole words (even the longest compound words) \n","!pip install tiktoken==0.6.0"]},{"cell_type":"markdown","id":"b5e4cedb","metadata":{"papermill":{"duration":0.002246,"end_time":"2024-02-24T05:37:44.743509","exception":false,"start_time":"2024-02-24T05:37:44.741263","status":"completed"},"tags":[]},"source":["# DataLoader"]},{"cell_type":"code","execution_count":2,"id":"4e84ac93","metadata":{"execution":{"iopub.execute_input":"2024-02-24T05:37:44.750235Z","iopub.status.busy":"2024-02-24T05:37:44.749473Z","iopub.status.idle":"2024-02-24T05:37:51.107143Z","shell.execute_reply":"2024-02-24T05:37:51.1061Z"},"papermill":{"duration":6.363487,"end_time":"2024-02-24T05:37:51.109406","exception":false,"start_time":"2024-02-24T05:37:44.745919","status":"completed"},"tags":[]},"outputs":[],"source":["import tiktoken\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","\n","class GPTDatasetV1(Dataset):\n","    def __init__(self, txt, tokenizer, max_length, stride):\n","        self.tokenizer=tokenizer\n","        self.input_ids=[]\n","        self.target_ids=[]\n","        \n","        # tokenize the entire text\n","        token_ids=tokenizer.encode(txt, allowed_special={'<|endoftext|>'})\n","        \n","        # use a sliding window to chunk the book into overlapping sequences of max_length\n","        for i in range(0, len(token_ids)-max_length, stride):\n","            input_chunk=token_ids[i:i+max_length]\n","            target_chunk=token_ids[i+1:i+max_length+1]\n","            self.input_ids.append(torch.tensor(input_chunk))\n","            self.target_ids.append(torch.tensor(target_chunk))\n","    \n","    def __len__(self):\n","        return len(self.input_ids)\n","    \n","    def __getitem__(self, idx):\n","        return self.input_ids[idx], self.target_ids[idx]\n","\n","\n","def create_dataloader(txt, batch_size=4, max_length=256, stride=128, shuffle=True):\n","    # initialize the tokenizer\n","    tokenizer=tiktoken.get_encoding('gpt2')\n","    \n","    # create dataset\n","    dataset=GPTDatasetV1(txt, tokenizer, max_length, stride)\n","    \n","    # create dataloader\n","    dataloader=DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n","    \n","    return dataloader\n","\n","\n","# with open('small-text-sample.txt', 'r', encoding='utf-8') as f:\n","#     raw_text=f.read()\n","\n","raw_text='''Once upon a time in a quiet village nestled among rolling hills and whispering forests, there lived a young girl named Elara. Elara was known for her boundless curiosity and her love for the stars. Every night, she would climb to the highest hill near her home to gaze at the glittering sky, dreaming of distant worlds and galaxies.\n","\n","In the heart of the village, there was an ancient library, tended by an old, wise librarian named Mr. Bramwell. This library was a treasure trove of books on every subject, but most importantly, it housed a collection of old star maps and celestial guides. Elara, fascinated by these books, spent countless hours with Mr. Bramwell, learning about constellations, planets, and the mysteries of the universe.\n","\n","One evening, while studying an old star map, Elara noticed a small, uncharted star that twinkled differently. She shared this discovery with Mr. Bramwell, who was equally intrigued. They decided to observe this star every night, noting its unique patterns and movements. This small, mysterious star, which they named \"Elara's Star,\" became the center of their nightly adventures.\n","\n","As days turned into weeks, the villagers began to take notice of Elara's star. The uncharted star brought the community together, with people of all ages joining Elara and Mr. Bramwell on the hill each night to gaze at the sky. The nightly gatherings turned into a festival of stars, where stories were shared, friendships were formed, and the mysteries of the cosmos were contemplated.\n","\n","The story of Elara and her star spread far and wide, attracting astronomers and dreamers from distant lands. The once quiet village became a beacon of wonder, a place where the sky seemed a little closer and the stars a bit friendlier. Elara's curiosity had not only unveiled a hidden star but had also brought her community together, reminding everyone that sometimes, the most extraordinary discoveries are waiting just above us, in the starlit sky.\n","'''\n","    \n","tokenizer=tiktoken.get_encoding('gpt2')\n","encoded_text=tokenizer.encode(raw_text)\n","\n","vocab_size=50257\n","output_dim=256\n","max_len=1024\n","block_size=max_len\n","\n","token_embedding_layer=nn.Embedding(vocab_size, output_dim)\n","pos_embedding_layer=torch.nn.Embedding(block_size, output_dim)\n","\n","max_length=4\n","dataloader=create_dataloader(raw_text, batch_size=8, max_length=max_length, stride=5)"]},{"cell_type":"code","execution_count":3,"id":"54fb600c","metadata":{"execution":{"iopub.execute_input":"2024-02-24T05:37:51.115814Z","iopub.status.busy":"2024-02-24T05:37:51.115446Z","iopub.status.idle":"2024-02-24T05:37:51.17203Z","shell.execute_reply":"2024-02-24T05:37:51.171345Z"},"papermill":{"duration":0.061568,"end_time":"2024-02-24T05:37:51.173666","exception":false,"start_time":"2024-02-24T05:37:51.112098","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([8, 4, 256])\n"]}],"source":["for batch in dataloader:\n","    x, y=batch\n","    token_embeddings=token_embedding_layer(x)\n","    pos_embeddings=pos_embedding_layer(torch.arange(max_length))\n","    \n","    input_embeddings=token_embeddings+pos_embeddings\n","    \n","    break\n","\n","print(input_embeddings.shape)"]},{"cell_type":"markdown","id":"d4ae67db","metadata":{"papermill":{"duration":0.002252,"end_time":"2024-02-24T05:37:51.178599","exception":false,"start_time":"2024-02-24T05:37:51.176347","status":"completed"},"tags":[]},"source":["# Multi-head Attention\n","\n","## Variant A: Simple implementation"]},{"cell_type":"code","execution_count":4,"id":"2e318414","metadata":{"execution":{"iopub.execute_input":"2024-02-24T05:37:51.185033Z","iopub.status.busy":"2024-02-24T05:37:51.184378Z","iopub.status.idle":"2024-02-24T05:37:51.24242Z","shell.execute_reply":"2024-02-24T05:37:51.241663Z"},"papermill":{"duration":0.063245,"end_time":"2024-02-24T05:37:51.244229","exception":false,"start_time":"2024-02-24T05:37:51.180984","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["context_vecs.shape: torch.Size([8, 4, 256])\n"]}],"source":["class CausalSelfAttention(nn.Module):\n","    def __init__(self, d_in, d_out, block_size, dropout, qkv_bias=False):\n","        super().__init__()\n","        self.d_out=d_out\n","        self.W_query=nn.Linear(d_in, d_out, bias=qkv_bias)\n","        self.W_key=nn.Linear(d_in, d_out, bias=qkv_bias)\n","        self.W_value=nn.Linear(d_in, d_out, bias=qkv_bias)\n","        self.dropout=nn.Dropout(dropout) # new\n","        self.register_buffer('mask', torch.triu(torch.ones(block_size, block_size), diagonal=1)) # new\n","        \n","    def forward(self, x):\n","        b, n_tokens, d_in=x.shape # new batch dimension b\n","        keys=self.W_key(x)\n","        queries=self.W_query(x)\n","        values=self.W_value(x)\n","        \n","        attn_scores=queries@keys.transpose(1,2) # changed transpose\n","        # new, _ops are in-place\n","        attn_scores.masked_fill_(\n","            self.mask.bool()[:n_tokens, :n_tokens], -torch.inf\n","        )\n","        \n","        atten_weights=torch.softmax(attn_scores/keys.shape[-1]**0.5, dim=1)\n","        atten_weights=self.dropout(atten_weights) # new\n","        \n","        context_vec=atten_weights@values\n","        return context_vec\n","    \n","\n","class MultiHeadAttentionWrapper(nn.Module):\n","    def __init__(self, d_in, d_out, block_size, dropout, num_heads, qkv_bias=False):\n","        super().__init__()\n","        self.heads=nn.ModuleList([CausalSelfAttention(d_in, d_out, block_size, dropout, qkv_bias) for _ in range(num_heads)])\n","        self.out_proj=nn.Linear(d_out*num_heads, d_out*num_heads)\n","    \n","    def forward(self, x):\n","        context_vec=torch.cat([head(x) for head in self.heads], dim=-1)\n","        return self.out_proj(context_vec)\n","    \n","\n","torch.manual_seed(123)\n","block_size=max_length\n","d_in=output_dim\n","\n","num_heads=2\n","d_out=d_in//num_heads\n","\n","mha=MultiHeadAttentionWrapper(d_in, d_out, block_size, 0.0, num_heads)\n","\n","batch=input_embeddings\n","context_vecs=mha(batch)\n","\n","print('context_vecs.shape:', context_vecs.shape)"]},{"cell_type":"markdown","id":"cda5b081","metadata":{"papermill":{"duration":0.002364,"end_time":"2024-02-24T05:37:51.249465","exception":false,"start_time":"2024-02-24T05:37:51.247101","status":"completed"},"tags":[]},"source":["## Vatiant B: Alternative implementation"]},{"cell_type":"code","execution_count":5,"id":"854614e4","metadata":{"execution":{"iopub.execute_input":"2024-02-24T05:37:51.25624Z","iopub.status.busy":"2024-02-24T05:37:51.255915Z","iopub.status.idle":"2024-02-24T05:37:51.27886Z","shell.execute_reply":"2024-02-24T05:37:51.278015Z"},"papermill":{"duration":0.02869,"end_time":"2024-02-24T05:37:51.280803","exception":false,"start_time":"2024-02-24T05:37:51.252113","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["context_vecs.shape: torch.Size([8, 4, 256])\n"]}],"source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_in, d_out, block_size, dropout, num_heads, qkv_bias=False):\n","        super().__init__()\n","        assert d_out % num_heads==0, \"d_out must be divisible by n_heads\"\n","        \n","        self.d_out=d_out\n","        self.num_heads=num_heads\n","        self.head_dim=d_out//num_heads # reduce the projection dim to match desired output dim\n","        \n","        self.W_query=nn.Linear(d_in, d_out, bias=qkv_bias)\n","        self.W_key=nn.Linear(d_in, d_out, bias=qkv_bias)\n","        self.W_value=nn.Linear(d_in, d_out, bias=qkv_bias)\n","        self.out_proj=nn.Linear(d_out, d_out) # Linear layer to combine head outputs\n","        self.dropout=nn.Dropout(dropout)\n","        self.register_buffer('mask', torch.triu(torch.ones(block_size, block_size), diagonal=1))\n","        \n","    def forward(self, x):\n","        b, num_tokens, d_in=x.shape\n","        \n","        keys=self.W_key(x) # Shape: (b, num_tokens, d_out)\n","        queries=self.W_query(x)\n","        values=self.W_value(x)\n","        \n","        # We implicity split the matrix by adding a `num_heads` dimension unroll last dimen: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n","        keys=keys.view(b, num_tokens, self.num_heads, self.head_dim)\n","        values=values.view(b, num_tokens, self.num_heads, self.head_dim)\n","        queries=queries.view(b, num_tokens, self.num_heads, self.head_dim)\n","        \n","        # transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n","        keys=keys.transpose(1,2)\n","        queries=queries.transpose(1,2)\n","        values=values.transpose(1,2)\n","        \n","        # compute scaled dot-product attention (aka self-attention) with a causal mask\n","        attn_scores=queries@keys.transpose(2,3) # Dot product for each head\n","        \n","        # original mask truncated to the number of tokens and converted to boolean\n","        mask_bool=self.mask.bool()[:num_tokens, :num_tokens]\n","        \n","        #unsqueeze the mask twice to match dimensions\n","        mask_unsqueezed=mask_bool.unsqueeze(0).unsqueeze(0)\n","        \n","        # use the unsqueezed mask to fill attention scores\n","        attn_scores.masked_fill_(mask_unsqueezed, -torch.inf)\n","        \n","        attn_weights=torch.softmax(attn_scores/keys.shape[-1]**0.5, dim=-1)\n","        attn_weights=self.dropout(attn_weights)\n","        \n","        #shape: (b, num_tokens, num_heads, head_dim)\n","        context_vec=(attn_weights@values).transpose(1,2)\n","        \n","        #combine heads, where self.d_out=self.num_heads * self.head_dim\n","        context_vec=context_vec.contiguous().view(b, num_tokens, self.d_out)\n","        context_vec=self.out_proj(context_vec) # optional projection\n","        \n","        return context_vec\n","\n","torch.manual_seed(123)\n","block_size=max_length\n","d_in=output_dim\n","d_out=d_in\n","\n","mha=MultiHeadAttention(d_in, d_out, block_size, 0.0, num_heads=2)\n","\n","batch=input_embeddings\n","context_vecs=mha(batch)\n","\n","print('context_vecs.shape:', context_vecs.shape)   "]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":19.789326,"end_time":"2024-02-24T05:37:51.903502","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-24T05:37:32.114176","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}