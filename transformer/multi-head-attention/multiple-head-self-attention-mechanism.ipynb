{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aisuko/multiple-head-self-attention-mechanism?scriptVersionId=164119992\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"795b16ef","metadata":{"papermill":{"duration":0.005665,"end_time":"2024-02-24T12:54:28.421596","exception":false,"start_time":"2024-02-24T12:54:28.415931","status":"completed"},"tags":[]},"source":["# Overview\n","\n","The Multiple Head Self Attention mechanism, which is a key component in Transformer models used in Natural Language Processing (NLP). In a nutshell, the Multi-Head Self Attention mechanism allows the model to focus on different positions of the input sequence, capturing various aspects of the information. **Multi-Head** means that the model has multiple sets of attention **heads**, allowing it to focus on different parts of the input for each head, thereby capturing a richer range of information."]},{"cell_type":"markdown","id":"0b1c0b13","metadata":{"papermill":{"duration":0.004391,"end_time":"2024-02-24T12:54:28.432087","exception":false,"start_time":"2024-02-24T12:54:28.427696","status":"completed"},"tags":[]},"source":["# Implement it with PyTorch"]},{"cell_type":"code","execution_count":1,"id":"86e2c21c","metadata":{"execution":{"iopub.execute_input":"2024-02-24T12:54:28.446248Z","iopub.status.busy":"2024-02-24T12:54:28.44565Z","iopub.status.idle":"2024-02-24T12:54:33.142132Z","shell.execute_reply":"2024-02-24T12:54:33.140733Z"},"papermill":{"duration":4.708013,"end_time":"2024-02-24T12:54:33.145755","exception":false,"start_time":"2024-02-24T12:54:28.437742","status":"completed"},"tags":[]},"outputs":[],"source":["from torch import nn\n","\n","class MultiHeadSelfAttention(nn.Module):\n","    def __init__(self, embed_size, num_heads):\n","        super(MultiHeadSelfAttention, self).__init__()\n","        self.embed_size=embed_size\n","        self.num_heads=num_heads\n","        self.head_dim=embed_size//num_heads\n","        \n","        assert(self.head_dim * num_heads==embed_size), \"Embedding size needs to be divisible by num_heads\"\n","        \n","        self.values=nn.Linear(self.head_dim, self.head_dim, bias=False)\n","        self.keys=nn.Linear(self.head_dim, self.head_dim, bias=False)\n","        self.queries=nn.Linear(self.head_dim, self.head_dim, bias=False)\n","        self.fc_out=nn.Linear(num_heads*self.head_dim, embed_size)\n","        \n","        self.layer_norm=nn.LayerNorm(embed_size) # Layer normalization\n","    \n","    def forward(self, values, keys, query, mask):\n","        N=query.shape[0]\n","        value_len,key_len,query_len=values.shape[1], keys.shape[1],query.shape[1]\n","        \n","        # Spliting the embedding into self.num_heads different pieces\n","        values=values.reshape(N, value_len, self.num_heads,self.head_dim)\n","        keys=keys.reshape(N, key_len,self.num_heads, self.head_dim)\n","        query=query.reshape(N, query_len, self.num_heads, self.head_dim)\n","        \n","        values=self.values(values)\n","        keys=self.keys(keys)\n","        queries=self.queries(query)\n","        \n","        # Get the dot product between queries and keys, and apply mask\n","        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n","        if mask is not None:\n","            energy =energy.masked_fill(mask==0, float(\"-1e20\"))\n","        attention = torch.softmax(energy/(self.embed_size ** (1/2)), dim=3)\n","        \n","        out=torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(N, query_len, self.num_heads*self.head_dim)\n","        \n","        out=self.fc_out(out)\n","        \n","        # Applying layer normalization\n","        out=self.layer_norm(out)\n","        return out"]},{"cell_type":"markdown","id":"98032ff0","metadata":{"papermill":{"duration":0.004074,"end_time":"2024-02-24T12:54:33.154395","exception":false,"start_time":"2024-02-24T12:54:33.150321","status":"completed"},"tags":[]},"source":["# Testing the Multi-Head Self Attention"]},{"cell_type":"code","execution_count":2,"id":"9579ce10","metadata":{"execution":{"iopub.execute_input":"2024-02-24T12:54:33.168227Z","iopub.status.busy":"2024-02-24T12:54:33.166314Z","iopub.status.idle":"2024-02-24T12:54:33.685732Z","shell.execute_reply":"2024-02-24T12:54:33.684482Z"},"papermill":{"duration":0.529532,"end_time":"2024-02-24T12:54:33.688845","exception":false,"start_time":"2024-02-24T12:54:33.159313","status":"completed"},"tags":[]},"outputs":[],"source":["import torch\n","\n","def test_multi_head_self_attention():\n","    batch_size=64\n","    sequence_length=100\n","    embed_size=512\n","    num_heads=8\n","    \n","    # Create a MultiheadSelfAttention instance\n","    attention = MultiHeadSelfAttention(embed_size, num_heads)\n","    \n","    # Create some random data to use as input\n","    values=torch.randn(batch_size, sequence_length, embed_size)\n","    keys=torch.randn(batch_size, sequence_length, embed_size)\n","    query=torch.randn(batch_size, sequence_length, embed_size)\n","    \n","    # Create a random mask\n","    mask=torch.randint(0,2,(batch_size,1,1,sequence_length)).to(torch.bool)\n","    \n","    # Pass the data through the attention mechanism\n","    out=attention(values, keys, query, mask)\n","    \n","    # Check that the output has the right shape\n","    assert out.shape==(batch_size, sequence_length, embed_size),\"Output shape is incorrect\"\n","    \n","test_multi_head_self_attention()"]},{"cell_type":"markdown","id":"b8f60ed5","metadata":{"papermill":{"duration":0.004164,"end_time":"2024-02-24T12:54:33.69829","exception":false,"start_time":"2024-02-24T12:54:33.694126","status":"completed"},"tags":[]},"source":["# A Linear Transformation\n","\n","A linear transformatin typically refers to a transformation of the input data using a set of weights and potentially biases. This is often represented manthematically as `y=Wx+b`, where `W` is the weight matrix, `x` is the input data, `b` is the bias, and `y` is the output data."]},{"cell_type":"code","execution_count":3,"id":"9a142f6d","metadata":{"execution":{"iopub.execute_input":"2024-02-24T12:54:33.709292Z","iopub.status.busy":"2024-02-24T12:54:33.708825Z","iopub.status.idle":"2024-02-24T12:54:33.74383Z","shell.execute_reply":"2024-02-24T12:54:33.742692Z"},"papermill":{"duration":0.043886,"end_time":"2024-02-24T12:54:33.746869","exception":false,"start_time":"2024-02-24T12:54:33.702983","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0.2439, -0.1287, -0.0315, -1.3184,  0.7279],\n","        [-0.8809,  0.8527, -1.2368,  1.0713,  1.9605],\n","        [-1.9387, -1.7888, -0.0498,  0.7842, -0.8771],\n","        [ 0.0944, -2.0787,  1.4073,  0.5511, -0.1695],\n","        [-1.3802,  0.5898, -0.8544,  0.7628, -1.7508],\n","        [-0.0255, -0.9585, -0.1014, -0.0206,  0.1431],\n","        [-0.0028, -1.9332, -0.9490,  1.3220,  0.7912],\n","        [-1.2679, -1.9436, -0.7273, -1.1826,  0.7140],\n","        [-0.0336,  0.6147, -0.6111, -0.8465,  0.2832],\n","        [ 0.3057, -0.8951,  1.0789,  0.1866, -1.6518]])\n","tensor([[-0.4170, -0.4357,  0.6642],\n","        [ 0.0235, -0.9622, -0.1988],\n","        [ 0.6236,  0.8460, -0.0572],\n","        [-0.0265,  0.6817,  0.1711],\n","        [ 1.4543, -0.1226,  0.3021],\n","        [ 0.0364, -0.0507,  0.3718],\n","        [ 0.0096, -0.0601, -0.0108],\n","        [-0.5574,  0.3546,  0.3470],\n","        [ 0.0921, -0.6850,  0.6240],\n","        [ 0.7344,  0.3885,  0.5738]], grad_fn=<AddmmBackward0>)\n"]}],"source":["# Define a linear layer with 5 input features and 3 output features\n","linear_layer = nn.Linear(in_features=5, out_features=3)\n","\n","# Now the linear layer can be used with input of size [batch_size, num_features]\n","input_tensor = torch.randn(10, 5)\n","output = linear_layer(input_tensor)\n","\n","print(input_tensor)\n","print(output)"]},{"cell_type":"markdown","id":"3b836a7c","metadata":{"papermill":{"duration":0.004145,"end_time":"2024-02-24T12:54:33.755827","exception":false,"start_time":"2024-02-24T12:54:33.751682","status":"completed"},"tags":[]},"source":["The weights and bias of the linear layer are automatically initialized and are kept as parameters of the layer, we can access them with below"]},{"cell_type":"code","execution_count":4,"id":"69103390","metadata":{"execution":{"iopub.execute_input":"2024-02-24T12:54:33.767686Z","iopub.status.busy":"2024-02-24T12:54:33.767158Z","iopub.status.idle":"2024-02-24T12:54:33.776862Z","shell.execute_reply":"2024-02-24T12:54:33.774941Z"},"papermill":{"duration":0.019682,"end_time":"2024-02-24T12:54:33.779973","exception":false,"start_time":"2024-02-24T12:54:33.760291","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Parameter containing:\n","tensor([[-0.0537,  0.1790, -0.0896,  0.2578, -0.4216],\n","        [-0.2518, -0.3187,  0.2433, -0.0111, -0.1438],\n","        [ 0.1896,  0.0263, -0.0685, -0.2402, -0.1494]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2631, -0.3176,  0.4113], requires_grad=True)\n"]}],"source":["print(linear_layer.weight)\n","print(linear_layer.bias)"]},{"cell_type":"markdown","id":"2678f087","metadata":{"papermill":{"duration":0.004303,"end_time":"2024-02-24T12:54:33.789115","exception":false,"start_time":"2024-02-24T12:54:33.784812","status":"completed"},"tags":[]},"source":["# `torch.einsum` function\n","\n","It is a very powerful function that allows you to perform operation on tensor in a very flexible way. The `String(nqhd,nkhd->nhqk)` argument to `einsum` specifies the operation in a compact way.\n","\n","* \"nqhd,nkhd\": This part before the -> describes the dimensions of the input tensors.\n","* \"->nhqk\": This part after the -> describes the dimensions of the output tensor.\n","\n","The operation performed by `einsum` in this case is a sum-product over the shared dimension $h$ (the last dimension of the first tensor and the third dimension of the second tensor). This is equivalent to calculating the dot product between the `queries` and `keys` tensors along the $h$ dimension, resulting in a new tensor with dimensions represented by `nhqk`.\n","\n","\n","# The Softmax Function\n","\n","It is used to `convert a vector of real numbers into a probability distribution`. That is, after applying softmax, each element of the output vector will be in the range(0,1), and the sum of the elements will be 1. The softmax funciton is defined as follows:\n","\n","$$Softmax(x_i) = \\frac{exp(x_i)}{\\Sigma_{j}(exp(x_j))}$$\n","\n","Where:\n","\n","* $x_i$ is the i-th element of the input vector\n","* $exp$ is the exponential function\n","* The denominator $\\Sigma_{j}(exp(x_j))$ is the sum of the exponential of each element $x_j$ in the input vector"]},{"cell_type":"code","execution_count":5,"id":"cb03dd6f","metadata":{"execution":{"iopub.execute_input":"2024-02-24T12:54:33.802328Z","iopub.status.busy":"2024-02-24T12:54:33.801879Z","iopub.status.idle":"2024-02-24T12:54:33.811389Z","shell.execute_reply":"2024-02-24T12:54:33.809486Z"},"papermill":{"duration":0.020138,"end_time":"2024-02-24T12:54:33.814495","exception":false,"start_time":"2024-02-24T12:54:33.794357","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0.0900, 0.2447, 0.6652])\n"]}],"source":["import torch.nn.functional as F\n","\n","# a tensor\n","x=torch.tensor([1.0,2.0,3.0])\n","\n","# apply softmax\n","y=F.softmax(x, dim=0)\n","\n","print(y)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30579,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":11.490098,"end_time":"2024-02-24T12:54:34.848831","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-24T12:54:23.358733","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}