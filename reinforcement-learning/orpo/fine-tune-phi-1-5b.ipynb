{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install -U -q transformers==4.39.3\n!pip install -U -q accelerate==0.28.0\n!pip install -U -q datasets==2.18.0\n# !pip install -U -q peft==0.10.0\n!pip install -U -q bitsandbytes==0.43.1\n!pip install -U -q trl==0.8.6","metadata":{"execution":{"iopub.status.busy":"2024-06-24T11:18:39.744296Z","iopub.execute_input":"2024-06-24T11:18:39.744654Z","iopub.status.idle":"2024-06-24T11:20:00.784403Z","shell.execute_reply.started":"2024-06-24T11:18:39.744628Z","shell.execute_reply":"2024-06-24T11:20:00.783217Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.4.1 requires cubinlinker, which is not installed.\ncudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.4.1 requires ptxcompiler, which is not installed.\ncuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ndistributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\ngcsfs 2024.3.1 requires fsspec==2024.3.1, but you have fsspec 2024.2.0 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\ns3fs 2024.3.1 requires fsspec==2024.3.1, but you have fsspec 2024.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import warnings\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-06-24T11:20:00.786450Z","iopub.execute_input":"2024-06-24T11:20:00.786749Z","iopub.status.idle":"2024-06-24T11:20:00.791064Z","shell.execute_reply.started":"2024-06-24T11:20:00.786722Z","shell.execute_reply":"2024-06-24T11:20:00.790424Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nlogin(token=user_secrets.get_secret(\"HUGGINGFACE_TOKEN\"))\n\nos.environ[\"WANDB_API_KEY\"]=user_secrets.get_secret(\"WANDB_API_KEY\")\nos.environ[\"WANDB_PROJECT\"] = \"Fine-tuning phi3-mini-128k-instruct\"\nos.environ[\"WANDB_NAME\"] = \"ft-phi3-mini-long-context-instruct\"\nos.environ[\"MODEL_NAME\"] = \"microsoft/Phi-3-mini-128k-instruct\"\nos.environ[\"DATASET\"] = \"HuggingFaceH4/ultrafeedback_binarized\"","metadata":{"execution":{"iopub.status.busy":"2024-06-24T11:20:00.792396Z","iopub.execute_input":"2024-06-24T11:20:00.792655Z","iopub.status.idle":"2024-06-24T11:20:01.726464Z","shell.execute_reply.started":"2024-06-24T11:20:00.792634Z","shell.execute_reply":"2024-06-24T11:20:01.725578Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer=AutoTokenizer.from_pretrained(\n    os.getenv(\"MODEL_NAME\"),\n    add_eos_token=True,\n    use_fast=True\n)\n\ntokenizer.pad_token=tokenizer.eos_token\ntokenizer.padding_side=\"left\"","metadata":{"execution":{"iopub.status.busy":"2024-06-24T11:21:41.586528Z","iopub.execute_input":"2024-06-24T11:21:41.587503Z","iopub.status.idle":"2024-06-24T11:21:43.226170Z","shell.execute_reply.started":"2024-06-24T11:21:41.587461Z","shell.execute_reply":"2024-06-24T11:21:43.225260Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8aa2eb9a7aef40a0aef7b0c72d11dda8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a42057658b6d4a9fade38cb0a066c1a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2294c476e5a487bb5b50f36f2c513f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e45fdc23d10d4a2189da2d080cf934c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/568 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c85e519ebb124ecdbcd7d420a3dd8236"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\n\nds=load_dataset(os.getenv(\"DATASET\"), split=[\"train_prefs\",\"test_prefs\"])\nds","metadata":{"execution":{"iopub.status.busy":"2024-06-24T11:21:47.154781Z","iopub.execute_input":"2024-06-24T11:21:47.155139Z","iopub.status.idle":"2024-06-24T11:22:04.483532Z","shell.execute_reply.started":"2024-06-24T11:21:47.155110Z","shell.execute_reply":"2024-06-24T11:22:04.482624Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/6.77k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f55e05f5fba44319972da1001aa40abb"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 226M/226M [00:01<00:00, 142MB/s]  \nDownloading data: 100%|██████████| 226M/226M [00:00<00:00, 233MB/s]  \nDownloading data: 100%|██████████| 7.29M/7.29M [00:00<00:00, 30.2MB/s]\nDownloading data: 100%|██████████| 3.72M/3.72M [00:00<00:00, 15.3MB/s]\nDownloading data: 100%|██████████| 184M/184M [00:00<00:00, 221MB/s]  \nDownloading data: 100%|██████████| 3.02M/3.02M [00:00<00:00, 13.2MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train_prefs split:   0%|          | 0/61135 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88e7681f56304143b33d0c3f9360c0a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train_sft split:   0%|          | 0/61135 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71990416fe8347a39d8e4457721fa218"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test_prefs split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a3fa4fa291449c8affb5b10befa3df8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test_sft split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11b428eb20d24c85914398aefcd2f596"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train_gen split:   0%|          | 0/61135 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e270881d797c4377a7e1be755c116276"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test_gen split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b9181358b834aeebf8f3864a7b0645e"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"[Dataset({\n     features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected'],\n     num_rows: 61135\n }),\n Dataset({\n     features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected'],\n     num_rows: 2000\n })]"},"metadata":{}}]},{"cell_type":"code","source":"train_ds=ds[0].shuffle(seed=42).select(range(300))\neval_ds=ds[1].shuffle(seed=42).select(range(100))","metadata":{"execution":{"iopub.status.busy":"2024-06-24T11:22:04.485051Z","iopub.execute_input":"2024-06-24T11:22:04.485500Z","iopub.status.idle":"2024-06-24T11:22:04.733399Z","shell.execute_reply.started":"2024-06-24T11:22:04.485474Z","shell.execute_reply":"2024-06-24T11:22:04.732663Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import torch, multiprocessing\n\ndef preprocess(x):\n    x[\"chosen\"]=tokenizer.apply_chat_template(x[\"chosen\"], tokenize=False)\n    x[\"rejected\"]=tokenizer.apply_chat_template(x[\"rejected\"], tokenize=False)\n    return x\n\ntrain_ds=train_ds.map(preprocess, num_proc=multiprocessing.cpu_count(), load_from_cache_file=False)\neval_ds=eval_ds.map(preprocess, num_proc=multiprocessing.cpu_count(), load_from_cache_file=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T11:22:04.734391Z","iopub.execute_input":"2024-06-24T11:22:04.734631Z","iopub.status.idle":"2024-06-24T11:22:05.508315Z","shell.execute_reply.started":"2024-06-24T11:22:04.734609Z","shell.execute_reply":"2024-06-24T11:22:05.507323Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/300 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69448dae748b456ba298cb78dfe38436"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc7a4fac4a8e4172a6f8f77e2e02ce59"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\n\nmodel=AutoModelForCausalLM.from_pretrained(\n    os.getenv(\"MODEL_NAME\"),\n    torch_dtype=torch.float16,\n    device_map={\"\": 0},\n#     device_map=\"cuda\",\n    trust_remote_code=True\n)\n\nmodel.gradient_checkpointing_enable()\nmodel.device","metadata":{"execution":{"iopub.status.busy":"2024-06-24T11:22:05.510517Z","iopub.execute_input":"2024-06-24T11:22:05.510847Z","iopub.status.idle":"2024-06-24T11:22:41.123073Z","shell.execute_reply.started":"2024-06-24T11:22:05.510814Z","shell.execute_reply":"2024-06-24T11:22:41.122174Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed61ddd57051437f8d0e7cb84bef4d69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_phi3.py:   0%|          | 0.00/10.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd7d4c64553842c1961b2b14d5e78b71"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n- configuration_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_phi3.py:   0%|          | 0.00/73.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52b7f5ffa6a246529c0b7add9422f67c"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n- modeling_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e7366d6a67744d6a4d9fa4953191678"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19126d6769194c799171a2edf02fd33a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d8d104eb8d54c0781df22090d3d5a4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"794b9cf400514e158f23e508db36ddfb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e74e439e04e64ed2b42054dd16fe5378"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/172 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5932798bb26743d38c07dd1dedaee080"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"code","source":"from trl import ORPOTrainer, ORPOConfig\n\norpo_config=ORPOConfig(\n    output_dir=os.getenv(\"WANDB_NAME\"),\n    evaluation_strategy=\"steps\",\n    do_eval=True,\n    optim=\"adamw_8bit\",\n    per_device_train_batch_size=8,\n    gradient_accumulation_steps=2,\n    per_device_eval_batch_size=8,\n    log_level=\"debug\",\n    logging_steps=100,\n    learning_rate=8e-6,\n    eval_steps=100,\n    save_steps=100,\n    save_strategy=\"epoch\",\n    num_train_epochs=1,\n    warmup_ratio=0.1,\n    lr_scheduler_type=\"linear\",\n    beta=0.1, # beta is ORPO's lambda\n    max_length=1024,\n    report_to=\"wandb\",\n    run_name=os.getenv('WANDB_NAME')\n)\n\ntrainer = ORPOTrainer(\n        model=model,\n        train_dataset=train_ds,\n        eval_dataset=eval_ds,\n        args=orpo_config,\n        tokenizer=tokenizer,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-24T11:22:41.124379Z","iopub.execute_input":"2024-06-24T11:22:41.124966Z","iopub.status.idle":"2024-06-24T11:23:34.504971Z","shell.execute_reply.started":"2024-06-24T11:22:41.124940Z","shell.execute_reply":"2024-06-24T11:23:34.503345Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"2024-06-24 11:22:43.369347: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-24 11:22:43.369447: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-24 11:22:43.492230: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/300 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27bb924919af4aa1893820cd083707c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fda45b614ddd47baab2611260a829f96"}},"metadata":{}},{"name":"stderr","text":"Currently training with a batch size of: 8\n***** Running training *****\n  Num examples = 300\n  Num Epochs = 1\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 16\n  Gradient Accumulation steps = 2\n  Total optimization steps = 19\n  Number of trainable parameters = 3,821,079,552\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33murakiny\u001b[0m (\u001b[33mcausal_language_trainer\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240624_112301-5lku14nf</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/causal_language_trainer/Fine-tuning%20phi3-mini-128k-instruct/runs/5lku14nf' target=\"_blank\">ft-phi3-mini-long-context-instruct</a></strong> to <a href='https://wandb.ai/causal_language_trainer/Fine-tuning%20phi3-mini-128k-instruct' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/causal_language_trainer/Fine-tuning%20phi3-mini-128k-instruct' target=\"_blank\">https://wandb.ai/causal_language_trainer/Fine-tuning%20phi3-mini-128k-instruct</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/causal_language_trainer/Fine-tuning%20phi3-mini-128k-instruct/runs/5lku14nf' target=\"_blank\">https://wandb.ai/causal_language_trainer/Fine-tuning%20phi3-mini-128k-instruct/runs/5lku14nf</a>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 34\u001b[0m\n\u001b[1;32m      3\u001b[0m orpo_config\u001b[38;5;241m=\u001b[39mORPOConfig(\n\u001b[1;32m      4\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWANDB_NAME\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      5\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     run_name\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWANDB_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m trainer \u001b[38;5;241m=\u001b[39m ORPOTrainer(\n\u001b[1;32m     27\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     28\u001b[0m         train_dataset\u001b[38;5;241m=\u001b[39mtrain_ds,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m         tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     32\u001b[0m )\n\u001b[0;32m---> 34\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1780\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1778\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2118\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2117\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2118\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2121\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2122\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2123\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2124\u001b[0m ):\n\u001b[1;32m   2125\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2126\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3036\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3033\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3035\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3036\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3038\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3039\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trl/trainer/orpo_trainer.py:786\u001b[0m, in \u001b[0;36mORPOTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m    783\u001b[0m compute_loss_context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_peft_has_been_casted_to_bf16 \u001b[38;5;28;01melse\u001b[39;00m nullcontext\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m compute_loss_context_manager():\n\u001b[0;32m--> 786\u001b[0m     loss, metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_loss_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# force log the metrics\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore_metrics(metrics, train_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trl/trainer/orpo_trainer.py:746\u001b[0m, in \u001b[0;36mORPOTrainer.get_batch_loss_metrics\u001b[0;34m(self, model, batch, train_eval)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the ORPO loss and other metrics for the given batch of inputs for train or test.\"\"\"\u001b[39;00m\n\u001b[1;32m    738\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    740\u001b[0m (\n\u001b[1;32m    741\u001b[0m     policy_chosen_logps,\n\u001b[1;32m    742\u001b[0m     policy_rejected_logps,\n\u001b[1;32m    743\u001b[0m     policy_chosen_logits,\n\u001b[1;32m    744\u001b[0m     policy_rejected_logits,\n\u001b[1;32m    745\u001b[0m     policy_nll_loss,\n\u001b[0;32m--> 746\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenated_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    748\u001b[0m losses, chosen_rewards, rejected_rewards, log_odds_ratio, log_odds_chosen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39modds_ratio_loss(\n\u001b[1;32m    749\u001b[0m     policy_chosen_logps, policy_rejected_logps\n\u001b[1;32m    750\u001b[0m )\n\u001b[1;32m    751\u001b[0m \u001b[38;5;66;03m# full ORPO loss\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trl/trainer/orpo_trainer.py:715\u001b[0m, in \u001b[0;36mORPOTrainer.concatenated_forward\u001b[0;34m(self, model, batch)\u001b[0m\n\u001b[1;32m    711\u001b[0m     labels \u001b[38;5;241m=\u001b[39m concatenated_batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcatenated_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    713\u001b[0m chosen_nll_loss \u001b[38;5;241m=\u001b[39m cross_entropy_loss(all_logits[:len_chosen], labels[:len_chosen])\n\u001b[0;32m--> 715\u001b[0m all_logps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_logps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcatenated_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconcatenated_labels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43maverage_log_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_encoder_decoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_encoder_decoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_pad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_pad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m chosen_logps \u001b[38;5;241m=\u001b[39m all_logps[:len_chosen]\n\u001b[1;32m    724\u001b[0m rejected_logps \u001b[38;5;241m=\u001b[39m all_logps[len_chosen:]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trl/trainer/orpo_trainer.py:655\u001b[0m, in \u001b[0;36mORPOTrainer.get_batch_logps\u001b[0;34m(logits, labels, average_log_prob, label_pad_token_id, is_encoder_decoder)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;66;03m# dummy token; we'll ignore the losses on these tokens later\u001b[39;00m\n\u001b[1;32m    653\u001b[0m labels[labels \u001b[38;5;241m==\u001b[39m label_pad_token_id] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 655\u001b[0m per_token_logps \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mgather(\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_softmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, index\u001b[38;5;241m=\u001b[39mlabels\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average_log_prob:\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (per_token_logps \u001b[38;5;241m*\u001b[39m loss_mask)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m loss_mask\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 15.89 GiB of which 1.28 GiB is free. Process 1973 has 14.62 GiB memory in use. Of the allocated memory 13.62 GiB is allocated by PyTorch, and 728.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacty of 15.89 GiB of which 1.28 GiB is free. Process 1973 has 14.62 GiB memory in use. Of the allocated memory 13.62 GiB is allocated by PyTorch, and 728.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]},{"cell_type":"code","source":"kwargs={\n    'model_name': os.getenv(\"WANDB_NAME\"),\n    'finetuned_from': os.getenv('MODEL_NAME'),\n#     'tasks': '',\n#     'dataset_tags':'',\n    'dataset': os.getenv(\"DATASET\")\n}\n\ntokenizer.push_to_hub(os.getenv(\"WANDB_NAME\"))\ntrainer.push_to_hub(**kwargs)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Credit\n\n* https://huggingface.co/microsoft/phi-1_5\n* https://huggingface.co/microsoft/phi-2\n* https://huggingface.co/microsoft/phi-1","metadata":{}}]}