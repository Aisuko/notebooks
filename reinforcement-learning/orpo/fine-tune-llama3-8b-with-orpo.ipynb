{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aisuko/fine-tune-llama3-with-orpo?scriptVersionId=185163732\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Overview\n\nORPO is a new exciting fine-tuning technique that combines that traditional supervised fine-tuning and preference alignement stagaes into a single process. This reduces the computational resources and time required for training. Moreover, empirical results demonstrate that ORPO outperforms other alignment methods on various model size and benchmarks.\n\nWe will fine-tune the Llama 3 model 8B model using ORPO with the TRL library.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install -U -q transformers==4.39.3\n!pip install -U -q accelerate==0.28.0\n!pip install -U -q datasets==2.18.0\n!pip install -U -q peft==0.10.0\n!pip install -U -q bitsandbytes==0.43.1\n!pip install -U -q trl==0.8.6","metadata":{"execution":{"iopub.status.busy":"2024-06-24T07:32:41.033793Z","iopub.execute_input":"2024-06-24T07:32:41.034191Z","iopub.status.idle":"2024-06-24T07:33:57.905615Z","shell.execute_reply.started":"2024-06-24T07:32:41.03416Z","shell.execute_reply":"2024-06-24T07:33:57.904333Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Note: If your env suports flash attention, be sure installed it.","metadata":{}},{"cell_type":"code","source":"import torch\n\nif torch.cuda.get_device_capability()[0] >= 8:\n    !pip install -qqq flash-attn\n    attn_implementation = \"flash_attention_2\"\n    torch_dtype = torch.bfloat16\nelse:\n    attn_implementation = \"eager\"\n    torch_dtype = torch.float16","metadata":{"execution":{"iopub.status.busy":"2024-06-24T07:33:57.907731Z","iopub.execute_input":"2024-06-24T07:33:57.90806Z","iopub.status.idle":"2024-06-24T07:33:59.77834Z","shell.execute_reply.started":"2024-06-24T07:33:57.90803Z","shell.execute_reply":"2024-06-24T07:33:59.777462Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nlogin(token=user_secrets.get_secret(\"HUGGINGFACE_TOKEN\"))\n\nos.environ[\"WANDB_API_KEY\"]=user_secrets.get_secret(\"WANDB_API_KEY\")\nos.environ[\"WANDB_PROJECT\"] = \"Fine-tuning Llama 3 8B\"\nos.environ[\"WANDB_NAME\"] = \"ft-Llama3-8b-orpo\"\nos.environ[\"MODEL_NAME\"] = \"meta-llama/Meta-Llama-3-8B\"\nos.environ[\"DATASET\"] = \"mlabonne/orpo-dpo-mix-40k\"\n\ntorch.backends.cudnn.deterministic=True\n# https://github.com/huggingface/transformers/issues/28731\ntorch.backends.cuda.enable_mem_efficient_sdp(False)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T07:33:59.779605Z","iopub.execute_input":"2024-06-24T07:33:59.78011Z","iopub.status.idle":"2024-06-24T07:34:01.954568Z","shell.execute_reply.started":"2024-06-24T07:33:59.780074Z","shell.execute_reply":"2024-06-24T07:34:01.953749Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"!accelerate estimate-memory ${MODEL_NAME} --library_name transformers","metadata":{"execution":{"iopub.status.busy":"2024-06-24T07:34:01.95585Z","iopub.execute_input":"2024-06-24T07:34:01.956228Z","iopub.status.idle":"2024-06-24T07:34:09.978745Z","shell.execute_reply.started":"2024-06-24T07:34:01.956192Z","shell.execute_reply":"2024-06-24T07:34:09.977692Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Loading pretrained config for `meta-llama/Meta-Llama-3-8B` from `transformers`...\n┌──────────────────────────────────────────────────────┐\n│Memory Usage for loading `meta-llama/Meta-Llama-3-8B` │\n├───────┬─────────────┬──────────┬─────────────────────┤\n│ dtype │Largest Layer│Total Size│ Training using Adam │\n├───────┼─────────────┼──────────┼─────────────────────┤\n│float32│   1.96 GB   │ 28.21 GB │      112.83 GB      │\n│float16│  1002.0 MB  │ 14.1 GB  │       56.42 GB      │\n│  int8 │   501.0 MB  │ 7.05 GB  │       28.21 GB      │\n│  int4 │   250.5 MB  │ 3.53 GB  │       14.1 GB       │\n└───────┴─────────────┴──────────┴─────────────────────┘\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Quantization with QLoRA","metadata":{}},{"cell_type":"code","source":"from transformers import BitsAndBytesConfig\nfrom peft import LoraConfig\n\nbnb_config=BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch_dtype,\n    bnb_4bit_use_double_quant=True\n#     llm_int8_enable_fp32_cpu_offload=True\n)\n\npeft_config=LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T07:34:09.981626Z","iopub.execute_input":"2024-06-24T07:34:09.98199Z","iopub.status.idle":"2024-06-24T07:34:11.532906Z","shell.execute_reply.started":"2024-06-24T07:34:09.981957Z","shell.execute_reply":"2024-06-24T07:34:11.532023Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer=AutoTokenizer.from_pretrained(os.getenv('MODEL_NAME'))","metadata":{"execution":{"iopub.status.busy":"2024-06-24T07:34:11.534097Z","iopub.execute_input":"2024-06-24T07:34:11.534548Z","iopub.status.idle":"2024-06-24T07:34:12.313303Z","shell.execute_reply.started":"2024-06-24T07:34:11.534519Z","shell.execute_reply":"2024-06-24T07:34:12.312329Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\n\nmodel=AutoModelForCausalLM.from_pretrained(\n    os.getenv('MODEL_NAME'),\n    quantization_config=bnb_config,\n    # https://github.com/huggingface/trl/issues/1571#issuecomment-2075404536\n    # https://github.com/xfactlab/orpo/issues/18\n    device_map={\"\":0},\n    torch_dtype=torch_dtype\n#     attn_implementation=attn_implementation\n)\n\nmodel.device","metadata":{"execution":{"iopub.status.busy":"2024-06-24T07:34:12.314737Z","iopub.execute_input":"2024-06-24T07:34:12.315046Z","iopub.status.idle":"2024-06-24T07:35:27.09856Z","shell.execute_reply.started":"2024-06-24T07:34:12.315018Z","shell.execute_reply":"2024-06-24T07:35:27.097566Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b00efa733b44c108c164c2fbc5e150d"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    trainable_params=0\n    all_params=0\n    for _, param in model.named_parameters():\n        all_params+=param.numel()\n        if param.requires_grad:\n            trainable_params+=param.numel()\n    print(f\"trainable params: {trainable_params} || all params: {all_params} || trainable%: {100 * trainable_params/all_params:.2f}\")\n\nprint_trainable_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T07:35:27.099915Z","iopub.execute_input":"2024-06-24T07:35:27.100297Z","iopub.status.idle":"2024-06-24T07:35:27.109738Z","shell.execute_reply.started":"2024-06-24T07:35:27.100262Z","shell.execute_reply":"2024-06-24T07:35:27.108807Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"trainable params: 1050939392 || all params: 4540600320 || trainable%: 23.15\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Set chat format and feeze pretrained weights","metadata":{}},{"cell_type":"code","source":"from trl import setup_chat_format\nfrom peft import prepare_model_for_kbit_training\n\nmodel, tokenizer=setup_chat_format(model, tokenizer)\n\nmodel=prepare_model_for_kbit_training(model)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T07:35:27.111059Z","iopub.execute_input":"2024-06-24T07:35:27.111473Z","iopub.status.idle":"2024-06-24T07:35:27.229318Z","shell.execute_reply.started":"2024-06-24T07:35:27.111431Z","shell.execute_reply":"2024-06-24T07:35:27.228285Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print_trainable_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T07:35:27.23062Z","iopub.execute_input":"2024-06-24T07:35:27.230892Z","iopub.status.idle":"2024-06-24T07:35:27.237728Z","shell.execute_reply.started":"2024-06-24T07:35:27.230869Z","shell.execute_reply":"2024-06-24T07:35:27.236882Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"trainable params: 0 || all params: 4540616704 || trainable%: 0.00\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Loading Dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Note: if you have enough computing resource, please considering use all data for your training.\n# ds=load_dataset(os.getenv('DATASET'), split='all')\n# ds=ds.shuffle(seed=42).select(range(1000))\n\n\nds=load_dataset(os.getenv('DATASET'), split='train[:300]')\nds","metadata":{"execution":{"iopub.status.busy":"2024-06-24T07:35:27.239128Z","iopub.execute_input":"2024-06-24T07:35:27.239432Z","iopub.status.idle":"2024-06-24T07:35:32.79231Z","shell.execute_reply.started":"2024-06-24T07:35:27.239402Z","shell.execute_reply":"2024-06-24T07:35:32.791423Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['source', 'chosen', 'rejected', 'prompt', 'question'],\n    num_rows: 300\n})"},"metadata":{}}]},{"cell_type":"code","source":"ds=ds.shuffle(seed=42)\n\ndef format_chat_template(row):\n    row[\"chosen\"] = tokenizer.apply_chat_template(row[\"chosen\"], tokenize=False)\n    row[\"rejected\"] = tokenizer.apply_chat_template(row[\"rejected\"], tokenize=False)\n    return row\n\nds=ds.map(format_chat_template, num_proc=os.cpu_count())","metadata":{"execution":{"iopub.status.busy":"2024-06-24T07:35:32.793744Z","iopub.execute_input":"2024-06-24T07:35:32.794892Z","iopub.status.idle":"2024-06-24T07:35:33.057679Z","shell.execute_reply.started":"2024-06-24T07:35:32.794853Z","shell.execute_reply":"2024-06-24T07:35:33.056652Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"ds=ds.train_test_split(test_size=0.01)\nds","metadata":{"execution":{"iopub.status.busy":"2024-06-24T07:35:33.05891Z","iopub.execute_input":"2024-06-24T07:35:33.059187Z","iopub.status.idle":"2024-06-24T07:35:33.085316Z","shell.execute_reply.started":"2024-06-24T07:35:33.059162Z","shell.execute_reply":"2024-06-24T07:35:33.084425Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['source', 'chosen', 'rejected', 'prompt', 'question'],\n        num_rows: 297\n    })\n    test: Dataset({\n        features: ['source', 'chosen', 'rejected', 'prompt', 'question'],\n        num_rows: 3\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Fine-tuning\n\nWe need to set a few hyperparameter for ORPO configuration.\n\n### learning_rate\n\nORPO uses very low learning rates compared to traditinal SFT or even DPO. This value of 8e-6 comes from the original paper. SFT is 1e-5, DPO is 5e-6.\n\n### beta\n\nIt is the $\\lambda\\$ parameter in the paper, with the default value of 0.1\n\n### max_lengthm batch_size\n\nOther parameters, like `max_length` and batch size are set to use as much VRAM as avaliable(~20 GB).","metadata":{}},{"cell_type":"code","source":"from trl import ORPOConfig, ORPOTrainer\n\n# https://github.com/huggingface/trl/blob/v0.8.6/trl/trainer/orpo_config.py\norpo_args=ORPOConfig(\n    learning_rate=8e-6,\n    beta=0.1,\n    lr_scheduler_type=\"linear\",\n    max_length=1024,\n    max_prompt_length=512,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    gradient_accumulation_steps=4,\n    optim=\"paged_adamw_8bit\",\n    num_train_epochs=1,\n    evaluation_strategy=\"steps\",\n    eval_steps=0.2,\n    logging_steps=1,\n    warmup_steps=10,\n    report_to=\"wandb\",\n    run_name=os.getenv('WANDB_NAME'),\n    output_dir=os.getenv('WANDB_NAME')\n)\n\ntrainer=ORPOTrainer(\n    model=model,\n    args=orpo_args,\n    train_dataset=ds[\"train\"],\n    eval_dataset=ds[\"test\"],\n    peft_config=peft_config,\n    tokenizer=tokenizer\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-24T07:35:33.089413Z","iopub.execute_input":"2024-06-24T07:35:33.089758Z","iopub.status.idle":"2024-06-24T07:36:15.293162Z","shell.execute_reply.started":"2024-06-24T07:35:33.089725Z","shell.execute_reply":"2024-06-24T07:36:15.291245Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"2024-06-24 07:35:35.517796: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-24 07:35:35.517921: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-24 07:35:35.644188: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/trl/trainer/orpo_trainer.py:247: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/297 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c09166805a84451a57655917f59605e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3c94a8f51b040ff9498dbd2dcefd9a5"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33murakiny\u001b[0m (\u001b[33mcausal_language_trainer\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240624_073546-mqzebl4y</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/causal_language_trainer/Fine-tuning%20Llama%203%208B/runs/mqzebl4y' target=\"_blank\">ft-Llama3-8b-orpo</a></strong> to <a href='https://wandb.ai/causal_language_trainer/Fine-tuning%20Llama%203%208B' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/causal_language_trainer/Fine-tuning%20Llama%203%208B' target=\"_blank\">https://wandb.ai/causal_language_trainer/Fine-tuning%20Llama%203%208B</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/causal_language_trainer/Fine-tuning%20Llama%203%208B/runs/mqzebl4y' target=\"_blank\">https://wandb.ai/causal_language_trainer/Fine-tuning%20Llama%203%208B/runs/mqzebl4y</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 33\u001b[0m\n\u001b[1;32m      4\u001b[0m orpo_args\u001b[38;5;241m=\u001b[39mORPOConfig(\n\u001b[1;32m      5\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8e-6\u001b[39m,\n\u001b[1;32m      6\u001b[0m     beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWANDB_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m trainer\u001b[38;5;241m=\u001b[39mORPOTrainer(\n\u001b[1;32m     25\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     26\u001b[0m     args\u001b[38;5;241m=\u001b[39morpo_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer\n\u001b[1;32m     31\u001b[0m )\n\u001b[0;32m---> 33\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1780\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1778\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2118\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2117\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2118\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2121\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2122\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2123\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2124\u001b[0m ):\n\u001b[1;32m   2125\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2126\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3036\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3033\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3035\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3036\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3038\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3039\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trl/trainer/orpo_trainer.py:786\u001b[0m, in \u001b[0;36mORPOTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m    783\u001b[0m compute_loss_context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_peft_has_been_casted_to_bf16 \u001b[38;5;28;01melse\u001b[39;00m nullcontext\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m compute_loss_context_manager():\n\u001b[0;32m--> 786\u001b[0m     loss, metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_loss_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# force log the metrics\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore_metrics(metrics, train_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trl/trainer/orpo_trainer.py:746\u001b[0m, in \u001b[0;36mORPOTrainer.get_batch_loss_metrics\u001b[0;34m(self, model, batch, train_eval)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the ORPO loss and other metrics for the given batch of inputs for train or test.\"\"\"\u001b[39;00m\n\u001b[1;32m    738\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    740\u001b[0m (\n\u001b[1;32m    741\u001b[0m     policy_chosen_logps,\n\u001b[1;32m    742\u001b[0m     policy_rejected_logps,\n\u001b[1;32m    743\u001b[0m     policy_chosen_logits,\n\u001b[1;32m    744\u001b[0m     policy_rejected_logits,\n\u001b[1;32m    745\u001b[0m     policy_nll_loss,\n\u001b[0;32m--> 746\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenated_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    748\u001b[0m losses, chosen_rewards, rejected_rewards, log_odds_ratio, log_odds_chosen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39modds_ratio_loss(\n\u001b[1;32m    749\u001b[0m     policy_chosen_logps, policy_rejected_logps\n\u001b[1;32m    750\u001b[0m )\n\u001b[1;32m    751\u001b[0m \u001b[38;5;66;03m# full ORPO loss\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trl/trainer/orpo_trainer.py:715\u001b[0m, in \u001b[0;36mORPOTrainer.concatenated_forward\u001b[0;34m(self, model, batch)\u001b[0m\n\u001b[1;32m    711\u001b[0m     labels \u001b[38;5;241m=\u001b[39m concatenated_batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcatenated_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    713\u001b[0m chosen_nll_loss \u001b[38;5;241m=\u001b[39m cross_entropy_loss(all_logits[:len_chosen], labels[:len_chosen])\n\u001b[0;32m--> 715\u001b[0m all_logps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_logps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcatenated_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconcatenated_labels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43maverage_log_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_encoder_decoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_encoder_decoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_pad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_pad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m chosen_logps \u001b[38;5;241m=\u001b[39m all_logps[:len_chosen]\n\u001b[1;32m    724\u001b[0m rejected_logps \u001b[38;5;241m=\u001b[39m all_logps[len_chosen:]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trl/trainer/orpo_trainer.py:655\u001b[0m, in \u001b[0;36mORPOTrainer.get_batch_logps\u001b[0;34m(logits, labels, average_log_prob, label_pad_token_id, is_encoder_decoder)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;66;03m# dummy token; we'll ignore the losses on these tokens later\u001b[39;00m\n\u001b[1;32m    653\u001b[0m labels[labels \u001b[38;5;241m==\u001b[39m label_pad_token_id] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 655\u001b[0m per_token_logps \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mgather(\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_softmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, index\u001b[38;5;241m=\u001b[39mlabels\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average_log_prob:\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (per_token_logps \u001b[38;5;241m*\u001b[39m loss_mask)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m loss_mask\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.93 GiB. GPU 0 has a total capacty of 15.89 GiB of which 644.12 MiB is free. Process 9356 has 15.26 GiB memory in use. Of the allocated memory 14.50 GiB is allocated by PyTorch, and 489.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 1.93 GiB. GPU 0 has a total capacty of 15.89 GiB of which 644.12 MiB is free. Process 9356 has 15.26 GiB memory in use. Of the allocated memory 14.50 GiB is allocated by PyTorch, and 489.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]},{"cell_type":"code","source":"kwargs={\n    'model_name': os.getenv(\"WANDB_NAME\"),\n    'finetuned_from': os.getenv('MODEL_NAME'),\n#     'tasks': '',\n#     'dataset_tags':'',\n    'dataset': os.getenv(\"DATASET\")\n}\n\ntokenizer.push_to_hub(os.getenv(\"WANDB_NAME\"))\ntrainer.push_to_hub(**kwargs)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T07:36:15.294112Z","iopub.status.idle":"2024-06-24T07:36:15.294609Z","shell.execute_reply.started":"2024-06-24T07:36:15.294343Z","shell.execute_reply":"2024-06-24T07:36:15.294363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Merge and push merged model","metadata":{}},{"cell_type":"code","source":"import gc\n\ndel trainer, model\ngc.collect()\n\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-06-24T07:36:15.296217Z","iopub.status.idle":"2024-06-24T07:36:15.296687Z","shell.execute_reply.started":"2024-06-24T07:36:15.296456Z","shell.execute_reply":"2024-06-24T07:36:15.296474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer=AutoTokenizer.from_pretrained(os.getenv('MODEL_NAME'))","metadata":{"execution":{"iopub.status.busy":"2024-06-24T07:36:15.297636Z","iopub.status.idle":"2024-06-24T07:36:15.298067Z","shell.execute_reply.started":"2024-06-24T07:36:15.297843Z","shell.execute_reply":"2024-06-24T07:36:15.297861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    os.getenv('MODEL_NAME'),\n    low_cpu_mem_usage=True,\n    return_dict=True,\n    torch_dtype=torch.float16,\n    device_map=\"cuda\",\n)\n\nmodel.device()","metadata":{"execution":{"iopub.status.busy":"2024-06-24T07:36:15.300031Z","iopub.status.idle":"2024-06-24T07:36:15.300527Z","shell.execute_reply.started":"2024-06-24T07:36:15.300267Z","shell.execute_reply":"2024-06-24T07:36:15.300284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, tokenizer = setup_chat_format(model, tokenizer)\n\n# Merge adapter with base model\nmodel = PeftModel.from_pretrained(model, os.getenv(\"WANDB_NAME\"))\nmodel = model.merge_and_unload()","metadata":{"execution":{"iopub.status.busy":"2024-06-24T07:36:15.302286Z","iopub.status.idle":"2024-06-24T07:36:15.302654Z","shell.execute_reply.started":"2024-06-24T07:36:15.302474Z","shell.execute_reply":"2024-06-24T07:36:15.302494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.push_to_hub(os.getenv(\"WANDB_NAME\"), use_temp_dir=False)\n# tokenizer.push_to_hub(os.getenv(\"WANDB_NAME\"), use_temp_dir=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T07:36:15.303991Z","iopub.status.idle":"2024-06-24T07:36:15.304324Z","shell.execute_reply.started":"2024-06-24T07:36:15.304162Z","shell.execute_reply":"2024-06-24T07:36:15.304175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Acknowledge\n\n* https://www.kaggle.com/code/aisuko/fine-tuning-phi-2-with-qlora\n* https://medium.com/towards-data-science/fine-tune-llama-3-with-orpo-56cfab2f9ada\n* https://www.kaggle.com/code/aisuko/llm-prompt-recovery-with-gemma","metadata":{}}]}