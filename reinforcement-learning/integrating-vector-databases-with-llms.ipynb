{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview\n\nIn this notebook, we will dive into LLM and their synergy with Vector Databases. The vector databases store data in a unique format known as **vector embeddings** which enable LLMs to grasp and utilize information more contextually and accurately. Let's create an application that **context-aware and reliable**. \n\n\n# Embedding Process\n\nIn deep learning, the raw data transformed into a numerical format which know as vectors that AI system can understand. High-dimensional data referes to data that has many attributes or features, each representing a different dimension. These dimensions help in capturing the nuanced characteristics of the data. The vector embeddings process likes below:\n\n```\nRaw input -> Tokenization -> Embedding -> Vector\n```\n\nEach number in vector represents a specific feature of the data, and together, these numbers encapsulate the seence of the original input int a format that the machine can process. For example, see the illustration below:\n\n![](https://cdn.masto.host/sigmoidsocial/media_attachments/files/112/030/524/565/225/614/original/62e6da79e44eda50.webp)\n\nThe vector representation of puppy would be positioned closer in vector space to dog than to house, reflecting their semantic proximity. This approach extends to analogical relationships as well. The vector distance and direction between man and woman can be analogous to that between king and queen. This illustrates **how word vectors not only represent words but also allow for a meaningful comparison of their semantic relationships in a multidimensional vector space.**\n\n\n# Vector Databases\n\n**Similarity Seach** is core function where vector databases excel. They can quickly **find data points that are similar to given query in a high-dimensional space.** Some examples like content-based Retrival, E-Commerce image searching, etc. It is also can enhance LLMs with **Contextual Understanding**. It stores and process text embeddings that enable LLMs to perform more nuanced and context-aware information retrieval. They help in understanding the semantic content of large volumes of text, which is pivotal in tasks like answering complex queries, **maintaining conversation context**, or generating relevant content.\n\n\n# Vector VS Traditional Databases\n\nTraditional SQL databases excel in structured data management, thriving on excat mathces and well-defined conditional logic. However, the rigid schema design makes them less adaptable to the semantic and contextual nuances of unstructured data. No SQL databases, offer more flexibility compared to traditional SQL systems. They can handle semi-structured and unstructured data. Despite this, even NoSQL databses can fall short in certain aspects of handling the complex, high-dimensional vector data essential for LLMs and Generative AI, which often involves interpreting context, patterns, and semantic content beyond simple data retrieval.\n\n\n# Enriching Context for LLMs with Vector Databases\n\nThe pre-trained mdoel is powerful like LLama2. However, they face challenges in hanlding specialized contexts due to theie training on baord, general datasets. Addressing the contextual limitations can be approached in two main ways:\n\n\n# Targeted Training\n\nThis involves retraining or fine-tuning the LLM on a dataset focused on the specific area of interest.\n\n\n# Incorporating Context via Vector Databases\n\nAlternatively, the LLM can be augmented by adding context directly into its prompts, using data from a vector database. In this setup, the vector database stores specialized information as vector embeddings, which can be retrieved and used by the LLM to enhance its responses. This approach allows for the inclusion of relevant, specialized knowledge without the need for extensive retraining. It's particularly useful for organizations of infivisuals lacking the resources for targeted training, as it leverages existing model capabilities while providing focused contextual insights. This is called **Retrieval Argumented Generation(RAG)**.\n\n![](https://cdn.masto.host/sigmoidsocial/media_attachments/files/112/031/445/938/150/573/original/aee0db54da449455.webp)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"%%capture\n!pip install transformers==4.36.2\n!pip install accelerate==0.25.0\n!pip install datasets==2.15.0\n!pip install peft==0.7.1\n!pip install bitsandbytes==0.41.3\n!pip install einops==0.7.0\n!pip install sentence-transformers==2.5.1\n!pip install chromadb==0.4.24","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nos.environ['DATASET']='databricks/databricks-dolly-15k'\nos.environ['MODEL_NAME']='tiiuae/falcon-7b-instruct'\nos.environ['TASK_TYPE']='text-generation'\nos.environ['SENTENCE_TRANSFORMER']='multi-qs-MiniLM-L6-cos-v1'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from dataset import load_dataset\n\ndataset=load_dataset(os.getenv('DATASET'), split='train[:1000]')\nprint(dataset)\n\nclosed_qa_dataset=dataset.filter(lambda example: example['category']=='closed_qa')\nprint(closed_qa_dataset[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import chromadb\nfrom sentence_transformers import SentenceTransformer\n\nclass VectorStore:\n    def __init__(self, collection_name, embedding_model):\n        self.embedding_model=embedding_model\n        self.chroma_client=chromadb.Client()\n        self.collection=self.chroma_client.create_collection(name=collection_name)\n        \n    # method to populate the vector store with embeddings from a dataset\n    def populate_vectors(self, dataset):\n        for i, item in enumerate(dataset):\n            combined_text=f\"{item['instruction']}, {item['context']}\"\n            embeddings=self.embedding_model.encode(combined_text).to_list()\n            self.collection.add(embeddings=[embeddings], documents=[item['context']],ids=[f\"id_{id}\"])\n            \n    # method to search the ChromaDB collection for relevant based on a query\n    def search_context(self, query, n_results=1):\n        query_embeddings=self.embedding_model(query).tolist()\n        return self.collection.query(query_embeddings=query_embeddings, n_results=n_results)\n\n    \nencoder=SentenceTransformer(os.getenv('SENTENCE_TRANSFORMER'), device='cuda')\nencoder.max_seq_length=200\nvector_store=VectorStore(\"knowledge-base\", encoder)\n\nvector_store.populate_vectors(closed_qa_dataset)                             ","metadata":{},"execution_count":null,"outputs":[]}]}