{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Mimic data interp-net training part\n\nThis note is a demo of impletment interp-net training \n\nThe origin code from \nhttps://github.com/mlds-lab/interp-net/blob/af2dbb8a23ba3584706c079432cc00568c68fd99/src/multivariate_example.py#L114-L207","metadata":{}},{"cell_type":"markdown","source":"## Environment setup\n","metadata":{}},{"cell_type":"code","source":"!pip install keras","metadata":{"execution":{"iopub.status.busy":"2024-09-22T16:05:02.407855Z","iopub.execute_input":"2024-09-22T16:05:02.408228Z","iopub.status.idle":"2024-09-22T16:05:17.521921Z","shell.execute_reply.started":"2024-09-22T16:05:02.408183Z","shell.execute_reply":"2024-09-22T16:05:17.520704Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (3.3.3)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras) (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras) (1.26.4)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras) (13.7.1)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras) (0.0.8)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras) (3.11.0)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras) (0.11.0)\nRequirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras) (0.3.2)\nRequirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from optree->keras) (4.12.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Function implement","metadata":{}},{"cell_type":"code","source":"import argparse\nimport numpy as np\nimport logging, os\nlogging.disable(logging.WARNING)\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\nimport tensorflow as tf\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import average_precision_score as auprc\nfrom sklearn.metrics import roc_auc_score as auc_score\nimport keras\n# from keras.utils import multi_gpu_model\nfrom keras.layers import Input, Dense, GRU, Lambda, Permute\nfrom keras.models import Model\n# from interpolation_layer import single_channel_interp, cross_channel_interp\n# from mimic_preprocessing import load_data, trim_los, fix_input_format\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nnp.random.seed(10)\n# tf.set_random_seed(10)\ntf.random.set_seed(10)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T16:05:17.524674Z","iopub.execute_input":"2024-09-22T16:05:17.524944Z","iopub.status.idle":"2024-09-22T16:05:17.534861Z","shell.execute_reply.started":"2024-09-22T16:05:17.524907Z","shell.execute_reply":"2024-09-22T16:05:17.533853Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"## Define mimic_preprocessing functions\n\nFunctions in mimic_preprocessing has been refined in notes\n\nhttps://www.kaggle.com/code/micost/mimic-interp-net-data-preprocessing\n\n","metadata":{}},{"cell_type":"code","source":"import pickle\nimport copy\nimport numpy as np\n\ndef load_data():\n    # batch_size is number of records within each vital file\n    batch_size = 10000\n    # batch_idx is index of the vital file.  \n    # Please note, vital files should be loaded in order\n    batch_idx = 1\n    print('Loading files ...')\n    with open('/kaggle/input/mimic-interp-net-data-demo/vitals_records_10000.p', 'rb') as file:\n        vitals = pickle.load(file)\n    print(len(vitals))\n    with open('/kaggle/input/mimic-interp-net-data-demo/adm_type_los_mortality.p', 'rb') as file:\n        adm_info = pickle.load(file)\n    print(len(adm_info))\n    print('Loading Done!')\n\n\n    # This step is about to filter vitals result by choose adm_info's 4th value larger than 48.  Only keep the corresponding vitals values\n    # Here is the original codes, correct me if I messed the logic. adm_id_needed is confusing\n\n    # adm_id = [record[0] for record in adm_info]\n    # adm_id_needed = [record[0] for record in adm_info if record[2] >= 48]\n    # vitals_dict = {}\n    # for i in range(len(adm_id)):\n    #     vitals_dict[adm_id[i]] = vitals[i]\n    # vitals = [vitals_dict[x] for x in adm_id_needed]\n    # label = [rec[3] for x in adm_id_needed for rec in adm_info if x == rec[0]]\n\n\n\n    start_point= batch_size*(batch_idx-1)\n\n    print(start_point)\n\n    label = []\n    for record in adm_info:\n        if record[2] >= 48:\n            label.append(record[3])\n\n    print(len(label))\n\n    vitals_new = []\n    for i in range(len(vitals)):\n        if adm_info[start_point+i][2] >= 48:\n            vitals_new.append(vitals[i])\n    print(len(vitals_new))\n\n    vitals = vitals_new\n\n    return vitals, label\n","metadata":{"execution":{"iopub.status.busy":"2024-09-22T16:05:17.536435Z","iopub.execute_input":"2024-09-22T16:05:17.536764Z","iopub.status.idle":"2024-09-22T16:05:17.548873Z","shell.execute_reply.started":"2024-09-22T16:05:17.536714Z","shell.execute_reply":"2024-09-22T16:05:17.547572Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef trim_los_parallel(data_chunk, length_of_stay):\n    num_features = 12  # final features (excluding EtCO2)\n    max_length = 2881  # maximum length of time stamp\n    a = np.full((len(data_chunk), num_features, max_length), -100, dtype=float)  # initialize array with -100 (missing data)\n    timestamps = []\n\n    for i in range(len(data_chunk)):\n        # Process temperature conversion in a vectorized way\n        if data_chunk[i][7]:\n            temp_array = np.array([elem[1] for elem in data_chunk[i][7] if elem[1] is not None])\n            data_chunk[i][6] += [(elem[0], temp * 1.8 + 32) for elem, temp in zip(data_chunk[i][7], temp_array)]\n\n        # Combine data[9] with data[10] and data[11]\n        data_chunk[i][9].extend(data_chunk[i][10] + data_chunk[i][11])\n\n        # Remove unwanted elements (EtCO2 data)\n        del data_chunk[i][5:7]\n        del data_chunk[i][8]\n\n        # Collect unique timestamps across all features\n        all_timestamps = sorted(set([elem[0] for j in range(num_features) for elem in data_chunk[i][j]]))\n\n        # Extract first 48-hour data\n        first_ts = all_timestamps[0] if all_timestamps else None\n        TS = [ts for ts in all_timestamps if (ts - first_ts).total_seconds() / 3600 <= length_of_stay]\n\n        timestamps.append(TS)\n\n        for j in range(num_features):\n            feature_data = data_chunk[i][j]\n            feature_dict = {entry[0]: entry[1] for entry in feature_data}  # Convert list to dictionary for fast lookup\n\n            for k, ts in enumerate(TS):\n                if ts in feature_dict:\n                    value = feature_dict[ts]\n                    if value is None or value in ('Other/Remarks', 'Comment'):\n                        a[i, j, k] = -100\n                    elif value in ('Normal <3 secs', 'Normal <3 Seconds', 'Brisk'):\n                        a[i, j, k] = 1\n                    elif value in ('Abnormal >3 secs', 'Abnormal >3 Seconds', 'Delayed'):\n                        a[i, j, k] = 2\n                    else:\n                        a[i, j, k] = value\n                else:\n                    a[i, j, k] = -100  # missing data\n\n    return a, timestamps\n\n# Function to split the data and run in parallel\ndef run_trim_los_in_parallel(data, length_of_stay, num_workers=4):\n    # Split data into chunks for parallel processing\n    chunk_size = len(data) // num_workers\n    data_chunks = [data[i:i + chunk_size] for i in range(0, len(data), chunk_size)]\n\n    results = []\n    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n        futures = [executor.submit(trim_los_parallel, chunk, length_of_stay) for chunk in data_chunks]\n        for future in futures:\n            results.append(future.result())\n\n    # Combine results from all chunks\n    all_a = np.concatenate([result[0] for result in results], axis=0)\n    all_timestamps = sum([result[1] for result in results], [])\n    \n    return all_a, all_timestamps\n\ndef trim_los(data, length_of_stay):\n    length_of_stay = 48\n    num_workers = 15  # Use the available 15 cores for parallel processing\n    return run_trim_los_in_parallel(vitals, length_of_stay, num_workers)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T16:05:17.552153Z","iopub.execute_input":"2024-09-22T16:05:17.552595Z","iopub.status.idle":"2024-09-22T16:05:17.574932Z","shell.execute_reply.started":"2024-09-22T16:05:17.552556Z","shell.execute_reply":"2024-09-22T16:05:17.573982Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"def fix_input_format(x, T):\n    \"\"\"Return the input in the proper format\n    x: observed values\n    M: masking, 0 indicates missing values\n    delta: time points of observation\n    \"\"\"\n    timestamp = 200\n    num_features = 12\n\n    # trim time stamps higher than 200\n    for i in range(len(T)):\n        if len(T[i]) > timestamp:\n            T[i] = T[i][:timestamp]\n\n    x = x[:, :, :timestamp]\n    M = np.zeros_like(x)\n    delta = np.zeros_like(x)\n    print(x.shape, len(T))\n\n    for t in T:\n        for i in range(1, len(t)):\n            t[i] = (t[i] - t[0]).total_seconds()/3600.0\n        if len(t) != 0:\n            t[0] = 0\n\n    # count outliers and negative values as missing values\n    # M = 0 indicates missing value\n    # M = 1 indicates observed value\n    # now since we have mask variable, we don't need -100\n    M[x > 500] = 0\n    x[x > 500] = 0.0\n    M[x < 0] = 0\n    x[x < 0] = 0.0\n    M[x > 0] = 1\n\n    for i in range(num_features):\n        for j in range(x.shape[0]):\n            for k in range(len(T[j])):\n                delta[j, i, k] = T[j][k]\n\n    return x, M, delta","metadata":{"execution":{"iopub.status.busy":"2024-09-22T16:05:17.576472Z","iopub.execute_input":"2024-09-22T16:05:17.577062Z","iopub.status.idle":"2024-09-22T16:05:17.589446Z","shell.execute_reply.started":"2024-09-22T16:05:17.577020Z","shell.execute_reply":"2024-09-22T16:05:17.588467Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"## Defin functions in interpolation layer\n\nInstead of import interpolation layer as a seperate file.  We impletement fucntions here","metadata":{}},{"cell_type":"code","source":"from keras import backend as K\n# from keras.engine.topology import Layer\nfrom keras.layers import Layer\nimport numpy as np\nimport tensorflow as tf\nimport keras\nfrom keras import activations\n\n\nclass single_channel_interp(Layer):\n\n    def __init__(self, ref_points, hours_look_ahead, **kwargs):\n        self.ref_points = ref_points\n        self.hours_look_ahead = hours_look_ahead  # in hours\n        super(single_channel_interp, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        #input_shape [batch, features, time_stamp]\n        self.time_stamp = input_shape[2]\n        self.d_dim = input_shape[1] // 4\n        self.activation = activations.get('sigmoid')\n        self.kernel = self.add_weight(\n            name='kernel',\n            shape=(self.d_dim, ),\n            initializer=keras.initializers.Constant(value=0.0),\n            trainable=True)\n        super(single_channel_interp, self).build(input_shape)\n\n    def call(self, x, reconstruction=False):\n        self.reconstruction = reconstruction\n        x_t = x[:, :self.d_dim, :]\n        d = x[:, 2*self.d_dim:3*self.d_dim, :]\n        if reconstruction:\n            output_dim = self.time_stamp\n            m = x[:, 3*self.d_dim:, :]\n            ref_t = K.tile(d[:, :, None, :], (1, 1, output_dim, 1))\n        else:\n            m = x[:, self.d_dim: 2*self.d_dim, :]\n            ref_t = np.linspace(0, self.hours_look_ahead, self.ref_points)\n            output_dim = self.ref_points\n            ref_t.shape = (1, ref_t.shape[0])\n        #x_t = x_t*m\n        d = K.tile(d[:, :, :, None], (1, 1, 1, output_dim))\n        mask = K.tile(m[:, :, :, None], (1, 1, 1, output_dim))\n        x_t = K.tile(x_t[:, :, :, None], (1, 1, 1, output_dim))\n        norm = (d - ref_t)*(d - ref_t)\n        a = K.ones((self.d_dim, self.time_stamp, output_dim))\n        pos_kernel = K.log(1 + K.exp(self.kernel))\n        alpha = a*pos_kernel[:, np.newaxis, np.newaxis]\n        w = K.logsumexp(-alpha*norm + K.log(mask), axis=2)\n        w1 = K.tile(w[:, :, None, :], (1, 1, self.time_stamp, 1))\n        w1 = K.exp(-alpha*norm + K.log(mask) - w1)\n        y = K.sum(w1*x_t, axis=2)\n        if reconstruction:\n            rep1 = tf.concat([y, w], 1)\n        else:\n            w_t = K.logsumexp(-10.0*alpha*norm + K.log(mask),\n                              axis=2)  # kappa = 10\n            w_t = K.tile(w_t[:, :, None, :], (1, 1, self.time_stamp, 1))\n            w_t = K.exp(-10.0*alpha*norm + K.log(mask) - w_t)\n            y_trans = K.sum(w_t*x_t, axis=2)\n            rep1 = tf.concat([y, w, y_trans], 1)\n        return rep1\n\n    def compute_output_shape(self, input_shape):\n        if self.reconstruction:\n            return (input_shape[0], 2*self.d_dim, self.time_stamp)\n        return (input_shape[0], 3*self.d_dim, self.ref_points)\n\nclass cross_channel_interp(Layer):\n\n    def __init__(self, **kwargs):\n        super(cross_channel_interp, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.d_dim = input_shape[1] // 3\n        self.activation = activations.get('sigmoid')\n        self.cross_channel_interp = self.add_weight(\n            name='cross_channel_interp',\n            shape=(self.d_dim, self.d_dim),\n            initializer=keras.initializers.Identity(gain=1.0),\n            trainable=True)\n\n        super(cross_channel_interp, self).build(input_shape)\n\n    def call(self, x, reconstruction=False):\n        self.reconstruction = reconstruction\n        self.output_dim = K.int_shape(x)[-1]\n        cross_channel_interp = self.cross_channel_interp\n        y = x[:, :self.d_dim, :]\n        w = x[:, self.d_dim:2*self.d_dim, :]\n        intensity = K.exp(w)\n        y = tf.transpose(y, perm=[0, 2, 1])\n        w = tf.transpose(w, perm=[0, 2, 1])\n        w2 = w\n        w = K.tile(w[:, :, :, None], (1, 1, 1, self.d_dim))\n        den = K.logsumexp(w, axis=2)\n        w = K.exp(w2 - den)\n        mean = K.mean(y, axis=1)\n        mean = K.tile(mean[:, None, :], (1, self.output_dim, 1))\n        w2 = K.dot(w*(y - mean), cross_channel_interp) + mean\n        rep1 = tf.transpose(w2, perm=[0, 2, 1])\n        if reconstruction is False:\n            y_trans = x[:, 2*self.d_dim:3*self.d_dim, :]\n            y_trans = y_trans - rep1  # subtracting smooth from transient part\n            rep1 = tf.concat([rep1, intensity, y_trans], 1)\n        return rep1\n\n    def compute_output_shape(self, input_shape):\n        if self.reconstruction:\n            return (input_shape[0], self.d_dim, self.output_dim)\n        return (input_shape[0], 3*self.d_dim, self.output_dim)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T16:05:17.591081Z","iopub.execute_input":"2024-09-22T16:05:17.591367Z","iopub.status.idle":"2024-09-22T16:05:17.627316Z","shell.execute_reply.started":"2024-09-22T16:05:17.591329Z","shell.execute_reply":"2024-09-22T16:05:17.626197Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"def hold_out(mask, perc=0.2):\n    \"\"\"To implement the autoencoder component of the loss, we introduce a set\n    of masking variables mr (and mr1) for each data point. If drop_mask = 0,\n    then we removecthe data point as an input to the interpolation network,\n    and includecthe predicted value at this time point when assessing\n    the autoencoder loss. In practice, we randomly select 20% of the\n    observed data points to hold out from\n    every input time series.\"\"\"\n    drop_mask = np.ones_like(mask)\n    drop_mask *= mask\n    for i in range(mask.shape[0]):\n        for j in range(mask.shape[1]):\n            count = np.sum(mask[i, j], dtype='int')\n            if int(0.20*count) > 1:\n                index = 0\n                r = np.ones((count, 1))\n                b = np.random.choice(count, int(0.20*count), replace=False)\n                r[b] = 0\n                for k in range(mask.shape[2]):\n                    if mask[i, j, k] > 0:\n                        drop_mask[i, j, k] = r[index,0]\n                        index += 1\n    return drop_mask","metadata":{"execution":{"iopub.status.busy":"2024-09-22T16:05:17.628888Z","iopub.execute_input":"2024-09-22T16:05:17.629204Z","iopub.status.idle":"2024-09-22T16:05:17.642789Z","shell.execute_reply.started":"2024-09-22T16:05:17.629128Z","shell.execute_reply":"2024-09-22T16:05:17.641553Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"def mean_imputation(vitals, mask):\n    \"\"\"For the time series missing entirely, our interpolation network \n    assigns the starting point (time t=0) value of the time series to \n    the global mean before applying the two-layer interpolation network.\n    In such cases, the first interpolation layer just outputs the global\n    mean for that channel, but the second interpolation layer performs \n    a more meaningful interpolation using the learned correlations from\n    other channels.\"\"\"\n    counts = np.sum(np.sum(mask, axis=2), axis=0)\n    mean_values = np.sum(np.sum(vitals*mask, axis=2), axis=0)/counts\n    for i in range(mask.shape[0]):\n        for j in range(mask.shape[1]):\n            if np.sum(mask[i, j]) == 0:\n                mask[i, j, 0] = 1\n                vitals[i, j, 0] = mean_values[j]\n    return\n","metadata":{"execution":{"iopub.status.busy":"2024-09-22T16:05:17.644603Z","iopub.execute_input":"2024-09-22T16:05:17.644860Z","iopub.status.idle":"2024-09-22T16:05:17.656088Z","shell.execute_reply.started":"2024-09-22T16:05:17.644823Z","shell.execute_reply":"2024-09-22T16:05:17.655175Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"## Argument process","metadata":{}},{"cell_type":"code","source":"# ap = argparse.ArgumentParser()\n# ap.add_argument(\"-g\", \"--gpus\", type=int, default=4,\n#                 help=\"# of GPUs to use for training\")\n# ap.add_argument(\"-batch\", \"--batch_size\", type=int, default=256,\n#                 help=\"# batch size to use for training\")\n# ap.add_argument(\"-e\", \"--epochs\", type=int, default=100,\n#                 help=\"# of epochs for training\")\n# ap.add_argument(\"-ref\", \"--reference_points\", type=int,\n#                 default=192, help=\"# of reference points\")\n# ap.add_argument(\"-units\", \"--hidden_units\", type=int,\n#                 default=100, help=\"# of hidden units\")\n# ap.add_argument(\"-hfadm\", \"--hours_from_adm\", type=int,\n#                 default=48, help=\"Hours of record to look at\")\n\n# args = vars(ap.parse_args())\n# gpu_num = args[\"gpus\"]\n# epoch = args[\"epochs\"]\n# hid = args[\"hidden_units\"]\n# ref_points = args[\"reference_points\"]\n# hours_look_ahead = args[\"hours_from_adm\"]\n# if gpu_num > 0:\n#     batch = args[\"batch_size\"]*gpu_num\n# else:\n#     batch = args[\"batch_size\"]\n# Let define some thing first\ngpu_num = 1\nhours_look_ahead = 48 \nbatch = 256\nepoch = 100\nref_points = 192\nhid = 100","metadata":{"execution":{"iopub.status.busy":"2024-09-22T16:05:17.657426Z","iopub.execute_input":"2024-09-22T16:05:17.657684Z","iopub.status.idle":"2024-09-22T16:05:17.667112Z","shell.execute_reply.started":"2024-09-22T16:05:17.657648Z","shell.execute_reply":"2024-09-22T16:05:17.666027Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"## Load dataset\n","metadata":{}},{"cell_type":"code","source":"# Loading dataset\n# y : (N,) discrete for classification, real values for regression\n# x : (N, D, tn) input multivariate time series data with dimension\n#     where N is number of data cases, D is the dimension of\n#     sparse and irregularly sampled time series and tn is the union\n#     of observed time stamps in all the dimension for a data case n.\n#     Since each tn is of variable length, we pad them with zeros to\n#     have an array representation.\n# m : (N, D, tn) where m[i,j,k] = 0 means that x[i,j,k] is not observed.\n# T : (N, D, tn) represents the actual time stamps of observation;\nhours_look_ahead = 48\nvitals, label = load_data()\nvitals, timestamps = trim_los(vitals, hours_look_ahead)\nx, m, T = fix_input_format(vitals, timestamps)\nmean_imputation(x, m)\nx = np.concatenate((x, m, T, hold_out(m)), axis=1)  # input format\ny = np.array(label)\nprint(x.shape, y.shape)\ntimestamp = x.shape[2]\nnum_features = x.shape[1] // 4","metadata":{"execution":{"iopub.status.busy":"2024-09-22T16:05:17.670445Z","iopub.execute_input":"2024-09-22T16:05:17.670710Z","iopub.status.idle":"2024-09-22T16:05:44.195439Z","shell.execute_reply.started":"2024-09-22T16:05:17.670674Z","shell.execute_reply":"2024-09-22T16:05:44.194213Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Loading files ...\n5000\n58976\nLoading Done!\n0\n53211\n4531\n(4531, 12, 200) 4531\n(4531, 48, 200) (53211,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Customloss","metadata":{}},{"cell_type":"code","source":"def customloss(ytrue, ypred):\n    \"\"\" Autoencoder loss\n    \"\"\"\n    # standard deviation of each feature mentioned in paper for MIMIC_III data\n    wc = np.array([3.33, 23.27, 5.69, 22.45, 14.75, 2.32,\n                   3.75, 1.0, 98.1, 23.41, 59.32, 1.41])\n    wc.shape = (1, num_features)\n    y = ytrue[:, :num_features, :]\n    m2 = ytrue[:, 3*num_features:4*num_features, :]\n    m2 = 1 - m2\n    m1 = ytrue[:, num_features:2*num_features, :]\n    m = m1*m2\n    ypred = ypred[:, :num_features, :]\n    x = (y - ypred)*(y - ypred)\n    x = x*m\n    count = tf.reduce_sum(m, axis=2)\n    count = tf.where(count > 0, count, tf.ones_like(count))\n    x = tf.reduce_sum(x, axis=2)/count\n    x = x/(wc**2)  # dividing by standard deviation\n    x = tf.reduce_sum(x, axis=1)/num_features\n    return tf.reduce_mean(x)\n\n\nseed = 0\nresults = {}\nresults['loss'] = []\nresults['auc'] = []\nresults['acc'] = []\nresults['auprc'] = []\n\n# interpolation-prediction network\n","metadata":{"execution":{"iopub.status.busy":"2024-09-22T16:05:44.197221Z","iopub.execute_input":"2024-09-22T16:05:44.197533Z","iopub.status.idle":"2024-09-22T16:05:44.209309Z","shell.execute_reply.started":"2024-09-22T16:05:44.197491Z","shell.execute_reply":"2024-09-22T16:05:44.208199Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"## interp net","metadata":{}},{"cell_type":"code","source":"def interp_net():\n    # Forget the multigpu support just make the gpu_num = 1 and tru\n    gpu_num = 1\n    if gpu_num > 1:\n        dev = \"/cpu:0\"\n    else:\n        dev = \"/gpu:0\"\n    with tf.device(dev):\n        main_input = Input(shape=(4*num_features, timestamp), name='input')\n        sci = single_channel_interp(ref_points, hours_look_ahead)\n        cci = cross_channel_interp()\n        interp = cci(sci(main_input))\n        reconst = cci(sci(main_input, reconstruction=True),\n                      reconstruction=True)\n        aux_output = Lambda(lambda x: x, name='aux_output')(reconst)\n        z = Permute((2, 1))(interp)\n        z = GRU(hid, activation='tanh', recurrent_dropout=0.2, dropout=0.2)(z)\n        main_output = Dense(1, activation='sigmoid', name='main_output')(z)\n        orig_model = Model([main_input], [main_output, aux_output])\n    if gpu_num > 1:\n        model = multi_gpu_model(orig_model, gpus=gpu_num)\n    else:\n        model = orig_model\n    print(orig_model.summary())\n    return model\n\n\nearlystop = keras.callbacks.EarlyStopping(\n    monitor='val_loss', min_delta=0.0000, patience=20, verbose=0)\ncallbacks_list = [earlystop]\n","metadata":{"execution":{"iopub.status.busy":"2024-09-22T16:05:44.210955Z","iopub.execute_input":"2024-09-22T16:05:44.211364Z","iopub.status.idle":"2024-09-22T16:05:44.223683Z","shell.execute_reply.started":"2024-09-22T16:05:44.211320Z","shell.execute_reply":"2024-09-22T16:05:44.222680Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":"## Fold cross-validation","metadata":{}},{"cell_type":"code","source":"i = 0\nkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\nfor train, test in kfold.split(np.zeros(len(y)), y):\n    print(\"Running Fold:\", i+1)\n    model = interp_net()  # re-initializing every time\n    model.compile(\n        optimizer='adam',\n        loss={'main_output': 'binary_crossentropy', 'aux_output': customloss},\n        loss_weights={'main_output': 1., 'aux_output': 1.},\n        metrics={'main_output': 'accuracy'})\n    model.fit(\n        {'input': x[train]}, {'main_output': y[train], 'aux_output': x[train]},\n        batch_size=batch,\n        callbacks=callbacks_list,\n        nb_epoch=epoch,\n        validation_split=0.20,\n        verbose=2)\n    y_pred = model.predict(x[test], batch_size=batch)\n    y_pred = y_pred[0]\n    total_loss, score, reconst_loss, acc = model.evaluate(\n        {'input': x[test]},\n        {'main_output': y[test], 'aux_output': x[test]},\n        batch_size=batch,\n        verbose=0)\n    results['loss'].append(score)\n    results['acc'].append(acc)\n    results['auc'].append(auc_score(y[test], y_pred))\n    results['auprc'].append(auprc(y[test], y_pred))\n    print(results)\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2024-09-22T16:05:44.225005Z","iopub.execute_input":"2024-09-22T16:05:44.225341Z","iopub.status.idle":"2024-09-22T16:05:44.469046Z","shell.execute_reply.started":"2024-09-22T16:05:44.225302Z","shell.execute_reply":"2024-09-22T16:05:44.467567Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Running Fold: 1\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[68], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m kfold\u001b[38;5;241m.\u001b[39msplit(np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(y)), y):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning Fold:\u001b[39m\u001b[38;5;124m\"\u001b[39m, i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43minterp_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# re-initializing every time\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m      7\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m         loss\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmain_output\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maux_output\u001b[39m\u001b[38;5;124m'\u001b[39m: customloss},\n\u001b[1;32m      9\u001b[0m         loss_weights\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmain_output\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maux_output\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1.\u001b[39m},\n\u001b[1;32m     10\u001b[0m         metrics\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmain_output\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m     11\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     12\u001b[0m         {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m: x[train]}, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmain_output\u001b[39m\u001b[38;5;124m'\u001b[39m: y[train], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maux_output\u001b[39m\u001b[38;5;124m'\u001b[39m: x[train]},\n\u001b[1;32m     13\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m         validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.20\u001b[39m,\n\u001b[1;32m     17\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n","Cell \u001b[0;32mIn[67], line 12\u001b[0m, in \u001b[0;36minterp_net\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m sci \u001b[38;5;241m=\u001b[39m single_channel_interp(ref_points, hours_look_ahead)\n\u001b[1;32m     11\u001b[0m cci \u001b[38;5;241m=\u001b[39m cross_channel_interp()\n\u001b[0;32m---> 12\u001b[0m interp \u001b[38;5;241m=\u001b[39m cci(\u001b[43msci\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain_input\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     13\u001b[0m reconst \u001b[38;5;241m=\u001b[39m cci(sci(main_input, reconstruction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     14\u001b[0m               reconstruction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m aux_output \u001b[38;5;241m=\u001b[39m Lambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: x, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maux_output\u001b[39m\u001b[38;5;124m'\u001b[39m)(reconst)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","Cell \u001b[0;32mIn[61], line 66\u001b[0m, in \u001b[0;36msingle_channel_interp.compute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_output_shape\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_shape):\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstruction\u001b[49m:\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (input_shape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_stamp)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (input_shape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mref_points)\n","\u001b[0;31mAttributeError\u001b[0m: Exception encountered when calling single_channel_interp.call().\n\n\u001b[1m'single_channel_interp' object has no attribute 'reconstruction'\u001b[0m\n\nArguments received by single_channel_interp.call():\n  • args=('<KerasTensor shape=(None, 48, 200), dtype=float32, sparse=None, name=input>',)\n  • kwargs=<class 'inspect._empty'>"],"ename":"AttributeError","evalue":"Exception encountered when calling single_channel_interp.call().\n\n\u001b[1m'single_channel_interp' object has no attribute 'reconstruction'\u001b[0m\n\nArguments received by single_channel_interp.call():\n  • args=('<KerasTensor shape=(None, 48, 200), dtype=float32, sparse=None, name=input>',)\n  • kwargs=<class 'inspect._empty'>","output_type":"error"}]}]}