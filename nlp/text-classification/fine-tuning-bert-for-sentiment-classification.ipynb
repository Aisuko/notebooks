{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview\n\n","metadata":{}},{"cell_type":"code","source":"import os\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nlogin(token=user_secrets.get_secret(\"HUGGINGFACE_TOKEN\"))\n\nos.environ[\"WANDB_API_KEY\"]=user_secrets.get_secret(\"WANDB_API_KEY\")\nos.environ[\"WANDB_PROJECT\"] = \"Fine-tuning bert-base-uncased\"\nos.environ[\"WANDB_NAME\"] = \"ft-bert-base-uncased-for-sentiment-classification\"\nos.environ[\"MODEL_NAME\"] = \"bert-base-uncased\"\nos.environ[\"TOKENIZER_NAME\"] = \"bert-base-uncased\"\nos.environ[\"DATASET\"] = \"https://huggingface.co/datasets/takala/financial_phrasebank\"","metadata":{"execution":{"iopub.status.busy":"2024-09-22T06:45:08.501614Z","iopub.execute_input":"2024-09-22T06:45:08.502554Z","iopub.status.idle":"2024-09-22T06:45:09.527640Z","shell.execute_reply.started":"2024-09-22T06:45:08.502500Z","shell.execute_reply":"2024-09-22T06:45:09.526694Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import BertTokenizer, BertForSequenceClassification\n\n# Load the Financial PhraseBank dataset with a specified configuration\nds = load_dataset(\"financial_phrasebank\", \"sentences_allagree\", trust_remote_code=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T06:45:09.529213Z","iopub.execute_input":"2024-09-22T06:45:09.529557Z","iopub.status.idle":"2024-09-22T06:45:19.630755Z","shell.execute_reply.started":"2024-09-22T06:45:09.529524Z","shell.execute_reply":"2024-09-22T06:45:19.629577Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.04k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1e4367e5a44422f953876f722be6bcb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/8.88k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56bc868f23da46c3bfc009b4fc7ace25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/682k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4570499355f44f308b14b025172dafe9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2264 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fcc8e140fe74567b699425405197160"}},"metadata":{}}]},{"cell_type":"code","source":"ds","metadata":{"execution":{"iopub.status.busy":"2024-09-22T06:45:19.631903Z","iopub.execute_input":"2024-09-22T06:45:19.632212Z","iopub.status.idle":"2024-09-22T06:45:19.639114Z","shell.execute_reply.started":"2024-09-22T06:45:19.632177Z","shell.execute_reply":"2024-09-22T06:45:19.638037Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['sentence', 'label'],\n        num_rows: 2264\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Preprocess the data","metadata":{}},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(os.getenv(\"MODEL_NAME\"))","metadata":{"execution":{"iopub.status.busy":"2024-09-22T06:45:19.641133Z","iopub.execute_input":"2024-09-22T06:45:19.641433Z","iopub.status.idle":"2024-09-22T06:45:21.105483Z","shell.execute_reply.started":"2024-09-22T06:45:19.641401Z","shell.execute_reply":"2024-09-22T06:45:21.104455Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"185a75bb4e234ebba1388d3dccbf4779"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3da0986994cb44919109922f289a8582"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2eba5f3c40f412297b62f63e0a63e0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6a5fafd40ca4f8da3a34c9567f348c7"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize_function(example):\n    return tokenizer(example['sentence'], padding=\"max_length\", truncation=True)\n\ntokenized_ds=ds.map(tokenize_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T06:45:21.107331Z","iopub.execute_input":"2024-09-22T06:45:21.107745Z","iopub.status.idle":"2024-09-22T06:45:24.385301Z","shell.execute_reply.started":"2024-09-22T06:45:21.107700Z","shell.execute_reply":"2024-09-22T06:45:24.384451Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2264 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9aaac5e95f824e77a9921854b16a589e"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_ds","metadata":{"execution":{"iopub.status.busy":"2024-09-22T06:45:24.386356Z","iopub.execute_input":"2024-09-22T06:45:24.386668Z","iopub.status.idle":"2024-09-22T06:45:24.392665Z","shell.execute_reply.started":"2024-09-22T06:45:24.386607Z","shell.execute_reply":"2024-09-22T06:45:24.391784Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['sentence', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 2264\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_ds=tokenized_ds.rename_column(\"label\", \"labels\")","metadata":{"execution":{"iopub.status.busy":"2024-09-22T06:45:24.394050Z","iopub.execute_input":"2024-09-22T06:45:24.394726Z","iopub.status.idle":"2024-09-22T06:45:24.409799Z","shell.execute_reply.started":"2024-09-22T06:45:24.394676Z","shell.execute_reply":"2024-09-22T06:45:24.408730Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_test_split=tokenized_ds['train'].train_test_split(test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T06:45:24.411120Z","iopub.execute_input":"2024-09-22T06:45:24.411434Z","iopub.status.idle":"2024-09-22T06:45:24.428312Z","shell.execute_reply.started":"2024-09-22T06:45:24.411403Z","shell.execute_reply":"2024-09-22T06:45:24.427574Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_ds=train_test_split['train']\nval_ds=train_test_split['test']","metadata":{"execution":{"iopub.status.busy":"2024-09-22T06:45:24.429458Z","iopub.execute_input":"2024-09-22T06:45:24.430043Z","iopub.status.idle":"2024-09-22T06:45:24.434383Z","shell.execute_reply.started":"2024-09-22T06:45:24.429999Z","shell.execute_reply":"2024-09-22T06:45:24.433446Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\nval_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])","metadata":{"execution":{"iopub.status.busy":"2024-09-22T06:45:24.436985Z","iopub.execute_input":"2024-09-22T06:45:24.437276Z","iopub.status.idle":"2024-09-22T06:45:24.443286Z","shell.execute_reply.started":"2024-09-22T06:45:24.437246Z","shell.execute_reply":"2024-09-22T06:45:24.442526Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_ds[0]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-22T06:45:24.444300Z","iopub.execute_input":"2024-09-22T06:45:24.444596Z","iopub.status.idle":"2024-09-22T06:45:24.498934Z","shell.execute_reply.started":"2024-09-22T06:45:24.444565Z","shell.execute_reply":"2024-09-22T06:45:24.498071Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'labels': tensor(1),\n 'input_ids': tensor([  101, 26850,  5620,  7479,  1012, 26850,  5620,  1012,  7367,  2097,\n          2468,  2112,  1997, 18906, 17619,  2474,  5946, 15451,  3775,  4063,\n          2422, 12278,  3131,  1012,   102,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0]),\n 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0])}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Load the model","metadata":{}},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(os.getenv(\"MODEL_NAME\"))\nmodel=BertForSequenceClassification.from_pretrained(os.getenv(\"MODEL_NAME\"), device_map=\"cuda\", num_labels=3) # 3 sentiment labels","metadata":{"execution":{"iopub.status.busy":"2024-09-22T06:45:24.500067Z","iopub.execute_input":"2024-09-22T06:45:24.500414Z","iopub.status.idle":"2024-09-22T06:45:26.819369Z","shell.execute_reply.started":"2024-09-22T06:45:24.500372Z","shell.execute_reply":"2024-09-22T06:45:26.818385Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e1ebf76a2144cc399217c5b2c9ce30e"}},"metadata":{}},{"name":"stderr","text":"A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nA parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\nA parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.device","metadata":{"execution":{"iopub.status.busy":"2024-09-22T06:45:26.820850Z","iopub.execute_input":"2024-09-22T06:45:26.821244Z","iopub.status.idle":"2024-09-22T06:45:26.827739Z","shell.execute_reply.started":"2024-09-22T06:45:26.821198Z","shell.execute_reply":"2024-09-22T06:45:26.826666Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\nimport numpy as np\n# from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=os.getenv(\"WANDB_NAME\"),\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    report_to=\"tensorboard\",\n    run_name=os.getenv('WANDB_NAME')\n)\n\n# Define a compute_metrics function for evaluation\n# def compute_metrics(eval_pred):\n#     logits, labels = eval_pred\n#     predictions = np.argmax(logits, axis=-1)\n#     precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n#     acc = accuracy_score(labels, predictions)\n#     return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n\n# Initialize the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds,\n    eval_dataset=val_ds,\n#     compute_metrics=compute_metrics,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-22T06:46:23.087757Z","iopub.execute_input":"2024-09-22T06:46:23.088152Z","iopub.status.idle":"2024-09-22T06:52:16.251243Z","shell.execute_reply.started":"2024-09-22T06:46:23.088114Z","shell.execute_reply":"2024-09-22T06:52:16.250281Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [384/384 05:50, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.164900</td>\n      <td>0.131920</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.132200</td>\n      <td>0.123158</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.009200</td>\n      <td>0.112018</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=384, training_loss=0.19538592130993493, metrics={'train_runtime': 352.0204, 'train_samples_per_second': 17.36, 'train_steps_per_second': 1.091, 'total_flos': 1607886095735808.0, 'train_loss': 0.19538592130993493, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Upload model to HF(optional)","metadata":{}},{"cell_type":"code","source":"kwargs={\n    'model_name': os.getenv(\"WANDB_NAME\"),\n    'finetuned_from': os.getenv('MODEL_NAME'),\n#     'tasks': 'Text-Generation',\n#     'dataset_tags':'',\n    'dataset': os.getenv(\"DATASET\")\n}\n\ntokenizer.push_to_hub(os.getenv(\"WANDB_NAME\"))\ntrainer.push_to_hub(**kwargs)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T06:56:51.503729Z","iopub.execute_input":"2024-09-22T06:56:51.504668Z","iopub.status.idle":"2024-09-22T06:57:10.912362Z","shell.execute_reply.started":"2024-09-22T06:56:51.504624Z","shell.execute_reply":"2024-09-22T06:57:10.911403Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a2b8866e28e467d90aae041b2473b18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5a5208dbe234fb6ad44c4a58b203d7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.24k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5732ee294c5341eab2cf548b021ff61d"}},"metadata":{}},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/aisuko/ft-bert-base-uncased-for-sentiment-classification/commit/3e930e0e0b724017039c2c053a1dfa38b98d2009', commit_message='End of training', commit_description='', oid='3e930e0e0b724017039c2c053a1dfa38b98d2009', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Acknowledgements\n\n* https://medium.com/gopenai/day-13-fine-tuning-llms-for-specific-use-cases-278c4535a468\n* https://www.kaggle.com/code/aisuko/mock-intermediate-level-challenge-1/notebook","metadata":{}}]}