{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aisuko/fine-tuning-phi-2-with-qlora?scriptVersionId=165487700\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Overview\n\nWe are going to fine-tune Microsoft Phi2 using QLoRA in this notebook.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"%%capture\n!pip install transformers==4.36.2\n!pip install accelerate==0.25.0\n!pip install datasets==2.15.0\n!pip install peft==0.7.1\n!pip install bitsandbytes==0.41.3","metadata":{"execution":{"iopub.status.busy":"2024-03-05T03:05:46.266646Z","iopub.execute_input":"2024-03-05T03:05:46.267127Z","iopub.status.idle":"2024-03-05T03:07:07.868476Z","shell.execute_reply.started":"2024-03-05T03:05:46.267085Z","shell.execute_reply":"2024-03-05T03:07:07.867182Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nlogin(token=user_secrets.get_secret(\"HUGGINGFACE_TOKEN\"))\n\nos.environ[\"WANDB_API_KEY\"]=user_secrets.get_secret(\"WANDB_API_KEY\")\nos.environ[\"WANDB_PROJECT\"] = \"Fine-tuning Microsoft-phi-2\"\nos.environ[\"WANDB_NAME\"] = \"ft-microsoft-phi-2\"\nos.environ[\"MODEL_NAME\"] = \"microsoft/phi-2\"\nos.environ[\"DATASET\"] = \"g-ronimo/riddles_evolved\"\n\ntorch.backends.cudnn.deterministic=True","metadata":{"execution":{"iopub.status.busy":"2024-03-05T03:07:07.870799Z","iopub.execute_input":"2024-03-05T03:07:07.871646Z","iopub.status.idle":"2024-03-05T03:07:12.868836Z","shell.execute_reply.started":"2024-03-05T03:07:07.871609Z","shell.execute_reply":"2024-03-05T03:07:12.867884Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"!accelerate estimate-memory ${MODEL_NAME} --library_name transformers","metadata":{"execution":{"iopub.status.busy":"2024-03-05T03:07:12.87034Z","iopub.execute_input":"2024-03-05T03:07:12.870819Z","iopub.status.idle":"2024-03-05T03:07:22.729251Z","shell.execute_reply.started":"2024-03-05T03:07:12.870782Z","shell.execute_reply":"2024-03-05T03:07:22.728261Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Loading pretrained config for `microsoft/phi-2` from `transformers`...\nconfig.json: 100%|█████████████████████████████| 863/863 [00:00<00:00, 5.54MB/s]\n┌────────────────────────────────────────────────────┐\n│     Memory Usage for loading `microsoft/phi-2`     │\n├───────┬─────────────┬──────────┬───────────────────┤\n│ dtype │Largest Layer│Total Size│Training using Adam│\n├───────┼─────────────┼──────────┼───────────────────┤\n│float32│   500.2 MB  │ 10.37 GB │      41.48 GB     │\n│float16│   250.1 MB  │ 5.19 GB  │      20.74 GB     │\n│  int8 │  125.05 MB  │ 2.59 GB  │      10.37 GB     │\n│  int4 │   62.52 MB  │  1.3 GB  │      5.19 GB      │\n└───────┴─────────────┴──────────┴───────────────────┘\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Loading Dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset=load_dataset(os.getenv(\"DATASET\"), split=\"train[:500]\")\ndataset=dataset.train_test_split(test_size=0.1)\nprint(dataset[\"train\"][0])\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-03-05T03:07:22.73162Z","iopub.execute_input":"2024-03-05T03:07:22.731947Z","iopub.status.idle":"2024-03-05T03:07:26.297749Z","shell.execute_reply.started":"2024-03-05T03:07:22.731919Z","shell.execute_reply":"2024-03-05T03:07:26.296782Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/938 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65e04247cc0a4f7d8cf4a3371f7e559b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d401b4a956e1446dbd91423d7d99cf19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.20M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fd1ebfd83434bf9b50fa924a327703f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cb3128c483341ce856bdf45f096c9bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1682 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6011b6a601904e29913ae779e25bfa3b"}},"metadata":{}},{"name":"stdout","text":"{'number': 412, 'messages': ['I am a word of six letters, the largest living organism is my kin, You cannot see or touch me, yet you can see all I touch, What am I?', 'The answer to this riddle is \"shadow.\" Shadows are formed when an object blocks the light, preventing it from reaching the ground or surface underneath. Although we cannot see or touch a shadow directly, we can see the objects or areas that cast the shadows. The largest living organism mentioned in the riddle is likely referring to the Armillaria ostoyae, also known as the honey mushroom, which forms the largest living organism by biomass in the world. Is there any specific information you need regarding the honey mushroom or the concept of shadows, or is the answer clear?', \"Wow, that's really cool! What's so special about the honey mushroom? Is it edible?\", \"The honey mushroom, scientifically known as Armillaria ostoyae, is a fascinating organism for several reasons. Its most notable feature is the vast network it forms, which can cover hundreds or even thousands of acres. This network is call a mycelium, and it consists of a mass of fine white threads called hyphae. The mycelium of an Armillaria ostoyae grows underground, and it forms symbiotic relationships with many trees and other organisms.\\n\\nThe honey mushroom is not directly related to the hive-building insects that give it its common name. Instead, the name comes from the way the mushrooms develop: they emerge along the main trunks of their host trees and appear as clusters of small, honey-colored caps, often growing side by side.\\n\\nEdibility of honey mushrooms is a topic of debate. Some people consider them a delicacy, while others caution against consuming them due to the potential for confusion with other Armillaria species that are toxic. The Armillaria ostoyae itself is generally considered safe to eat when cooked adequately. Nevertheless, it is always advised to consult an expert in mushroom foraging or consult reputable resources before consuming wild mushrooms. Cultivating honey mushrooms for consumption is becoming increasingly popular, providing a more reliable and safer source of this gourmet fungi.\\n\\nOne more interesting point about the honey mushroom: it's not actually a separate organism but rather a part of a larger, interconnected organism. This organism is actually a vast, interconnected mycelial network that can span hundreds to thousands of acres. Each individual organism in this network is connected by the mycelium and shares nutrients with other organisms around it, creating a complex, collaborative ecosystem.\"]}\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['number', 'messages'],\n        num_rows: 450\n    })\n    test: Dataset({\n        features: ['number', 'messages'],\n        num_rows: 50\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Loading Tokenizer\n\n* Loading tokenizer\n* Adding chatML tokens to tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer=AutoTokenizer.from_pretrained(os.getenv(\"MODEL_NAME\"), use_fast=False)\nprint(len(tokenizer))\n# add chatML tokens to tokenizer\ntokenizer.add_tokens([\"<|im_start|>\",\"<PAD>\"])\ntokenizer.pad_token=\"<PAD>\"\ntokenizer.add_special_tokens(dict(eos_token=\"<|im_end|>\"))\nprint(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2024-03-05T03:07:26.298939Z","iopub.execute_input":"2024-03-05T03:07:26.299375Z","iopub.status.idle":"2024-03-05T03:07:28.397967Z","shell.execute_reply.started":"2024-03-05T03:07:26.299348Z","shell.execute_reply":"2024-03-05T03:07:28.397064Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80de821e30a04d6aa1b0503ef0435afa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df2c82717eca4af8be1d8b1d50805d24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f50989001cda44bcb15174f9251372ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9de662b99aba4b7bb0770ba04e6bc14f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95811a0cba674bf4af2fba909d487bef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a41d8337bb14d75a08428bce39ddd07"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"50295\n50298\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Preprocess Data\n\nWe are going to apply ChatML format and tokenize to the data.","metadata":{}},{"cell_type":"code","source":"from functools import partial\n\ntemplates=[\n    '<|im_start|>assistant\\n{msg}<|im_end|>',\n    '<|im_start|>user\\n{msg}<|im_end|>'\n]\n\nIGNORE_INDEX=-100\n\ndef preprocess_func(input, max_length):\n    input_ids, attention_mask, labels=[],[],[]\n    for i, msg in enumerate(input[\"messages\"]):\n        isHuman=i%2==0\n        msg_chatml=templates[isHuman].format(msg=msg)\n        msg_tokenized=tokenizer(msg_chatml,truncation=False, add_special_tokens=False)\n        \n        input_ids+=msg_tokenized[\"input_ids\"]\n        attention_mask+=msg_tokenized[\"attention_mask\"]\n        labels+=[IGNORE_INDEX]*len(msg_tokenized[\"input_ids\"]) if isHuman else msg_tokenized[\"input_ids\"]\n\n    return {\n        \"input_ids\": input_ids[:max_length],\n        \"attention_mask\": attention_mask[:max_length],\n        \"labels\": labels[:max_length]\n    }\n\ndataset_tokenized=dataset.map(\n    partial(preprocess_func, max_length=1024), # max sample length 1024 tokens, enough for the dataset\n    batched=False,\n    num_proc=os.cpu_count(),\n    remove_columns=dataset[\"train\"].column_names # do not need this anymore, we have tokens from here on\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T03:07:28.399499Z","iopub.execute_input":"2024-03-05T03:07:28.40018Z","iopub.status.idle":"2024-03-05T03:07:34.296764Z","shell.execute_reply.started":"2024-03-05T03:07:28.400144Z","shell.execute_reply":"2024-03-05T03:07:34.295737Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/450 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d35cef566490467dbb6e4b108433c47f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/50 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c34582e116834a58871b54c6b53050a8"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Visualization data","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndata=[len(tok) for tok in (dataset_tokenized[\"train\"][\"input_ids\"]+dataset_tokenized[\"test\"][\"input_ids\"])]\nprint(f\"Longest sample: {max(data)} tokens\")\n\nplt.hist(data, bins=10)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-05T03:07:34.298231Z","iopub.execute_input":"2024-03-05T03:07:34.298637Z","iopub.status.idle":"2024-03-05T03:07:34.703637Z","shell.execute_reply.started":"2024-03-05T03:07:34.298603Z","shell.execute_reply":"2024-03-05T03:07:34.702745Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Longest sample: 924 tokens\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"# Batch the Data","metadata":{}},{"cell_type":"code","source":"def collate(example):\n    tokens=[e[\"input_ids\"] for e in example]\n    tokens_maxlen=max([len(t) for t in tokens])\n    \n    for i, sample in enumerate(example):\n        input_ids=sample[\"input_ids\"]\n        labels=sample[\"labels\"]\n        attention_mask=sample[\"attention_mask\"]\n        \n        pad_len=tokens_maxlen-len(input_ids)\n        \n        input_ids.extend(pad_len*[tokenizer.pad_token_id])\n        labels.extend(pad_len*[IGNORE_INDEX])\n        attention_mask.extend(pad_len*[0])\n        \n    batch={\n        \"input_ids\":torch.tensor([e[\"input_ids\"] for e in example]),\n        \"labels\":torch.tensor([e[\"labels\"] for e in example]),\n        \"attention_mask\": torch.tensor([e[\"attention_mask\"] for e in example])\n    }\n    \n    return batch","metadata":{"execution":{"iopub.status.busy":"2024-03-05T03:07:34.704724Z","iopub.execute_input":"2024-03-05T03:07:34.704983Z","iopub.status.idle":"2024-03-05T03:07:34.712329Z","shell.execute_reply.started":"2024-03-05T03:07:34.704961Z","shell.execute_reply":"2024-03-05T03:07:34.711402Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Loading Model\n\n* Quantization\n* Free the original weights\n* LoRA\n\nThere is no need to resize the token embeeddings, phi-2 already has embeddings sized for additional tokens. The model's vocabulary size is 51200, this means you can add ~700 tokens to the tokenizer without having to resize the embeddings.","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n\nbnb_config=BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    llm_int8_enable_fp32_cpu_offload=True,\n)\n\nmodel=AutoModelForCausalLM.from_pretrained(\n    os.getenv(\"MODEL_NAME\"),\n    quantization_config=bnb_config,\n    torch_dtype=torch.bfloat16,\n    device_map=\"auto\",\n    trust_remote_code=True, # for phi-2\n)\n\nmodel.config.eos_token_id=tokenizer.eos_token_id\nmodel.gradient_checkpointing_enable() # reducing memory usage\nprint(model.model.embed_tokens)\n\ndef print_trainable_parameters(model):\n    trainable_params=0\n    all_params=0\n    for _, param in model.named_parameters():\n        all_params+=param.numel()\n        if param.requires_grad:\n            trainable_params+=param.numel()\n    print(f\"trainable params: {trainable_params} || all params: {all_params} || trainable%: {100 * trainable_params/all_params:.2f}\")\n\nprint_trainable_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T03:07:34.713642Z","iopub.execute_input":"2024-03-05T03:07:34.71394Z","iopub.status.idle":"2024-03-05T03:08:15.987604Z","shell.execute_reply.started":"2024-03-05T03:07:34.713898Z","shell.execute_reply":"2024-03-05T03:08:15.986539Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"configuration_phi.py:   0%|          | 0.00/9.26k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c04ceab68d91401c8ad08e7712d85635"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-2:\n- configuration_phi.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_phi.py:   0%|          | 0.00/62.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4a765b90f564e3abbaa404dba1932e5"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-2:\n- modeling_phi.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c86eea97c1cb440e99818c6ce0848cd5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe46e40de07e477983e6358136a8617f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dafc3e42b7aa48d1b06e5d758cb58201"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afb8b75c2b984a46a43e89b700213f0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b26bf59895804d8b98661d05d9bf156f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b496a1dd36ae4a45bb332902bb62a35e"}},"metadata":{}},{"name":"stdout","text":"Embedding(51200, 2560)\ntrainable params: 262364160 || all params: 1521392640 || trainable%: 17.24\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Freeze weigths and apply LoRA","metadata":{}},{"cell_type":"code","source":"from peft import prepare_model_for_kbit_training\n\nprepared_model=prepare_model_for_kbit_training(\n    model, use_gradient_checkpointing=True\n)\n\nprint_trainable_parameters(prepared_model)\nprint(prepared_model)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T03:08:15.990647Z","iopub.execute_input":"2024-03-05T03:08:15.99112Z","iopub.status.idle":"2024-03-05T03:08:16.066488Z","shell.execute_reply.started":"2024-03-05T03:08:15.991094Z","shell.execute_reply":"2024-03-05T03:08:16.06527Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"trainable params: 0 || all params: 1521392640 || trainable%: 0.00\nPhiForCausalLM(\n  (model): PhiModel(\n    (embed_tokens): Embedding(51200, 2560)\n    (embed_dropout): Dropout(p=0.0, inplace=False)\n    (layers): ModuleList(\n      (0-31): 32 x PhiDecoderLayer(\n        (self_attn): PhiAttention(\n          (q_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n          (k_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n          (v_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n          (dense): Linear4bit(in_features=2560, out_features=2560, bias=True)\n          (rotary_emb): PhiRotaryEmbedding()\n        )\n        (mlp): PhiMLP(\n          (activation_fn): NewGELUActivation()\n          (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n          (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n        )\n        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=2560, out_features=51200, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"from peft import LoraConfig, TaskType, get_peft_model\n\nlora_config=LoraConfig(\n    r=16,\n    lora_alpha=16,\n    target_modules=['q_proj', 'k_proj', 'v_proj', 'dense'],\n    lora_dropout=0.1,\n    bias=\"none\",\n    modules_to_save=[\"lm_head\",\"embed_tokens\"], # we added new tokens to tokenizer, this is necesarry\n    task_type=TaskType.CAUSAL_LM\n)\n\nlora_model=get_peft_model(prepared_model, lora_config)\nlora_model.config.use_cache=False\nprint_trainable_parameters(lora_model)\nprint(lora_model)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T03:08:16.06775Z","iopub.execute_input":"2024-03-05T03:08:16.068125Z","iopub.status.idle":"2024-03-05T03:08:20.611576Z","shell.execute_reply.started":"2024-03-05T03:08:16.068091Z","shell.execute_reply":"2024-03-05T03:08:20.61057Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"trainable params: 272680960 || all params: 1794073600 || trainable%: 15.20\nPeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): PhiForCausalLM(\n      (model): PhiModel(\n        (embed_tokens): ModulesToSaveWrapper(\n          (original_module): Embedding(51200, 2560)\n          (modules_to_save): ModuleDict(\n            (default): Embedding(51200, 2560)\n          )\n        )\n        (embed_dropout): Dropout(p=0.0, inplace=False)\n        (layers): ModuleList(\n          (0-31): 32 x PhiDecoderLayer(\n            (self_attn): PhiAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2560, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=2560, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2560, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=2560, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2560, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=2560, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (dense): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2560, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=2560, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (rotary_emb): PhiRotaryEmbedding()\n            )\n            (mlp): PhiMLP(\n              (activation_fn): NewGELUActivation()\n              (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n              (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n            )\n            (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n            (resid_dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      )\n      (lm_head): ModulesToSaveWrapper(\n        (original_module): Linear(in_features=2560, out_features=51200, bias=True)\n        (modules_to_save): ModuleDict(\n          (default): Linear(in_features=2560, out_features=51200, bias=True)\n        )\n      )\n    )\n  )\n)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"from transformers import set_seed, TrainingArguments, Trainer\n\nset_seed(2024)\n\nbs=2\nbs_eval=4\nga_steps=16\nlr=0.00002\nepochs=2\n\nsteps_per_epoch=len(dataset_tokenized[\"train\"])//(bs*ga_steps)\n\nargs=TrainingArguments(\n    output_dir=os.getenv(\"WANDB_NAME\"),\n    per_device_train_batch_size=bs,\n    per_device_eval_batch_size=bs_eval,\n    evaluation_strategy=\"steps\",\n    logging_steps=1,\n    eval_steps=steps_per_epoch//2,\n    save_steps=steps_per_epoch,\n    gradient_accumulation_steps=ga_steps,\n    num_train_epochs=epochs,\n    lr_scheduler_type=\"constant\",\n    optim=\"paged_adamw_32bit\", # val_loss will go nan with paged_adamw_8bit\n    learning_rate=lr,\n    group_by_length=False,\n    fp16=True,\n    ddp_find_unused_parameters=False,\n    report_to='wandb',\n    run_name=os.getenv('WANDB_NAME')\n)\n\ntrainer=Trainer(\n    model=lora_model,\n    tokenizer=tokenizer,\n    args=args,\n    data_collator=collate,\n    train_dataset=dataset_tokenized[\"train\"],\n    eval_dataset=dataset_tokenized[\"test\"]\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-05T03:08:20.612576Z","iopub.execute_input":"2024-03-05T03:08:20.612829Z","iopub.status.idle":"2024-03-05T03:32:03.364827Z","shell.execute_reply.started":"2024-03-05T03:08:20.612806Z","shell.execute_reply":"2024-03-05T03:32:03.363657Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"2024-03-05 03:08:22.906675: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-05 03:08:22.906808: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-05 03:08:23.075506: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33murakiny\u001b[0m (\u001b[33mcausal_language_trainer\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240305_030834-psrn34gi</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/causal_language_trainer/Fine-tuning%20Microsoft-phi-2/runs/psrn34gi' target=\"_blank\">ft-microsoft-phi-2</a></strong> to <a href='https://wandb.ai/causal_language_trainer/Fine-tuning%20Microsoft-phi-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/causal_language_trainer/Fine-tuning%20Microsoft-phi-2' target=\"_blank\">https://wandb.ai/causal_language_trainer/Fine-tuning%20Microsoft-phi-2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/causal_language_trainer/Fine-tuning%20Microsoft-phi-2/runs/psrn34gi' target=\"_blank\">https://wandb.ai/causal_language_trainer/Fine-tuning%20Microsoft-phi-2/runs/psrn34gi</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [28/28 22:17, Epoch 1/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>7</td>\n      <td>1.759000</td>\n      <td>1.685468</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>1.596400</td>\n      <td>1.635313</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>1.681900</td>\n      <td>1.591179</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>1.537300</td>\n      <td>1.540736</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=28, training_loss=1.6597118760858263, metrics={'train_runtime': 1410.4876, 'train_samples_per_second': 0.638, 'train_steps_per_second': 0.02, 'total_flos': 6221645500723200.0, 'train_loss': 1.6597118760858263, 'epoch': 1.99})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import GenerationConfig\n\nkwargs={\n    'model_name': f'{os.getenv(\"WANDB_NAME\")}',\n    'finetuned_from': os.getenv('MODEL_NAME'),\n#     'tasks': '',\n#     'dataset_tags':'',\n    'dataset': os.getenv(\"DATASET\")\n}\n\ngeneration_config=GenerationConfig(\n    max_new_tokens=100,\n    temperature=0.7,\n    top_p=0.1,\n    top_k=40,\n    repetition_penalty=1.18,\n    do_sample=True,\n    pad_token_id=tokenizer.pad_token_id,\n    eos_token_id=tokenizer.eos_token_id\n)\n\ngeneration_config.save_pretrained('aisuko/'+os.getenv('WANDB_NAME'), push_to_hub=True)\ntokenizer.push_to_hub(os.getenv(\"WANDB_NAME\"))\ntrainer.push_to_hub(**kwargs)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T03:32:03.36652Z","iopub.execute_input":"2024-03-05T03:32:03.367449Z","iopub.status.idle":"2024-03-05T03:32:37.623507Z","shell.execute_reply.started":"2024-03-05T03:32:03.367409Z","shell.execute_reply":"2024-03-05T03:32:37.621655Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/4.73k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"732e89b076f948ce885e54019a78fc13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/1.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eeb134034f9e43ed951acad3923c3820"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b57202ec0694cc68a0a718adbe1be83"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/aisuko/ft-microsoft-phi-2/commit/d187c09f68635333f0b1aa31da8971fee17d446a', commit_message='End of training', commit_description='', oid='d187c09f68635333f0b1aa31da8971fee17d446a', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"import gc\n\ndel tokenizer, lora_model, prepared_model, model\n\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-03-05T03:51:44.317935Z","iopub.execute_input":"2024-03-05T03:51:44.318331Z","iopub.status.idle":"2024-03-05T03:51:44.755753Z","shell.execute_reply.started":"2024-03-05T03:51:44.318301Z","shell.execute_reply":"2024-03-05T03:51:44.7547Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"tokenizer=AutoTokenizer.from_pretrained(os.getenv(\"MODEL_NAME\"), use_fast=False)\ntokenizer.add_tokens([\"<|im_start|>\",\"<PAD>\"])\ntokenizer.pad_token=\"<PAD>\"\ntokenizer.add_special_tokens(dict(eos_token=\"<|im_end|>\"))\n\ntokenizer.chat_template=\"{% if not add_generation_prompt is defined%}{% set add_generation_prompt=false%}{%endif%}{%for message in messages%}{{'<|im_start|>'+message['role']+message['content']+'<|im_end|>'}}{%endfor%}{%if add_generation_prompt%}{{'<|im_start|>assistant'}}{%endif%}\"","metadata":{"execution":{"iopub.status.busy":"2024-03-05T03:51:50.768491Z","iopub.execute_input":"2024-03-05T03:51:50.769533Z","iopub.status.idle":"2024-03-05T03:51:50.999809Z","shell.execute_reply.started":"2024-03-05T03:51:50.769495Z","shell.execute_reply":"2024-03-05T03:51:50.998606Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"model=AutoModelForCausalLM.from_pretrained(os.getenv(\"MODEL_NAME\"), torch_dtype=torch.bfloat16,trust_remote_code=True, device_map=\"auto\")\nmodel.config.eos_token_id=tokenizer.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2024-03-05T03:52:41.432608Z","iopub.execute_input":"2024-03-05T03:52:41.433464Z","iopub.status.idle":"2024-03-05T03:53:05.204677Z","shell.execute_reply.started":"2024-03-05T03:52:41.433425Z","shell.execute_reply":"2024-03-05T03:53:05.203241Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a16d508c2fd4b77a393be00df789a5d"}},"metadata":{}}]},{"cell_type":"code","source":"from peft import PeftModel\n\ngeneration_config=GenerationConfig(\n    max_new_tokens=100,\n    temperature=0.7,\n    top_p=0.1,\n    top_k=40,\n    repetition_penalty=1.18,\n    do_sample=True,\n    pad_token_id=tokenizer.pad_token_id,\n    eos_token_id=tokenizer.eos_token_id\n)\n\nmodel=PeftModel.from_pretrained(model, os.getenv(\"WANDB_NAME\"))\nmodel=model.merge_and_unload()\n\nquestion=\"Hello, Who are you\"\nmessages=[{\"role\":\"user\",\"content\":question}]\n\ninput_tokens=tokenizer.apply_chat_template(\n    messages,\n    add_generation_prompt=True,\n    return_tensors=\"pt\"\n).to('cuda')\n\noutput_tokens=model.generate(input_tokens)\noutput=tokenizer.decode(output_tokens[0][len(input_tokens[0]):], skip_special_tokens=True)\nprint(output)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T03:54:14.048566Z","iopub.execute_input":"2024-03-05T03:54:14.048948Z","iopub.status.idle":"2024-03-05T03:54:43.584467Z","shell.execute_reply.started":"2024-03-05T03:54:14.048917Z","shell.execute_reply":"2024-03-05T03:54:43.583278Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained(os.getenv(\"WANDB_NAME\"), safe_serialization=True, max_shared_size=\"4GB\")\n\nmodel.push_to_hub(os.getenv(\"WANDB_NAME\"))\ntokenizer.save_pretrained(os.getenv(\"WANDB_NAME\"), push_to_hub=True)\ngeneration_config.save_pretrained(os.getenv(\"WANDB_NAME\"), push_to_hub=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T04:02:20.599192Z","iopub.execute_input":"2024-03-05T04:02:20.599577Z","iopub.status.idle":"2024-03-05T04:03:27.534402Z","shell.execute_reply.started":"2024-03-05T04:02:20.599547Z","shell.execute_reply":"2024-03-05T04:03:27.53316Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# Reference List\n\n* https://medium.com/@geronimo7/phinetuning-2-0-28a2be6de110\n* https://github.com/geronimi73/phi2-finetune/blob/main/nb_qlora.ipynb\n* https://www.kaggle.com/code/aisuko/text-summarization-with-bart-series-llm\n* https://www.kaggle.com/code/aisuko/fine-tuning-microsoft-phi2","metadata":{}}]}