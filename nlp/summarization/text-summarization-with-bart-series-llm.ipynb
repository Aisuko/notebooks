{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aisuko/text-summarization-with-bart-series-llm?scriptVersionId=163496659\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Overview\n\nIn this notebook, we will fine-tune `facebook/bart-large-xsum` model on `SamSum` dataset.\n\nNote: There is a technique we did not mentioned in the previously notebook. It is `transfer learning`, we can also call it `fine-tuning`.\n\n\n# Evaluation Strategy\n\nEvaluating performance for language models can be quite tricky, especially when it comes to text summarization. The goal of our model is to produce a short sentence describing the content of a dialogue, while maintaining all the important information within that dialogue.\n\nOne of the quantitative metrics we can employ to evaluate performance is the `ROUGE Score`. It is considered one of the best metrics for text summarization and it evaluates performance by comparing the quality of a machine-generated summary to a human generated summary used for reference.\n\nThe similarities between both summaries are measured by analyzing the overlapping `n-grams`, either single words of sequences of words that are present in both summaries. These can be unigrams(ROUGE-1), where only the overlap of sole words is measured; biggrams(ROUGE-2), where we measure the overlap of two-word sequencesl trigrams(ROUGE-3), where we measrure the overlap of three-word sequences; etc. Besides that, we also have:\n\n\n**ROUGE-L**\n\nIt measures the *Longest Common Subsequence(LCS)* between the two summaries, which helps to capture content coverage of the machine-generated text. If both summaries have the sequence \"the apple is green\", we have a match regardless of where they appear in both texts.\n\n**ROUGE-S**\n\nIt avaluates the overlap of skip-bigrams, which are bigrams that permit gaps between words. This helps to measure the coherence of a machine-generated summary. For example, in the phrase \"this apple is absolutely green\", we find a match for the terms such as \"apple\" and \"green\", if that is what we are looking for.\n\nThese scores might typically range from 0 to 100, where 0 indicates no match and 100 indicates a perfect match between both summaries. Besides quantitative metrics, it is useful to use `human evaluation` to analyze the output of language models, since we are able to comprehend text in a wat that a machine does not.\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!nvidia-smi # Checking GPU","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture --no-stderr\n!pip install transformers==4.37.2\n!pip install datasets==2.17.0\n!pip install evaluate==0.4.1\n!pip install rouge-score==0.1.2\n# Installing library to save zip archives\n!pip install py7zr==0.20.8","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nlogin(token=user_secrets.get_secret(\"HUGGINGFACE_TOKEN\"))\n\nos.environ['MODEL']='facebook/bart-large-xsum'\n\nos.environ[\"WANDB_API_KEY\"]=user_secrets.get_secret(\"WANDB_API_KEY\")\nos.environ[\"WANDB_PROJECT\"] = \"Fine-tuning HuBERT\"\nos.environ[\"WANDB_NOTES\"] = \"Fine-tuning HuBERT on gtzan\"\nos.environ[\"WANDB_NAME\"] = \"ft-hubert-on-gtzan\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\n\nwarnings.filterwarnings('ignore')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Handling\nimport pandas as pd\n\ntrain=pd.read_csv('/kaggle/input/samsum-dataset-text-summarization/samsum-train.csv')\ntest=pd.read_csv('/kaggle/input/samsum-dataset-text-summarization/samsum-test.csv')\nval=pd.read_csv('/kaggle/input/samsum-dataset-text-summarization/samsum-validation.csv')\ntype(train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the notebook [Visualisation and Statistic SamSum Dataset](https://www.kaggle.com/code/aisuko/visualisation-and-statistic-samsum-dataset), we can see that some tags in a few texts, such as `file_photo` in dialogue. Let's remove these tags from the texts.","metadata":{}},{"cell_type":"code","source":"print(train['dialogue'].iloc[14727])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_tags(text):\n    clean=re.complie('<.*?>') # compiling tags\n    clean=re.sub(clean, '', text) # replacing tags text by an empty string\n    \n    # removing empty dialogues\n    clean='\\n'.join([line for line in clean.split('\\n') if not re.match('.*:\\s*$', line)])\n    return clean\n\ntest1=clean_tags(train['dialogue'].iloc[14727])\ntest2=clean_tags(test['dialogue'].iloc[0])\n\nprint(test1)\nprint('\\n'*3)\nprint(test2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's define a function and apply `clean_tags` to the entire datasets. It's beneficial to conduct such data cleansing to eliminate noise-information.","metadata":{}},{"cell_type":"code","source":"def clean_df(df, cols):\n    for col in cols:\n        df[col]=df[col].fillna('').apply(clean_tags)\n    return df\n\ntrain=clean_df(train, ['dialogue','summary'])\ntest=clean_df(test, ['dialogue', 'summary'])\nval=clean_df(val, ['dialogue', 'summary'])\n\n# visualizing results\ntrain.tail(3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Handling\nfrom datasets import Dataset, load_metric\n\ntrain_ds=Dataset.from_pandas(train)\ntest_ds=Dataset.from_pandas(test)\nval_ds=Dataset.from_pandas(val)\n\nprint(train_ds)\nprint('\\n'*2)\nprint(test_ds)\nprint('\\n'*2)\nprint(val_ds)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds[0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\nsummarizer=pipeline('summarization', model=os.getenv('MODEL'))\n\nnews='''Melbourne, Australia, a vibrant city pulsating with energy, seamlessly blends historical charm with modern dynamism. Nestled on the southeastern coast, it beckons with iconic landmarks, hidden alleyways teeming with artistic expression, and a diverse culinary scene that tantalizes every palate. Immerse yourself in the city's soul at Federation Square, a modern marvel where plazas, bars, and restaurants pulsate with life beside the Yarra River. Delve into Melbourne's artistic heart, the Southbank Arts Precinct, where the renowned Arts Centre Melbourne stages captivating performances and the National Gallery of Victoria houses a treasure trove of Australian and international art. Beyond the cultural haven, Melbourne's laneways unveil a hidden world. These narrow passageways, once industrial backstreets, have transformed into vibrant arteries brimming with trendy cafes, eclectic street art, and hidden bars, pulsating with a unique character. Explore Hosier Lane, adorned with captivating murals, or AC/DC Lane, a haven for rock n' roll memorabilia and hidden bars. Melbourne's culinary scene is a symphony of flavors, a testament to its multicultural tapestry. Michelin-starred restaurants offer exquisite experiences, while hidden gems tucked away in laneways tantalize with innovative dishes. Venture beyond the city center and discover the Yarra Valley, a renowned wine region, or embark on the Great Ocean Road, a world-famous coastal drive unfolding breathtaking scenery. Escape the urban buzz in the Dandenong Ranges, a haven of lush rainforests and charming villages. Melbourne's cultural tapestry is as diverse as its population, acknowledging the traditional owners and celebrating their heritage through various initiatives. Vibrant festivals showcase the city's multicultural spirit, and Melbourne embraces inclusivity, fostering a thriving LGBTQ+ community. As the sun sets, Melbourne's nightlife ignites, offering rooftop bars with stunning cityscapes, intimate jazz clubs pulsating with live music, and underground dance floors catering to all musical tastes. Melbourne defies definition, a symphony of experiences where history whispers, art bursts forth, and flavors tantalize. It's a city that embraces diversity, celebrates creativity, and pulsates with an infectious energy that lingers long after your visit.'''\n\nsummarizer(news)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transfromers import BartTokenizer, BartForConditionalGeneration # BERT Tokenizer and architecture\n\ntokenizer=BartTokenizer.from_pertrained(os.getenv('MODEL'))\ntokenizer","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=BartForConditionalGeneration.from_pretrained(os.getenv('MODEL'))\nprint(model)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is possible to see that models consist of an encoder and a decoder, we can see the Linear Layers, as well as the activation functions, which use $GeLU$, instead of the more typical $ReLU$. It is also interesting to observe the output layer, **lm_head**, which shows us that this model is ideal for generating outputs with a vocabulary size - `out_features=50264` - this shows us that this architecture","metadata":{}}]}