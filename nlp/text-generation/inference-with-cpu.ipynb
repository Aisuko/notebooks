{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aisuko/inference-with-cpu?scriptVersionId=164530532\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"52f1d867","metadata":{"papermill":{"duration":0.005672,"end_time":"2024-02-27T11:35:52.159127","exception":false,"start_time":"2024-02-27T11:35:52.153455","status":"completed"},"tags":[]},"source":["# DeepSpare\n","\n","It is a CPU inference runtime that takes advantages of sparsity to accelerate neural network inference. Coupled with SparseML(A optimization library for pruning and quantizing models). DeepSpare delivers exceptional inference performance on CPU hardware.\n","\n","\n","# Features\n","* Sparse kernels for speedups and memory savings from unstructured sparse weights\n","* 8-bit weight and activation quantization support\n","* Efficient usage of cached attention keys and values for minimal memory movement\n","\n","\n","# Checking if CPU support AVX and AVX2"]},{"cell_type":"code","execution_count":1,"id":"52c67ab5","metadata":{"execution":{"iopub.execute_input":"2024-02-27T11:35:52.172208Z","iopub.status.busy":"2024-02-27T11:35:52.171279Z","iopub.status.idle":"2024-02-27T11:35:53.326175Z","shell.execute_reply":"2024-02-27T11:35:53.324216Z"},"papermill":{"duration":1.165721,"end_time":"2024-02-27T11:35:53.330011","exception":false,"start_time":"2024-02-27T11:35:52.16429","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\r\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\r\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\r\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\r\n"]}],"source":["!grep avx /proc/cpuinfo"]},{"cell_type":"code","execution_count":2,"id":"edcad13e","metadata":{"execution":{"iopub.execute_input":"2024-02-27T11:35:53.342963Z","iopub.status.busy":"2024-02-27T11:35:53.342497Z","iopub.status.idle":"2024-02-27T11:35:54.470501Z","shell.execute_reply":"2024-02-27T11:35:54.468888Z"},"papermill":{"duration":1.13913,"end_time":"2024-02-27T11:35:54.474143","exception":false,"start_time":"2024-02-27T11:35:53.335013","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\r\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\r\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\r\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\r\n"]}],"source":["!grep avx2 /proc/cpuinfo"]},{"cell_type":"markdown","id":"32114378","metadata":{"papermill":{"duration":0.006367,"end_time":"2024-02-27T11:35:54.487019","exception":false,"start_time":"2024-02-27T11:35:54.480652","status":"completed"},"tags":[]},"source":["# Installation\n","\n","Here are two ways to install deepsparse:\n","* `pip install -U deepsparse-nightly[llm]`\n","* `pip install deepsparse`\n","\n","However, the latest stable version in Kaggle environment will cause issue `ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.`\n","\n","I guess it needs specific version of transformers."]},{"cell_type":"code","execution_count":3,"id":"56a33be5","metadata":{"execution":{"iopub.execute_input":"2024-02-27T11:35:54.501591Z","iopub.status.busy":"2024-02-27T11:35:54.501119Z","iopub.status.idle":"2024-02-27T11:36:46.044287Z","shell.execute_reply":"2024-02-27T11:36:46.041796Z"},"papermill":{"duration":51.554068,"end_time":"2024-02-27T11:36:46.047708","exception":false,"start_time":"2024-02-27T11:35:54.49364","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting deepsparse-nightly[llm]\r\n","  Obtaining dependency information for deepsparse-nightly[llm] from https://files.pythonhosted.org/packages/9c/8e/4087b342e07536edc09bac5abac6b748bef0f9aed6fd068f08e0f8e545d2/deepsparse_nightly-1.7.0.20240131-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n","  Downloading deepsparse_nightly-1.7.0.20240131-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\r\n","Collecting sparsezoo-nightly~=1.7.0 (from deepsparse-nightly[llm])\r\n","  Obtaining dependency information for sparsezoo-nightly~=1.7.0 from https://files.pythonhosted.org/packages/5f/23/42f0298c587914186ef490c0975ed8f2ee8c9bb0a1a0686f47f56d570661/sparsezoo_nightly-1.7.0.20240131-py3-none-any.whl.metadata\r\n","  Downloading sparsezoo_nightly-1.7.0.20240131-py3-none-any.whl.metadata (21 kB)\r\n","Requirement already satisfied: numpy>=1.16.3 in /opt/conda/lib/python3.10/site-packages (from deepsparse-nightly[llm]) (1.24.3)\r\n","Collecting onnx<1.15.0,>=1.5.0 (from deepsparse-nightly[llm])\r\n","  Obtaining dependency information for onnx<1.15.0,>=1.5.0 from https://files.pythonhosted.org/packages/47/d4/f2d212558245e252b936247666c3f5981e6dba62ec470ff8be3df3389364/onnx-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n","  Downloading onnx-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\r\n","Requirement already satisfied: pydantic<2.0.0,>=1.8.2 in /opt/conda/lib/python3.10/site-packages (from deepsparse-nightly[llm]) (1.10.12)\r\n","Requirement already satisfied: requests>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from deepsparse-nightly[llm]) (2.31.0)\r\n","Requirement already satisfied: tqdm>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from deepsparse-nightly[llm]) (4.66.1)\r\n","Requirement already satisfied: protobuf>=3.12.2 in /opt/conda/lib/python3.10/site-packages (from deepsparse-nightly[llm]) (3.20.3)\r\n","Requirement already satisfied: click!=8.0.0,>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from deepsparse-nightly[llm]) (8.1.7)\r\n","Requirement already satisfied: transformers<4.37 in /opt/conda/lib/python3.10/site-packages (from deepsparse-nightly[llm]) (4.35.0)\r\n","Requirement already satisfied: datasets<2.16 in /opt/conda/lib/python3.10/site-packages (from deepsparse-nightly[llm]) (2.1.0)\r\n","Requirement already satisfied: accelerate<0.26 in /opt/conda/lib/python3.10/site-packages (from deepsparse-nightly[llm]) (0.24.1)\r\n","Collecting seqeval (from deepsparse-nightly[llm])\r\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate<0.26->deepsparse-nightly[llm]) (21.3)\r\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate<0.26->deepsparse-nightly[llm]) (5.9.3)\r\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate<0.26->deepsparse-nightly[llm]) (6.0.1)\r\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate<0.26->deepsparse-nightly[llm]) (2.0.0+cpu)\r\n","Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate<0.26->deepsparse-nightly[llm]) (0.17.3)\r\n","Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets<2.16->deepsparse-nightly[llm]) (9.0.0)\r\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets<2.16->deepsparse-nightly[llm]) (0.3.7)\r\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets<2.16->deepsparse-nightly[llm]) (2.0.3)\r\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets<2.16->deepsparse-nightly[llm]) (3.4.1)\r\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets<2.16->deepsparse-nightly[llm]) (0.70.15)\r\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets<2.16->deepsparse-nightly[llm]) (2023.10.0)\r\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets<2.16->deepsparse-nightly[llm]) (3.8.5)\r\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets<2.16->deepsparse-nightly[llm]) (0.18.0)\r\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /opt/conda/lib/python3.10/site-packages (from onnx<1.15.0,>=1.5.0->deepsparse-nightly[llm]) (4.5.0)\r\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.0.0->deepsparse-nightly[llm]) (3.2.0)\r\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.0.0->deepsparse-nightly[llm]) (3.4)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.0.0->deepsparse-nightly[llm]) (1.26.15)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.0.0->deepsparse-nightly[llm]) (2023.7.22)\r\n","Collecting py-machineid>=0.3.0 (from sparsezoo-nightly~=1.7.0->deepsparse-nightly[llm])\r\n","  Obtaining dependency information for py-machineid>=0.3.0 from https://files.pythonhosted.org/packages/44/57/091f3baf06ab1e240ca4d863fe94a9dba39ec8faa49d4cae7e2ac68eeef5/py_machineid-0.5.1-py3-none-any.whl.metadata\r\n","  Downloading py_machineid-0.5.1-py3-none-any.whl.metadata (2.3 kB)\r\n","Collecting geocoder>=1.38.0 (from sparsezoo-nightly~=1.7.0->deepsparse-nightly[llm])\r\n","  Downloading geocoder-1.38.1-py2.py3-none-any.whl (98 kB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers<4.37->deepsparse-nightly[llm]) (3.12.2)\r\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<4.37->deepsparse-nightly[llm]) (2023.8.8)\r\n","Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<4.37->deepsparse-nightly[llm]) (0.14.1)\r\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<4.37->deepsparse-nightly[llm]) (0.4.0)\r\n","Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval->deepsparse-nightly[llm]) (1.2.2)\r\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<2.16->deepsparse-nightly[llm]) (23.1.0)\r\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<2.16->deepsparse-nightly[llm]) (6.0.4)\r\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<2.16->deepsparse-nightly[llm]) (4.0.3)\r\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<2.16->deepsparse-nightly[llm]) (1.9.2)\r\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<2.16->deepsparse-nightly[llm]) (1.4.0)\r\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<2.16->deepsparse-nightly[llm]) (1.3.1)\r\n","Requirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from geocoder>=1.38.0->sparsezoo-nightly~=1.7.0->deepsparse-nightly[llm]) (0.18.3)\r\n","Collecting ratelim (from geocoder>=1.38.0->sparsezoo-nightly~=1.7.0->deepsparse-nightly[llm])\r\n","  Downloading ratelim-0.1.6-py2.py3-none-any.whl (4.0 kB)\r\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from geocoder>=1.38.0->sparsezoo-nightly~=1.7.0->deepsparse-nightly[llm]) (1.16.0)\r\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate<0.26->deepsparse-nightly[llm]) (3.0.9)\r\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets<2.16->deepsparse-nightly[llm]) (2.8.2)\r\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets<2.16->deepsparse-nightly[llm]) (2023.3)\r\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets<2.16->deepsparse-nightly[llm]) (2023.3)\r\n","Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->deepsparse-nightly[llm]) (1.11.3)\r\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->deepsparse-nightly[llm]) (1.3.2)\r\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->deepsparse-nightly[llm]) (3.2.0)\r\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate<0.26->deepsparse-nightly[llm]) (1.12)\r\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate<0.26->deepsparse-nightly[llm]) (3.1)\r\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate<0.26->deepsparse-nightly[llm]) (3.1.2)\r\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate<0.26->deepsparse-nightly[llm]) (2.1.3)\r\n","Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ratelim->geocoder>=1.38.0->sparsezoo-nightly~=1.7.0->deepsparse-nightly[llm]) (5.1.1)\r\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate<0.26->deepsparse-nightly[llm]) (1.3.0)\r\n","Downloading onnx-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading sparsezoo_nightly-1.7.0.20240131-py3-none-any.whl (172 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading deepsparse_nightly-1.7.0.20240131-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.3 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading py_machineid-0.5.1-py3-none-any.whl (4.7 kB)\r\n","Building wheels for collected packages: seqeval\r\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n","\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=053cf96a8c8687933fb04b181df2daa02cd20828e4c05d8240b632156f4346fb\r\n","  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\r\n","Successfully built seqeval\r\n","Installing collected packages: py-machineid, ratelim, onnx, geocoder, sparsezoo-nightly, seqeval, deepsparse-nightly\r\n","  Attempting uninstall: onnx\r\n","    Found existing installation: onnx 1.15.0\r\n","    Uninstalling onnx-1.15.0:\r\n","      Successfully uninstalled onnx-1.15.0\r\n","Successfully installed deepsparse-nightly-1.7.0.20240131 geocoder-1.38.1 onnx-1.14.1 py-machineid-0.5.1 ratelim-0.1.6 seqeval-1.2.2 sparsezoo-nightly-1.7.0.20240131\r\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install -U deepsparse-nightly[llm]"]},{"cell_type":"markdown","id":"fd5237d6","metadata":{"papermill":{"duration":0.024954,"end_time":"2024-02-27T11:36:46.095519","exception":false,"start_time":"2024-02-27T11:36:46.070565","status":"completed"},"tags":[]},"source":["# Demo of Inference"]},{"cell_type":"code","execution_count":4,"id":"6317c8dc","metadata":{"execution":{"iopub.execute_input":"2024-02-27T11:36:46.142682Z","iopub.status.busy":"2024-02-27T11:36:46.142159Z","iopub.status.idle":"2024-02-27T11:48:44.838111Z","shell.execute_reply":"2024-02-27T11:48:44.835924Z"},"papermill":{"duration":718.743046,"end_time":"2024-02-27T11:48:44.861179","exception":false,"start_time":"2024-02-27T11:36:46.118133","status":"completed"},"tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3eb767a5d09a45e7ab522aa1784199f9","version_major":2,"version_minor":0},"text/plain":["Downloading (…)ed/deployment.tar.gz:   0%|          | 0.00/3.04G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["DeepSparse, Copyright 2021-present / Neuralmagic, Inc. version: 1.7.0.20240131 COMMUNITY | (1ddb9f31) (release) (optimized) (system=avx2, binary=avx2)\n","[7c10a4ffe700 >WARN<  operator() ./src/include/wand/utility/warnings.hpp:14] Generating emulated code for quantized (INT8) operations since no VNNI instructions were detected. Set NM_FAST_VNNI_EMULATION=1 to increase performance at the expense of accuracy.\n"]},{"name":"stdout","output_type":"stream","text":["Sparsity is the number of non-zero elements in a matrix. For example, in the matrix A = [1, 2, 3, 4, 5, 6, 7, 8, 9] the number of non-zero elements is 3.\n"]}],"source":["from deepsparse import TextGeneration\n","\n","pipeline = TextGeneration(model=\"zoo:mpt-7b-dolly_mpt_pretrain-pruned50_quantized\")\n","\n","prompt=\"\"\"\n","Below is aninstruction that describes a task. Write a response that appropriately completes the request. ### Instruction: what is sparsity? ### Response:\n","\"\"\"\n","\n","print(pipeline(prompt, max_new_tokens=75).generations[0].text)"]},{"cell_type":"markdown","id":"a40becef","metadata":{"papermill":{"duration":0.024059,"end_time":"2024-02-27T11:48:44.907903","exception":false,"start_time":"2024-02-27T11:48:44.883844","status":"completed"},"tags":[]},"source":["# Computer Vision and NLP Models\n","\n","DeepSparse supports many variants of CNNs and Transformer models, such as BERT, ViT, ResNet, TOLOv5/8, and many more. DeepSpare includes three deployment APIs:\n","\n","\n","## Engine \n","\n","It is the lowest-level API. With Engine, you compile an ONNX model, pass tensors as input, and receive the raw outputs.\n","\n","\n","## Pipeline\n","\n","It wraps the Engine with pre- and post-processing. With Pipeline, you pass raw data and receive the prediction.\n","\n","\n","## Server\n","\n","It wraps Pipelines with a REST API using FastAPI. With Server, you send raw data over HTTP and receive the prediction."]},{"cell_type":"markdown","id":"8fdb7667","metadata":{"papermill":{"duration":0.021337,"end_time":"2024-02-27T11:48:44.951695","exception":false,"start_time":"2024-02-27T11:48:44.930358","status":"completed"},"tags":[]},"source":["# Engine\n","\n","This example will downloads a 90% pruned-quantized BERT model for sentiment analysis in ONNX format from SparseZoo, complies the model, and runs inference on randomsly generated input. Users can provide their own ONNX models, whether dense or sparse"]},{"cell_type":"code","execution_count":5,"id":"30bc1913","metadata":{"execution":{"iopub.execute_input":"2024-02-27T11:48:45.120575Z","iopub.status.busy":"2024-02-27T11:48:45.117314Z","iopub.status.idle":"2024-02-27T11:48:59.628083Z","shell.execute_reply":"2024-02-27T11:48:59.626389Z"},"papermill":{"duration":14.657417,"end_time":"2024-02-27T11:48:59.631445","exception":false,"start_time":"2024-02-27T11:48:44.974028","status":"completed"},"tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0bcf130ea78c46ffae5e0b2566bd4f86","version_major":2,"version_minor":0},"text/plain":["Downloading (…)ed/deployment.tar.gz:   0%|          | 0.00/29.8M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from deepsparse import Engine\n","\n","model_address =\"zoo:nlp/sentiment_analysis/obert-base/pytorch/huggingface/sst2/pruned90_quant-none\"\n","compiled_model=Engine(model=model_address, batch_size=1)"]},{"cell_type":"code","execution_count":6,"id":"628ff375","metadata":{"execution":{"iopub.execute_input":"2024-02-27T11:48:59.678817Z","iopub.status.busy":"2024-02-27T11:48:59.678324Z","iopub.status.idle":"2024-02-27T11:48:59.887004Z","shell.execute_reply":"2024-02-27T11:48:59.885524Z"},"papermill":{"duration":0.236418,"end_time":"2024-02-27T11:48:59.890486","exception":false,"start_time":"2024-02-27T11:48:59.654068","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-02-27 11:48:59 deepsparse.utils.onnx INFO     Generating input 'input_ids', type = int64, shape = [1, 128]\n","2024-02-27 11:48:59 deepsparse.utils.onnx INFO     Generating input 'attention_mask', type = int64, shape = [1, 128]\n","2024-02-27 11:48:59 deepsparse.utils.onnx INFO     Generating input 'token_type_ids', type = int64, shape = [1, 128]\n"]},{"name":"stdout","output_type":"stream","text":["[array([[-0.34614536,  0.09025408]], dtype=float32)]\n"]}],"source":["inputs=compiled_model.generate_random_inputs()\n","output=compiled_model(inputs)\n","print(output)"]},{"cell_type":"markdown","id":"ab159294","metadata":{"papermill":{"duration":0.024314,"end_time":"2024-02-27T11:48:59.938681","exception":false,"start_time":"2024-02-27T11:48:59.914367","status":"completed"},"tags":[]},"source":["# Pipeline\n","\n","It wrap Engine with pre- and post-processing, enabling you to pass raw data and receive the post-processed prediction."]},{"cell_type":"code","execution_count":7,"id":"068beeeb","metadata":{"execution":{"iopub.execute_input":"2024-02-27T11:48:59.989677Z","iopub.status.busy":"2024-02-27T11:48:59.989201Z","iopub.status.idle":"2024-02-27T11:49:10.333Z","shell.execute_reply":"2024-02-27T11:49:10.330605Z"},"papermill":{"duration":10.374434,"end_time":"2024-02-27T11:49:10.336524","exception":false,"start_time":"2024-02-27T11:48:59.96209","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-02-27 11:48:59 deepsparse.pipeline WARNING  Could not create v2 'sentiment-analysis' pipeline, trying legacy\n"]}],"source":["from deepsparse import Pipeline\n","\n","# download onnx, set up pipeline\n","zoo_stub = \"zoo:nlp/sentiment_analysis/obert-base/pytorch/huggingface/sst2/pruned90_quant-none\"\n","\n","sentiment_analysis_pipeline = Pipeline.create(\n","  task=\"sentiment-analysis\",    # name of the task\n","  model_path=zoo_stub,          # zoo stub or path to local onnx file\n",")"]},{"cell_type":"code","execution_count":8,"id":"92e7ef1d","metadata":{"execution":{"iopub.execute_input":"2024-02-27T11:49:10.390123Z","iopub.status.busy":"2024-02-27T11:49:10.389628Z","iopub.status.idle":"2024-02-27T11:49:10.46752Z","shell.execute_reply":"2024-02-27T11:49:10.464724Z"},"papermill":{"duration":0.107792,"end_time":"2024-02-27T11:49:10.470973","exception":false,"start_time":"2024-02-27T11:49:10.363181","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["labels=['positive'] scores=[0.9995297193527222]\n"]}],"source":["prediction = sentiment_analysis_pipeline(\"Cool\")\n","print(prediction)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30579,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":807.369497,"end_time":"2024-02-27T11:49:14.120637","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-27T11:35:46.75114","version":"2.4.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"0bcf130ea78c46ffae5e0b2566bd4f86":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2a26454421624e8c97f41e9cb2ab5a8a","IPY_MODEL_a5b0de1e1af64e1699c44a6d214e2440","IPY_MODEL_295088e29ecb4a15987a12a136ab6f07"],"layout":"IPY_MODEL_2d7e4ff8030c4384acfbb9d0675c2319"}},"16b5267e9cb34344ad2ef7ab9dde24d1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"295088e29ecb4a15987a12a136ab6f07":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65c5f2763a4d4e898417d584b976a1b2","placeholder":"​","style":"IPY_MODEL_6f8c6eb5302c4e439c94f38f1c4f1710","value":" 29.8M/29.8M [00:01&lt;00:00, 37.0MB/s]"}},"2a26454421624e8c97f41e9cb2ab5a8a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb69d2035b484c68a762d15d8cf9d5f4","placeholder":"​","style":"IPY_MODEL_ac6c292bbcf54c6b816552d93101b06d","value":"Downloading (…)ed/deployment.tar.gz: 100%"}},"2d1fa3dfa7834b10b4ffd5a38356f5c1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d7e4ff8030c4384acfbb9d0675c2319":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fb28b7221ac4522afc460e8350059bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32019b16e0dc4d1cb48f321c3260dce3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3eb767a5d09a45e7ab522aa1784199f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ad3fef8917994adfbcaa8c64baf192d8","IPY_MODEL_cf5b7124dc96448ab71a4bdd918a4bb6","IPY_MODEL_533d65dae2224372adb4ce51b6cebbe2"],"layout":"IPY_MODEL_2d1fa3dfa7834b10b4ffd5a38356f5c1"}},"533d65dae2224372adb4ce51b6cebbe2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8789c48ca474f409936b86b2be40c3d","placeholder":"​","style":"IPY_MODEL_2fb28b7221ac4522afc460e8350059bc","value":" 3.04G/3.04G [02:16&lt;00:00, 11.9MB/s]"}},"65c5f2763a4d4e898417d584b976a1b2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67840caebbb0470f9fb88705cd939a5c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f8c6eb5302c4e439c94f38f1c4f1710":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5b0de1e1af64e1699c44a6d214e2440":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_32019b16e0dc4d1cb48f321c3260dce3","max":31205128.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_db1d447cc4ab42ee98fd191f96a0406a","value":31205128.0}},"ac6c292bbcf54c6b816552d93101b06d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad3fef8917994adfbcaa8c64baf192d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16b5267e9cb34344ad2ef7ab9dde24d1","placeholder":"​","style":"IPY_MODEL_eff3ebe647804843b110724fc035fde4","value":"Downloading (…)ed/deployment.tar.gz: 100%"}},"cf5b7124dc96448ab71a4bdd918a4bb6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_67840caebbb0470f9fb88705cd939a5c","max":3266787178.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_d4636ebbde7f454aa283c1e4616748d9","value":3266787178.0}},"d4636ebbde7f454aa283c1e4616748d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d8789c48ca474f409936b86b2be40c3d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db1d447cc4ab42ee98fd191f96a0406a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eb69d2035b484c68a762d15d8cf9d5f4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eff3ebe647804843b110724fc035fde4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":5}