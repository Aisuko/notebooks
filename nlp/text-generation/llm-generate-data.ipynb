{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview\n\nLet's instruct a dataset from various documents. Here we will use Bonito.The workflow see below:\n\n![](https://cdn.masto.host/sigmoidsocial/media_attachments/files/112/171/384/916/341/941/original/0518bdfdaf362c60.webp)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"%%capture\n!pip install -e git+https://github.com/BatsResearch/bonito#egg=bonito\n\n# https://github.com/huggingface/datasets/issues/6753\n!pip install datasets==2.17.0\n!pip install PyMuPDF==1.24.0\n!pip install spacy==3.7.4\n!pip install huggingface-hub==0.22.1","metadata":{"execution":{"iopub.status.busy":"2024-03-28T04:56:50.321509Z","iopub.execute_input":"2024-03-28T04:56:50.322083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nlogin(token=user_secrets.get_secret(\"HUGGINGFACE_TOKEN\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading data","metadata":{}},{"cell_type":"code","source":"import fitz\n\npdf_path='/kaggle/input/pdf-for-data-generation/cssf12_552eng.pdf'\n\ndef extract_text_from_pdf(pdf_path):\n    doc = fitz.open(pdf_path)\n    text = \"\"\n    for page in doc:  # Iterate through each page\n        text += page.get_text()  # Extract text and append it to the text variable\n    return text\n\ntext = extract_text_from_pdf(pdf_path)  # Call the function with the path to your PDF","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Text to sentences","metadata":{}},{"cell_type":"code","source":"import spacy\n\nnlp = spacy.load(\"en_core_web_sm\")  # Load the English language model\n\ndef split_into_sentences(text):\n    doc = nlp(text)  # Process the text with SpaCy\n    sentences = [sent.text.strip() for sent in doc.sents]  # Extract sentences and strip whitespace\n    return sentences\n\nsentences = split_into_sentences(text)  # Split the extracted text into sentences\nprint(len(sentences))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sentences[500])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading to Huggingface Dataset Format","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset\n\n# Assuming sentences is a list of strings, where each string is a sentence\ndata = {\"sentence\": sentences}\ndataset = Dataset.from_dict(data)\ndataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generating the Synthetic Dataset\n\nWe are using Bonito library to generate a synthetic dataset for \"question generation\". However, it also supports a wide array of tasks, see the link in \"Acknowledge\" section.","metadata":{}},{"cell_type":"code","source":"from bonito import Bonito, SamplingParams\nfrom datasets import load_dataset\n\n# Initialize the Bonito model\nbonito = Bonito(\"BatsResearch/bonito-v1\")\n\nsampling_params = SamplingParams(max_tokens=256, top_p=0.95, temperature=0.5, n=1)\nsynthetic_dataset = bonito.generate_tasks(\n    dataset,\n    context_col=\"sentence\",\n    task_type=\"qg\",\n    sampling_params=sampling_params\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndf=pd.DataFrame(synthetic_dataset)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pushing to Hub","metadata":{}},{"cell_type":"code","source":"synthetic_dataset.push_to_hub('aisuko/generate_dataset12_552')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Acknowledge\n\n* https://arxiv.org/pdf/2402.18334.pdf\n* https://medium.com/towards-data-science/how-to-generate-instruction-datasets-from-any-documents-for-llm-fine-tuning-abb319a05d91\n* https://huggingface.co/BatsResearch/bonito-v1","metadata":{}}]}