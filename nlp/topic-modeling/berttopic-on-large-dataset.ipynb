{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview\n\nDue to the modularity of BERTopic, it can also be used on large datasets `Cohere/wikipedia-22-12` (>1_000_000) if we change some of the internal algorithms such that they can scale a bit better. And we can also enable GPU-accelrated machine learning.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"%%capture\n!pip install bertopic==0.16.0\n!pip install datasets==2.17.0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sometimes, it might happen that you get the `NotImplementedError: A UTF-8 locale is required. Got ANSI_X3.4-1968` error, if so make sure to run the following code","metadata":{}},{"cell_type":"code","source":"import locale\n\nlocale.getpreferredencoding=lambda: \"UTF-8\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the dataset\n\nWe are going to load in Wikipedia texts. Cohere has fortunately created a dataset split by paragraphs, which allows us to stay within token limit sizes. Let's load in 1 million texts from Wikipedia and see if we can extract topics from them.","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\n# extract 1 millions records\nlang='en'\ndata=load_dataset(f'Cohere/wikipedia-22-12', lang, split='train', streaming=True)\ndocs=[doc['text'] for doc in data if doc['id']!='1_000_000']\nlen(docs)","metadata":{},"execution_count":null,"outputs":[]}]}