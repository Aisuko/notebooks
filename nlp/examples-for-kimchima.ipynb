{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview\n\nWe invoke Huggingface ML ecosystem libs in kimchima. We want to make sure that the kimchima can be a buffer zone for ML dependencies. So, we use poetry to manage all the ML libs in kimchima.\n\n## Note\n\nFirst, we upgrade to Python 3.11. After the installing process was finished. We restart the notebook.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"%%capture\n!mamba create -n py311 -y\n!source /opt/conda/bin/activate py311 && mamba install python=3.11 jupyter mamba -y\n\n!sudo rm /opt/conda/bin/python3\n!sudo ln -sf /opt/conda/envs/py311/bin/python3 /opt/conda/bin/python3\n!sudo rm /opt/conda/bin/python3.10\n!sudo ln -sf /opt/conda/envs/py311/bin/python3 /opt/conda/bin/python3.10\n!sudo rm /opt/conda/bin/python\n!sudo ln -sf /opt/conda/envs/py311/bin/python3 /opt/conda/bin/python","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python --version","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.version","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U -q kimchima==0.4.1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Computing Embeddings","metadata":{}},{"cell_type":"code","source":"from kimchima import (\n    ModelFactory, \n    TokenizerFactory,\n    StreamerFactory,\n    EmbeddingsFactory,\n    PipelinesFactory,\n    Devices\n)\n\n\npretrained_model_name_or_path = \"sentence-transformers/all-MiniLM-L6-v2\"\n\nmodel = ModelFactory.auto_model(pretrained_model_name_or_path=pretrained_model_name_or_path)\ntokenizer= TokenizerFactory.auto_tokenizer(pretrained_model_name_or_path=pretrained_model_name_or_path)\n\n# computing embeddings for single text\nembeddings = EmbeddingsFactory.get_text_embeddings(\n    model=model,\n    tokenizer=tokenizer,\n    prompt='Melbourne',\n    device='cuda'\n)\nprint(embeddings.shape)\n\n# computing embeddings for multiple texts\nembeddings = EmbeddingsFactory.get_text_embeddings(\n    model=model,\n    tokenizer=tokenizer,\n    prompt=['Melbourne', 'Sydney'],\n    device='cuda'\n)\nprint(embeddings.shape)\n\n# Checking the device: GPU, mps and CPU\ndevice = Devices.get_device()\nprint(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:15:21.064107Z","iopub.execute_input":"2024-04-13T06:15:21.064494Z","iopub.status.idle":"2024-04-13T06:15:27.739883Z","shell.execute_reply.started":"2024-04-13T06:15:21.064458Z","shell.execute_reply":"2024-04-13T06:15:27.738852Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d1c1d6ad8174bbf8b5e7e730b47a517"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f0808468e0846fa907afbd7a6b2023a"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 were not used when initializing BertModel: ['pooler.dense.bias', 'pooler.dense.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b92353209bdf46fbb461576a073b9183"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9689f708c09489ba600694068df363c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d097755cd1047f5aa9b584eba857f33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dbb874e0a7f492cbcafe43f73c4e0be"}},"metadata":{}},{"name":"stdout","text":"torch.Size([1, 384])\ntorch.Size([2, 384])\nDevices.GPU\n","output_type":"stream"}]},{"cell_type":"code","source":"# get capability of GPU(Nvidia)\ncapability = Devices.get_capability()\nprint(capability)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:15:32.366306Z","iopub.execute_input":"2024-04-13T06:15:32.366645Z","iopub.status.idle":"2024-04-13T06:15:32.371535Z","shell.execute_reply.started":"2024-04-13T06:15:32.366611Z","shell.execute_reply":"2024-04-13T06:15:32.370660Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"(6, 0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Inference by using Streaming","metadata":{}},{"cell_type":"code","source":"# streamer\nmodel= ModelFactory.auto_model_for_causal_lm(pretrained_model_name_or_path=\"gpt2\")\ntokenizer= TokenizerFactory.auto_tokenizer(pretrained_model_name_or_path=\"gpt2\")\nstreamer= StreamerFactory.text_streamer(tokenizer=tokenizer, skip_prompt=False, skip_prompt_tokens=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:15:35.019812Z","iopub.execute_input":"2024-04-13T06:15:35.020189Z","iopub.status.idle":"2024-04-13T06:15:39.596913Z","shell.execute_reply.started":"2024-04-13T06:15:35.020156Z","shell.execute_reply":"2024-04-13T06:15:39.596065Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02dec2fcb3c74720a52ac1fde4b85790"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"254b8c6231854deab286119366639f2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5744da0832494531a3672d49f769c032"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a671b13d89e4b63b80598e75fb09294"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94f70d6dfd394218a3b5b6761a2eb601"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33c8372f482d41eabedee283b5f7ffc2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"064e4edfba2c416a8874dcd8feeecbc2"}},"metadata":{}}]},{"cell_type":"code","source":"pipe=PipelinesFactory.text_generation(\n    model=model, \n    tokenizer=tokenizer, \n    text_streamer=streamer\n    )\n\npip.device","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe(\"Melbourne is the capital of Victoria\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conversation_model=\"facebook/blenderbot-400M-distill\"\nmsg = \"why Melbourne is a good place to travel?\"\nprompt = \"Melbourne is often considered one of the most livable cities globally, offering a high quality of life.\"\nres = PipelinesFactory.chat_response(\n    conversation_model=conversation_model,\n    messages=msg,\n    prompt=prompt\n    )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Acknowledge\n* https://www.kaggle.com/discussions/general/402718","metadata":{}}]}