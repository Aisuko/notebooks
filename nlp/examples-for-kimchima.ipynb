{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview\n\nWe invoke Huggingface ML ecosystem libs in kimchima. We want to make sure that the kimchima can be a buffer zone for ML dependencies. So, we use poetry to manage all the ML libs in kimchima.\n\n## Note\n\nFirst, we upgrade to Python 3.11. After the installing process was finished. We restart the notebook.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"%%capture\n!mamba create -n py311 -y\n!source /opt/conda/bin/activate py311 && mamba install python=3.11 jupyter mamba -y\n\n!sudo rm /opt/conda/bin/python3\n!sudo ln -sf /opt/conda/envs/py311/bin/python3 /opt/conda/bin/python3\n!sudo rm /opt/conda/bin/python3.10\n!sudo ln -sf /opt/conda/envs/py311/bin/python3 /opt/conda/bin/python3.10\n!sudo rm /opt/conda/bin/python\n!sudo ln -sf /opt/conda/envs/py311/bin/python3 /opt/conda/bin/python","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python --version","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.version","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U -q kimchima==0.4.1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import kimchima","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:03:51.933203Z","iopub.execute_input":"2024-04-13T06:03:51.934023Z","iopub.status.idle":"2024-04-13T06:03:55.672135Z","shell.execute_reply.started":"2024-04-13T06:03:51.933976Z","shell.execute_reply":"2024-04-13T06:03:55.671370Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Downloading Model Manually","metadata":{}},{"cell_type":"code","source":"from kimchima.pkg import DownloadHub\n\n\nfile_path=DownloadHub.download_specific_file(\n    repo_id=\"microsoft/Mistral-7B-v0.1-onnx\",\n    filename=\"README.md\",\n    folder_name=\".\",\n    revision=\"main\"\n)\n\nprint(file_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# repo_path=DownloadHub.download_repo(\n#     repo_id=\"openai-community/gpt2\",\n#     folder_name=\".\",\n#     revision=\"main\"\n# )\n\n# print(repo_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Computing Embeddings","metadata":{}},{"cell_type":"code","source":"from kimchima import (\n    ModelFactory, \n    TokenizerFactory,\n    StreamerFactory,\n    EmbeddingsFactory,\n    PipelinesFactory,\n    Devices\n)\n\n\npretrained_model_name_or_path = \"sentence-transformers/all-MiniLM-L6-v2\"\n\nmodel = ModelFactory.auto_model(pretrained_model_name_or_path=pretrained_model_name_or_path)\ntokenizer= TokenizerFactory.auto_tokenizer(pretrained_model_name_or_path=pretrained_model_name_or_path)\n\n# computing embeddings for single text\nembeddings = EmbeddingsFactory.get_text_embeddings(\n    model=model,\n    tokenizer=tokenizer,\n    prompt='Melbourne',\n    device='cuda'\n)\nprint(embeddings.shape)\n\n# computing embeddings for multiple texts\nembeddings = EmbeddingsFactory.get_text_embeddings(\n    model=model,\n    tokenizer=tokenizer,\n    prompt=['Melbourne', 'Sydney'],\n    device='cuda'\n)\nprint(embeddings.shape)\n\n# Checking the device: GPU, mps and CPU\ndevice = Devices.get_device()\nprint(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:04:36.904903Z","iopub.execute_input":"2024-04-13T06:04:36.905288Z","iopub.status.idle":"2024-04-13T06:04:37.821494Z","shell.execute_reply.started":"2024-04-13T06:04:36.905252Z","shell.execute_reply":"2024-04-13T06:04:37.820557Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 were not used when initializing BertModel: ['pooler.dense.bias', 'pooler.dense.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([1, 384])\ntorch.Size([2, 384])\nDevices.GPU\n","output_type":"stream"}]},{"cell_type":"code","source":"# get capability of GPU(Nvidia)\ncapability = Devices.get_capability()\nprint(capability)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:04:44.403137Z","iopub.execute_input":"2024-04-13T06:04:44.403529Z","iopub.status.idle":"2024-04-13T06:04:44.409297Z","shell.execute_reply.started":"2024-04-13T06:04:44.403494Z","shell.execute_reply":"2024-04-13T06:04:44.408236Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(6, 0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Inference by using Streaming","metadata":{}},{"cell_type":"code","source":"# streamer\nmodel= ModelFactory.auto_model_for_causal_lm(pretrained_model_name_or_path=\"gpt2\")\ntokenizer= TokenizerFactory.auto_tokenizer(pretrained_model_name_or_path=\"gpt2\")\nstreamer= StreamerFactory.text_streamer(tokenizer=tokenizer, skip_prompt=False, skip_prompt_tokens=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:05:19.315130Z","iopub.execute_input":"2024-04-13T06:05:19.315541Z","iopub.status.idle":"2024-04-13T06:05:23.938280Z","shell.execute_reply.started":"2024-04-13T06:05:19.315511Z","shell.execute_reply":"2024-04-13T06:05:23.937193Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e842b68edd046289fe5a3477a47db58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc48efd7a0f544feb16f098e81658106"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09775fc5d50940fba0e7c6bd16aeb831"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f806d42457145ada9b7e855bcd7c75d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c0621a66dcf40b0b82db8882947d303"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be484fdf44f943dd8d192411a1ca8e01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43155bc9686c43588a6155c7c1b775f4"}},"metadata":{}}]},{"cell_type":"code","source":"pipe=PipelinesFactory.text_generation(\n    model=model, \n    tokenizer=tokenizer, \n    text_streamer=streamer\n    )","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:05:37.262015Z","iopub.execute_input":"2024-04-13T06:05:37.262432Z","iopub.status.idle":"2024-04-13T06:05:37.267941Z","shell.execute_reply.started":"2024-04-13T06:05:37.262397Z","shell.execute_reply":"2024-04-13T06:05:37.266905Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"pipe(\"Melbourne is the capital of Victoria\")","metadata":{"execution":{"iopub.status.busy":"2024-04-13T06:05:40.467910Z","iopub.execute_input":"2024-04-13T06:05:40.468274Z","iopub.status.idle":"2024-04-13T06:05:42.181618Z","shell.execute_reply.started":"2024-04-13T06:05:40.468241Z","shell.execute_reply":"2024-04-13T06:05:42.180671Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Melbourne is the capital of Victoria's Western Sydney CBD and also home to many restaurants and restaurants.\n\nOne of the highlights of\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': \"Melbourne is the capital of Victoria's Western Sydney CBD and also home to many restaurants and restaurants.\\n\\nOne of the highlights of\"}]"},"metadata":{}}]},{"cell_type":"markdown","source":"# Acknowledge\n* https://www.kaggle.com/discussions/general/402718","metadata":{}}]}