{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aisuko/using-civitai-checkpoints-lora-with-diffusers?scriptVersionId=161773820\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Overview\n\nLet's see how to use custom models on CivitAI with diffusers.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install diffusers==0.23.1\n!pip install omegaconf==2.3.0\n!pip install compel==2.0.2","metadata":{"execution":{"iopub.status.busy":"2024-02-05T10:20:07.076304Z","iopub.execute_input":"2024-02-05T10:20:07.077248Z","iopub.status.idle":"2024-02-05T10:20:43.981405Z","shell.execute_reply.started":"2024-02-05T10:20:07.077195Z","shell.execute_reply":"2024-02-05T10:20:43.980184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we will download the custom model is based on `StableDiffusion V1.5`.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\ncivitai_key = user_secrets.get_secret(\"CIVITAI\")\n\n# https://education.civitai.com/civitais-guide-to-downloading-via-api/\nos.environ[\"CHECKPOINT_MERGED\"] = \"meichidark_mix_v3.5.safetensors\"\nos.environ['CHECKPOINT_URL'] = \"https://civitai.com/api/download/models/90778?&token=\"+civitai_key\nos.environ[\"LORA_ADAPTER\"] = \"armor.safetensors\"\nos.environ[\"LORA_URL\"]=\"https://civitai.com/api/download/models/224823?&token=\"+civitai_key","metadata":{"execution":{"iopub.status.busy":"2024-02-05T10:20:43.983468Z","iopub.execute_input":"2024-02-05T10:20:43.983913Z","iopub.status.idle":"2024-02-05T10:20:44.196273Z","shell.execute_reply.started":"2024-02-05T10:20:43.983881Z","shell.execute_reply":"2024-02-05T10:20:44.195229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Downloading the custom checkpoint(merged)\n\nWe download the merged checkpoint first.","metadata":{}},{"cell_type":"code","source":"!wget -q -O  ${CHECKPOINT_MERGED} ${CHECKPOINT_URL} --content-disposition ","metadata":{"execution":{"iopub.status.busy":"2024-02-05T10:20:44.197612Z","iopub.execute_input":"2024-02-05T10:20:44.198279Z","iopub.status.idle":"2024-02-05T10:23:02.121678Z","shell.execute_reply.started":"2024-02-05T10:20:44.198243Z","shell.execute_reply":"2024-02-05T10:23:02.1203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget -q -O ${LORA_ADAPTER} ${LORA_URL} --content-disposition","metadata":{"execution":{"iopub.status.busy":"2024-02-05T10:23:02.124678Z","iopub.execute_input":"2024-02-05T10:23:02.125092Z","iopub.status.idle":"2024-02-05T10:23:04.257095Z","shell.execute_reply.started":"2024-02-05T10:23:02.125051Z","shell.execute_reply":"2024-02-05T10:23:04.255503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the custom checkpoint(merged)","metadata":{}},{"cell_type":"code","source":"from diffusers import StableDiffusionPipeline\nimport torch\n\n# Loading the pretrained checkpoint(merged) from downloaded safetensors\npipe=StableDiffusionPipeline.from_single_file(\n    os.getenv('CHECKPOINT_MERGED'),\n    use_safetensors=True,\n    torch_dtype=torch.float16 # For CUDA\n)\npipe.enable_model_cpu_offload()\npipe","metadata":{"execution":{"iopub.status.busy":"2024-02-05T10:23:39.44775Z","iopub.execute_input":"2024-02-05T10:23:39.448162Z","iopub.status.idle":"2024-02-05T10:23:49.718214Z","shell.execute_reply.started":"2024-02-05T10:23:39.448119Z","shell.execute_reply":"2024-02-05T10:23:49.717224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the custom LoRA\n\nHere we only use one Lora adapter, it can also support using multiple adapters.\n\n```python\n# Using multiple LoRAs with different scaling factors.\n\nlora_dirs = [\"lora1.safetensors\", \"lora2.safetensors\", ...]\nlora_scales = [0.7, 0.7, ...]\n\nldir, lsc in zip(lora_dirs, lora_scales):\n    # Iteratively add new LoRA.\n    pipe.load_lora_weights(ldir)\n    # And scale them accordingly.\n    pipe.fuse_lora(lora_scale = lsc)\n```","metadata":{}},{"cell_type":"code","source":"pipe.load_lora_weights(os.getenv('LORA_ADAPTER'))\npipe","metadata":{"execution":{"iopub.status.busy":"2024-02-05T10:24:08.52425Z","iopub.execute_input":"2024-02-05T10:24:08.525122Z","iopub.status.idle":"2024-02-05T10:24:08.982296Z","shell.execute_reply.started":"2024-02-05T10:24:08.525084Z","shell.execute_reply":"2024-02-05T10:24:08.981399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setting Clip_skip","metadata":{}},{"cell_type":"code","source":"clip_skip=2\npipe.text_encoder.text_model.encoder.layers=pipe.text_encoder.text_model.encoder.layers[:-clip_skip]\npipe.safety_checker=None","metadata":{"execution":{"iopub.status.busy":"2024-02-05T10:24:12.937729Z","iopub.execute_input":"2024-02-05T10:24:12.938102Z","iopub.status.idle":"2024-02-05T10:24:12.945135Z","shell.execute_reply.started":"2024-02-05T10:24:12.938072Z","shell.execute_reply":"2024-02-05T10:24:12.944226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading scheduler","metadata":{}},{"cell_type":"code","source":"from diffusers import (EulerAncestralDiscreteScheduler,\n                       EulerDiscreteScheduler,\n                       DPMSolverMultistepScheduler)\nscheduler='none'\n\nif scheduler=='EDS':\n    pipe.scheduler= EulerDiscreteScheduler.from_config(pipe.scheduler.config)\nelif scheduler=='EADS':\n    pipe.scheduler=EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\nelse:\n    pipe.scheduler=DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\npipe.enable_model_cpu_offload()\npipe","metadata":{"execution":{"iopub.status.busy":"2024-02-05T10:24:16.24147Z","iopub.execute_input":"2024-02-05T10:24:16.241848Z","iopub.status.idle":"2024-02-05T10:24:17.000625Z","shell.execute_reply.started":"2024-02-05T10:24:16.24182Z","shell.execute_reply":"2024-02-05T10:24:16.99954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess the prompt\n\nWe want to overcome the 77 tokens limit. So, we use [compel](https://github.com/damian0815/compel) to embedding the prompts to a PyTorch tensor.","metadata":{}},{"cell_type":"code","source":"from compel import Compel\n\n\nembeddings=True\n\nprompt='((a female wearing a red hood)), fantasy theme, medieval, fierce look, ((dynamic poses)), tattoo on her arms, white ruffled sleeve shirt, choker,  gloves, corset, leather pants, belt, waist sash, cape,  (((masterpiece))),  ((best quality)), ((intricate detailed)), ((Hyperrealistic)), a woman with perfect body figure wearing cyberpunk cloth, pale skin, ((huge breast)),  highly detailed, illustration, perfect hands, detailed fingers, beautiful detailed eyes, red hair, black hair, multiple color hair, long hair, (fantasy:1.2),  armor, detailed background, tavern , night, light by candle, lens flare, tempting look, looking at the viewer, from above,  <lora:adventurers_v1:1>  <lora:sxz-niji-v2:0.6>'\nnegative_prompt='easynegative, badhandv4, (low quality, worst quality:1.4), poorly drawn hands, bad anatomy, monochrome, { long body }, bad anatomy, liquid body, malformed, mutated, anatomical nonsense, bad proportions, uncoordinated body, unnatural body, disfigured, ugly, gross proportions, mutation, disfigured, deformed, { mutation}, {poorlydrawn}, bad hand, mutated hand, bad fingers, mutated fingers,   badhandv4, liquid tongue, long neck, fused ears, bad ears, poorly drawn ears, extra ears, liquid ears, heavy ears, missing ears, fused animal ears, bad animal ears, poorly drawn animal ears, extra animal ears, liquid animal ears, heavy animal ears, missing animal ears, bad hairs, poorly drawn hairs, fused hairs, bad face, fused face, poorly drawn face, cloned face, big face, long face, bad eyes, fused eyes poorly drawn eyes, extra eyes, bad mouth, fused mouth, poorly drawn mouth, bad tongue, big mouth, bad perspective, bad objects placement, NSFW, bad weapon, fused weapon, extra weapons, poorly weapon, bad sword, poor sword'\n\n\ncompel=Compel(tokenizer=pipe.tokenizer, text_encoder=pipe.text_encoder)\ncon_embeds=compel([prompt])\nneg_embeds=compel([negative_prompt])\n\nprint(con_embeds.size())\nprint(neg_embeds.size())\n\n\n# Warning\n# Below function will cause the different size of two prompts(con, neg_promt)\n\n# max_length=pipe.tokenizer.model_max_length\n# def get_prompt_embeddings(prompt, negative_prompt):\n#     count_prompt=len(prompt.split(' '))\n#     count_negative_prompt=len(prompt.split(' '))\n    \n#     if count_prompt>=count_negative_prompt:\n#         input_ids=pipe.tokenizer(prompt, \n#                                   truncation=False, \n#                                   return_tensors='pt').input_ids.to('cuda')\n#         shape_max_length=input_ids.shape[-1]\n        \n#         negative_ids=pipe.tokenizer(negative_prompt, truncation=False, \n#                                     padding='max_length', \n#                                     max_length=shape_max_length, \n#                                     return_tensors='pt').input_ids.to('cuda')\n#     else:\n#         negative_ids=pipe.tokenizer(negative_prompt, truncation=False,\n#                                    return_tensors='pt').input_ids.to('cuda')\n#         shape_max_length=negative_ids.shape[-1]\n#         input_ids=pipe.tokenizer(prompt, truncation=False,\n#                                 padding='max_length',\n#                                 max_length=shape_max_length,\n#                                 return_tensors='pt').input_ids.to('cuda')\n        \n#     concat_embeds=[]\n#     neg_embeds=[]\n#     for i in range(0,shape_max_length, max_length):\n#         concat_embeds.append(pipe.text_encoder(input_ids[:,i:i+max_length])[0])\n#         neg_embeds.append(pipe.text_encoder(negative_ids[:,i:i+max_length])[0])\n    \n#     prompt_embeddings=torch.cat(concat_embeds, dim=1)\n#     negative_prompt_embeddings=torch.cat(neg_embeds, dim=1)\n    \n#     return prompt_embeddings, negative_prompt_embeddings\n\n# if embeddings:\n#     prompt_embed, negative_embed=get_prompt_embeddings(prompt, negative_prompt)\n# print(prompt_embed.size())\n# print(negative_embed.size())","metadata":{"execution":{"iopub.status.busy":"2024-02-05T10:24:20.860627Z","iopub.execute_input":"2024-02-05T10:24:20.860959Z","iopub.status.idle":"2024-02-05T10:24:22.090451Z","shell.execute_reply.started":"2024-02-05T10:24:20.860933Z","shell.execute_reply":"2024-02-05T10:24:22.089495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if embeddings:\n    imgs=pipe(prompt_embeds=con_embeds,\n             negative_prompt_embeds=neg_embeds,\n             width=512,\n             height=832,\n             guidance_scale=7.0,\n             num_inference_steps=35,\n             num_images_per_prompt=1,\n             generator=torch.manual_seed(93421173)).images\nelse:\n    imgs=pipe(prompt=prompt,\n              negative_prompt=negative_prompt,\n              width=512,height=832,\n              guidance_scale=12.0,num_inference_steps=50,\n              num_images_per_prompt=1,\n              generator=torch.manual_seed(0)).images\nimgs[0]","metadata":{"execution":{"iopub.status.busy":"2024-02-05T10:24:25.693875Z","iopub.execute_input":"2024-02-05T10:24:25.69476Z","iopub.status.idle":"2024-02-05T10:24:45.535631Z","shell.execute_reply.started":"2024-02-05T10:24:25.694715Z","shell.execute_reply":"2024-02-05T10:24:45.534627Z"},"trusted":true},"execution_count":null,"outputs":[]}]}