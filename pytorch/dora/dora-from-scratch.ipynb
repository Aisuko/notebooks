{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "970055c4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.006534,
     "end_time": "2024-02-22T00:45:57.557844",
     "exception": false,
     "start_time": "2024-02-22T00:45:57.551310",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "**Note: All the images are come from the credit setion at the bottom.**\n",
    "\n",
    "Low-rank adaptation(LoRA) is a machine learning technique that modifies a pretrained model(for example, an LLM or vision transformer) to better suit a specific, often smaller, dataset by adjusting only a small, low-rank subset of the model's parameters.\n",
    "\n",
    "This approach is important because it allows for efficient finetuning of large models on task-specific data significantly reducing the computational cost and time required for finetuning.\n",
    "\n",
    "More details see notebook [Lora From Scratch](https://www.kaggle.com/code/aisuko/lora-from-scratch)\n",
    "\n",
    "In this notebook, we are going to talk about [Weight-Decomposed Low-Rank Adaptation](https://arxiv.org/abs/2402.09353), which is a new alterative to LoRA, which may outperform LoRA by a large margin. We are going to implement both LoRA and DoRA in PyTorch from scratch in this notebook. \n",
    "\n",
    "Thanks for [Sebastian Raschka, Phd's greate write-up](https://magazine.sebastianraschka.com/p/lora-and-dora-from-scratch) and I credit it at the bottom.\n",
    "\n",
    "![](https://cdn.masto.host/sigmoidsocial/media_attachments/files/111/966/286/141/991/915/small/82bb43214ea19389.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718c6662",
   "metadata": {
    "papermill": {
     "duration": 0.005651,
     "end_time": "2024-02-22T00:45:57.569698",
     "exception": false,
     "start_time": "2024-02-22T00:45:57.564047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Weight-Decomposed Low-Rank Adaptation(DoRA)\n",
    "\n",
    "DoRA can be seen as an improvement or extension of LoRA that is built on top of it, and we can now easily adapt some of our previous code to implement DoRA. DoRA can be described in two steps, where the first step is to decompose a pretrained weight matrix into a magnitude vector($m$) and a directional matrix($V$). The second step is applyting LoRA to the directional matrix $V$ and training the magnitude vector $m$ separately.\n",
    "\n",
    "The decomposition into magnitude and directional components is inspired by the mathematical principle that **any vector can be represented as the product of its magnitude(a scalar value indicating its length)** and its direction (a unit vector indicating its orientation in space).\n",
    "\n",
    "![](https://cdn.masto.host/sigmoidsocial/media_attachments/files/111/967/578/668/588/233/original/6444016e59fb5aa1.png)\n",
    "\n",
    "Illustration of the direction and magnitude of a single vector. For example, if have a 2D vector [1,2], we can decompose it into a magnitude 2.24 and a directional vector [0.447, 0.894]. Then 2.24 * [0.447, 0.894]=[1,2].\n",
    "\n",
    "In DoRA, we apply the decomposition into magnitude and directinal components to a whole pretrained matrix $W$ instead of a vector, where each column (vector) of the weight matrix corresponds to the weights connecting all inputs to a particular output neuron.\n",
    "\n",
    "So the result of decomposing $W$ is a magnitude vector $m$ that represents the scale or length of each column vector in the weight matrix, as illustrated in the figure below.\n",
    "\n",
    "![](https://cdn.masto.host/sigmoidsocial/media_attachments/files/111/967/632/855/320/899/original/ecf712f2fac89b88.png)\n",
    "\n",
    "Illustration of the weight matrix decomposition in DoRA\n",
    "\n",
    "Then, DoRA takes the directional matrix $V$ and applies standard LoRA, for instance:\n",
    "\n",
    "$$W^{\\prime}=\\frac{m(V+\\Delta V)}{norm}=\\frac{m(W+AB)}{norm}$$\n",
    "\n",
    "The normalization, which I abbreviated as `norm` to not further complicate things in this overview, is based on the weight normalization method proposed in Saliman's and Kingma's [Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks paper](https://arxiv.org/abs/1602.07868).\n",
    "\n",
    "The DoRA two-step process(decomposing a pretrained weight matrix and applying LoRA to the directional matrix) is further illustrated in the figure from the DoRA paper below.\n",
    "\n",
    "![](https://cdn.masto.host/sigmoidsocial/media_attachments/files/111/967/675/274/524/590/original/52ec39d84afdc908.webp)\n",
    "\n",
    "\n",
    "The motivation for developing DoRA is based on analyzing and comparing the LoRA and full finetuning learning patterns. The DoRA authors found that LoRA either increases or decreases magnitude and direction updates proportionally but seems to lack the capability to make only subtle directional changes as found in full finetuning. Hence, the researchers propose the decoupling of magnitude and directional components.\n",
    "\n",
    "In other words, their DoRA method aims to apply LoRA only to the directional component, $V$, while also allowing the magnitude component, $m$, to be trained separately.\n",
    "\n",
    "Introducing the magnitude vector m adds $0.01%$ more parameters if DoRA is compared to LoRA. However, across both LLM and vision transformer benchmarks, they found the DoRA even outperforms LoRA if the DoRA rank is halved, for instance, when DoRA only uses half the parameters of regular LoRA, as shown in the performance comparison below.\n",
    "\n",
    "![](https://cdn.masto.host/sigmoidsocial/media_attachments/files/111/967/733/748/743/976/original/cf8372d4af905b1b.webp)\n",
    "\n",
    "So, it seems that DoRA is much more robust to changes in rank. The possibility to successfully use DoRA with relatively small ranks makes this method even more parameter-efficient than LoRA.\n",
    "\n",
    "\n",
    "## Implementing DoRA Layers in PyTorch\n",
    "\n",
    "Previously, we said that we can initialize a pretrained weight $W_{0}$ with magnitude $m$ and directional component $V$. For instance, we have the following equation:\n",
    "\n",
    "$$W_{0}=m \\frac{V}{||V||_{c}}=||W||_{c} \\frac{W}{||W||_{c}}$$\n",
    "\n",
    "Where $||V||_{c}$ is the vector-wide norm of $V$. Then we can write DoRA including the LoRA weight update $BA$ as shown below:\n",
    "\n",
    "$$W^{\\prime}=\\underline{m} \\frac{V+\\Delta V}{||V+\\Delta V||_{c}}=\\underline{m} \\frac{W_{0}+\\underline{BA}}{||W_{0}+\\underline{BA}||_{c}}$$\n",
    "\n",
    "Here, $\\Delta V$ is the update to the directional component, matrix $V$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f7e925e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T00:45:57.583239Z",
     "iopub.status.busy": "2024-02-22T00:45:57.582873Z",
     "iopub.status.idle": "2024-02-22T00:46:01.269770Z",
     "shell.execute_reply": "2024-02-22T00:46:01.268864Z"
    },
    "papermill": {
     "duration": 3.695945,
     "end_time": "2024-02-22T00:46:01.271827",
     "exception": false,
     "start_time": "2024-02-22T00:45:57.575882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    DEVICE=torch.device('cuda')\n",
    "else:\n",
    "    DEVICE=torch.device('cpu')\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1acc58",
   "metadata": {
    "papermill": {
     "duration": 0.006011,
     "end_time": "2024-02-22T00:46:01.284040",
     "exception": false,
     "start_time": "2024-02-22T00:46:01.278029",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Compare to $LinearWithLoRAMerged$ class in [LoRA From Scratch](https://www.kaggle.com/code/aisuko/lora-from-scratch). Both classes integrate a $LoRALayer$ to augment the original linear layer's weights, but DoRA adds **weight normalization** and **adjustment**. \n",
    "\n",
    "And we can see in the code below, $LinearWithDoRAMerged$ introduces an additional step involving dynamic normalization of the augmented weights. After combining the original weights with the LoRA-adjusted weights $self.linear.weight+self.lora.alpha*lora.T$, it calculates the **norm of these combined weights across columns(column_norm)**. Then, it **normalizes the combined weights** by dividing them by their norms $V=combined_weight/column_norm$. This step ensures taht each column of the combined weight matrix has a unit norm, which can help stabilize the learning process by maintaining the scale of weight updates.\n",
    "\n",
    "DoRA also introduces a learnable vector $self.m$, **which represents the magnitude of each column of the normalized weight matrix**. This parameter allows the model to dynamically adjust the scale of each weight vector in the combined weight matrix during training. This additional flexibility can help the model better capture the importance of different features.\n",
    "\n",
    "In summary, $LinearWithDoRAMerged$ extends the concept of $LinearWithLoRAMerged$ by incorporating dynamic weight normalization and scaling to improve the training performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2b2f648",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T00:46:01.297620Z",
     "iopub.status.busy": "2024-02-22T00:46:01.297022Z",
     "iopub.status.idle": "2024-02-22T00:46:01.310186Z",
     "shell.execute_reply": "2024-02-22T00:46:01.309378Z"
    },
    "papermill": {
     "duration": 0.022081,
     "end_time": "2024-02-22T00:46:01.312063",
     "exception": false,
     "start_time": "2024-02-22T00:46:01.289982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LoRALayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        std_dev=1/torch.sqrt(torch.tensor(rank).float())\n",
    "        self.A=nn.Parameter(torch.randn(in_dim, rank)*std_dev)\n",
    "        self.B=nn.Parameter(torch.zeros(rank, out_dim))\n",
    "        self.alpha=alpha\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # @ means matrix \n",
    "        x=self.alpha*(x @ self.A @ self.B)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LinearWithDoRA(nn.Module):\n",
    "    def __init__(self, linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.linear=linear\n",
    "        self.lora=LoRALayer(\n",
    "            linear.in_features, linear.out_features, rank, alpha\n",
    "        )\n",
    "        self.m=nn.Parameter(torch.ones(1, linear.out_features))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        linear_output=self.linear(x)\n",
    "        lora_output=self.lora(x)\n",
    "        lora_output_norm=lora_output/lora_output.norm(p=2, dim=1, keepdim=True)\n",
    "        dora_modification=self.m * lora_output_norm\n",
    "        dora_output=self.lora(x)\n",
    "        return linear_output+dora_output\n",
    "\n",
    "\n",
    "# this code is equivalent to LinearWithDoRA\n",
    "class LinearWithDoRAMerged(nn.Module):\n",
    "    def __init__(self, linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.linear=linear\n",
    "        self.lora=LoRALayer(\n",
    "            linear.in_features, linear.out_features, rank, alpha\n",
    "        )\n",
    "        self.m=nn.Parameter(self.linear.weight.norm(p=2, dim=0, keepdim=True))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lora=self.lora.A @self.lora.B\n",
    "        numerator=self.linear.weight+self.lora.alpha*lora.T\n",
    "        denominator=numerator.norm(p=2, dim=0, keepdim=True)\n",
    "        directional_component=numerator/denominator\n",
    "        new_weight=self.m*directional_component\n",
    "        return F.linear(x, new_weight, self.linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdeeb847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T00:46:01.325293Z",
     "iopub.status.busy": "2024-02-22T00:46:01.325028Z",
     "iopub.status.idle": "2024-02-22T00:46:01.354015Z",
     "shell.execute_reply": "2024-02-22T00:46:01.353275Z"
    },
    "papermill": {
     "duration": 0.037831,
     "end_time": "2024-02-22T00:46:01.355941",
     "exception": false,
     "start_time": "2024-02-22T00:46:01.318110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "random_seed=123\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "layer=nn.Linear(10,2)\n",
    "x=torch.randn(1,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c22732",
   "metadata": {
    "papermill": {
     "duration": 0.0059,
     "end_time": "2024-02-22T00:46:01.367960",
     "exception": false,
     "start_time": "2024-02-22T00:46:01.362060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Swaping existing Linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47d608df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T00:46:01.381145Z",
     "iopub.status.busy": "2024-02-22T00:46:01.380821Z",
     "iopub.status.idle": "2024-02-22T00:46:01.482069Z",
     "shell.execute_reply": "2024-02-22T00:46:01.481193Z"
    },
    "papermill": {
     "duration": 0.110066,
     "end_time": "2024-02-22T00:46:01.484058",
     "exception": false,
     "start_time": "2024-02-22T00:46:01.373992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6639, 0.4487]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer_dora_1=LinearWithDoRA(layer, rank=2, alpha=4)\n",
    "print(layer_dora_1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ea22a36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T00:46:01.497472Z",
     "iopub.status.busy": "2024-02-22T00:46:01.497205Z",
     "iopub.status.idle": "2024-02-22T00:46:01.510273Z",
     "shell.execute_reply": "2024-02-22T00:46:01.509343Z"
    },
    "papermill": {
     "duration": 0.021975,
     "end_time": "2024-02-22T00:46:01.512236",
     "exception": false,
     "start_time": "2024-02-22T00:46:01.490261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6639, 0.4487]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer_dora_2=LinearWithDoRAMerged(layer, rank=2, alpha=4)\n",
    "print(layer_dora_2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c39155d",
   "metadata": {
    "papermill": {
     "duration": 0.006911,
     "end_time": "2024-02-22T00:46:01.525206",
     "exception": false,
     "start_time": "2024-02-22T00:46:01.518295",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Multilayer Perceptron Model(Without DoRA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f333edd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T00:46:01.538558Z",
     "iopub.status.busy": "2024-02-22T00:46:01.538285Z",
     "iopub.status.idle": "2024-02-22T00:46:04.311976Z",
     "shell.execute_reply": "2024-02-22T00:46:04.311130Z"
    },
    "papermill": {
     "duration": 2.782967,
     "end_time": "2024-02-22T00:46:04.314269",
     "exception": false,
     "start_time": "2024-02-22T00:46:01.531302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "learning_rate=0.005\n",
    "num_epochs=10\n",
    "\n",
    "# architecture\n",
    "num_features=784\n",
    "num_hidden_1=128\n",
    "num_hidden_2=256\n",
    "num_classes=10\n",
    "\n",
    "class MultilayerPerceptron(nn.Module):\n",
    "    def __init__(self, num_features, num_hidden_1, num_hidden_2, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers=nn.Sequential(\n",
    "            nn.Linear(num_features, num_hidden_1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden_1, num_hidden_2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden_2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.layers(x)\n",
    "        return x\n",
    "\n",
    "model=MultilayerPerceptron(\n",
    "    num_features=num_features,\n",
    "    num_hidden_1=num_hidden_1,\n",
    "    num_hidden_2=num_hidden_2,\n",
    "    num_classes=num_classes\n",
    ")\n",
    "\n",
    "model.to(DEVICE)\n",
    "optimizer_pretrained=torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a9aa07",
   "metadata": {
    "papermill": {
     "duration": 0.00621,
     "end_time": "2024-02-22T00:46:04.327053",
     "exception": false,
     "start_time": "2024-02-22T00:46:04.320843",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34236d5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T00:46:04.341178Z",
     "iopub.status.busy": "2024-02-22T00:46:04.340459Z",
     "iopub.status.idle": "2024-02-22T00:46:05.531347Z",
     "shell.execute_reply": "2024-02-22T00:46:05.530247Z"
    },
    "papermill": {
     "duration": 1.20005,
     "end_time": "2024-02-22T00:46:05.533343",
     "exception": false,
     "start_time": "2024-02-22T00:46:04.333293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 129495548.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 50431179.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 38749048.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 29581566.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Image batch dimensions: torch.Size([64, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE=64\n",
    "\n",
    "# note transforms.ToTensor() scales input images to 0-1 range\n",
    "train_dataset=datasets.MNIST(root='data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset=datasets.MNIST(root='data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader=DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader=DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# checking the dataset\n",
    "for images, labels in train_loader:\n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb358c0",
   "metadata": {
    "papermill": {
     "duration": 0.007972,
     "end_time": "2024-02-22T00:46:05.549396",
     "exception": false,
     "start_time": "2024-02-22T00:46:05.541424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Evaluation and Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b68afd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T00:46:05.566311Z",
     "iopub.status.busy": "2024-02-22T00:46:05.566012Z",
     "iopub.status.idle": "2024-02-22T00:48:27.591470Z",
     "shell.execute_reply": "2024-02-22T00:48:27.590351Z"
    },
    "papermill": {
     "duration": 142.036624,
     "end_time": "2024-02-22T00:48:27.593748",
     "exception": false,
     "start_time": "2024-02-22T00:46:05.557124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/010 | Batch 000/938 | Loss: 2.3110\n",
      "Epoch 001/010 | Batch 400/938 | Loss: 0.1470\n",
      "Epoch 001/010 | Batch 800/938 | Loss: 0.2974\n",
      "Epoch: 001/010 training accuracy: 95.42%\n",
      "Time elapsed: 0.24 min\n",
      "Epoch 002/010 | Batch 000/938 | Loss: 0.0643\n",
      "Epoch 002/010 | Batch 400/938 | Loss: 0.1181\n",
      "Epoch 002/010 | Batch 800/938 | Loss: 0.1319\n",
      "Epoch: 002/010 training accuracy: 96.01%\n",
      "Time elapsed: 0.48 min\n",
      "Epoch 003/010 | Batch 000/938 | Loss: 0.1533\n",
      "Epoch 003/010 | Batch 400/938 | Loss: 0.0541\n",
      "Epoch 003/010 | Batch 800/938 | Loss: 0.1072\n",
      "Epoch: 003/010 training accuracy: 97.22%\n",
      "Time elapsed: 0.71 min\n",
      "Epoch 004/010 | Batch 000/938 | Loss: 0.1163\n",
      "Epoch 004/010 | Batch 400/938 | Loss: 0.0741\n",
      "Epoch 004/010 | Batch 800/938 | Loss: 0.1829\n",
      "Epoch: 004/010 training accuracy: 97.68%\n",
      "Time elapsed: 0.95 min\n",
      "Epoch 005/010 | Batch 000/938 | Loss: 0.0283\n",
      "Epoch 005/010 | Batch 400/938 | Loss: 0.1460\n",
      "Epoch 005/010 | Batch 800/938 | Loss: 0.1727\n",
      "Epoch: 005/010 training accuracy: 96.90%\n",
      "Time elapsed: 1.18 min\n",
      "Epoch 006/010 | Batch 000/938 | Loss: 0.0635\n",
      "Epoch 006/010 | Batch 400/938 | Loss: 0.1518\n",
      "Epoch 006/010 | Batch 800/938 | Loss: 0.2216\n",
      "Epoch: 006/010 training accuracy: 97.30%\n",
      "Time elapsed: 1.42 min\n",
      "Epoch 007/010 | Batch 000/938 | Loss: 0.0295\n",
      "Epoch 007/010 | Batch 400/938 | Loss: 0.0786\n",
      "Epoch 007/010 | Batch 800/938 | Loss: 0.1485\n",
      "Epoch: 007/010 training accuracy: 97.73%\n",
      "Time elapsed: 1.65 min\n",
      "Epoch 008/010 | Batch 000/938 | Loss: 0.0299\n",
      "Epoch 008/010 | Batch 400/938 | Loss: 0.0208\n",
      "Epoch 008/010 | Batch 800/938 | Loss: 0.1708\n",
      "Epoch: 008/010 training accuracy: 98.56%\n",
      "Time elapsed: 1.88 min\n",
      "Epoch 009/010 | Batch 000/938 | Loss: 0.0052\n",
      "Epoch 009/010 | Batch 400/938 | Loss: 0.0359\n",
      "Epoch 009/010 | Batch 800/938 | Loss: 0.1250\n",
      "Epoch: 009/010 training accuracy: 98.26%\n",
      "Time elapsed: 2.12 min\n",
      "Epoch 010/010 | Batch 000/938 | Loss: 0.0273\n",
      "Epoch 010/010 | Batch 400/938 | Loss: 0.0699\n",
      "Epoch 010/010 | Batch 800/938 | Loss: 0.0878\n",
      "Epoch: 010/010 training accuracy: 98.61%\n",
      "Time elapsed: 2.35 min\n",
      "Total Training TIme: 2.35 min\n",
      "Test accuracy: 97.19%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def compute_accuracy(model, data_loader, device):\n",
    "    model.eval()\n",
    "    correct_pred, num_examples=0,0\n",
    "    with torch.no_grad():\n",
    "        for features, targets in data_loader:\n",
    "            features=features.view(-1, 28*28).to(device)\n",
    "            targets=targets.to(device)\n",
    "            logits=model(features)\n",
    "            _, predicted_labels=torch.max(logits,1)\n",
    "            num_examples+=targets.size(0)\n",
    "            correct_pred+=(predicted_labels==targets).sum()\n",
    "        return correct_pred.float()/num_examples*100\n",
    "\n",
    "def train(num_epochs, model, optimizer, train_loader, device):\n",
    "    start_time=time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "            features=features.view(-1, 28*28).to(device)\n",
    "            targets=targets.to(device)\n",
    "            \n",
    "            # Forward and backpropgation\n",
    "            logits=model(features)\n",
    "            loss=F.cross_entropy(logits, targets)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            # update model parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            #logging\n",
    "            if not batch_idx %400:\n",
    "                print('Epoch %03d/%03d | Batch %03d/%03d | Loss: %.4f' % (epoch+1, num_epochs, batch_idx, len(train_loader), loss))\n",
    "        with torch.set_grad_enabled(False):\n",
    "            print('Epoch: %03d/%03d training accuracy: %0.2f%%' % (epoch+1, num_epochs, compute_accuracy(model, train_loader, device)))\n",
    "        print('Time elapsed: %.2f min' % ((time.time()- start_time)/60))\n",
    "    print('Total Training TIme: %.2f min' % ((time.time()-start_time)/60))\n",
    "    \n",
    "\n",
    "train(num_epochs, model, optimizer_pretrained, train_loader, DEVICE)\n",
    "print(f'Test accuracy: {compute_accuracy(model, test_loader, DEVICE):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa636b2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T00:48:27.616863Z",
     "iopub.status.busy": "2024-02-22T00:48:27.616572Z",
     "iopub.status.idle": "2024-02-22T00:48:27.623075Z",
     "shell.execute_reply": "2024-02-22T00:48:27.621968Z"
    },
    "papermill": {
     "duration": 0.019596,
     "end_time": "2024-02-22T00:48:27.624945",
     "exception": false,
     "start_time": "2024-02-22T00:48:27.605349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultilayerPerceptron(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "model_dora=copy.deepcopy(model)\n",
    "print(model_dora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b677822",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T00:48:27.646738Z",
     "iopub.status.busy": "2024-02-22T00:48:27.646465Z",
     "iopub.status.idle": "2024-02-22T00:48:27.700981Z",
     "shell.execute_reply": "2024-02-22T00:48:27.699815Z"
    },
    "papermill": {
     "duration": 0.067801,
     "end_time": "2024-02-22T00:48:27.703110",
     "exception": false,
     "start_time": "2024-02-22T00:48:27.635309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultilayerPerceptron(\n",
      "  (layers): Sequential(\n",
      "    (0): LinearWithDoRAMerged(\n",
      "      (linear): Linear(in_features=784, out_features=128, bias=True)\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "    (1): ReLU()\n",
      "    (2): LinearWithDoRAMerged(\n",
      "      (linear): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "    (3): ReLU()\n",
      "    (4): LinearWithDoRAMerged(\n",
      "      (linear): Linear(in_features=256, out_features=10, bias=True)\n",
      "      (lora): LoRALayer()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_dora.layers[0]=LinearWithDoRAMerged(model_dora.layers[0], rank=4, alpha=8)\n",
    "model_dora.layers[2]=LinearWithDoRAMerged(model_dora.layers[2], rank=4, alpha=8)\n",
    "model_dora.layers[4]=LinearWithDoRAMerged(model_dora.layers[4], rank=4, alpha=8)\n",
    "\n",
    "model_dora.to(DEVICE)\n",
    "optimizer_dora=torch.optim.Adam(model_dora.parameters(), lr=learning_rate)\n",
    "\n",
    "print(model_dora)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e6895f",
   "metadata": {
    "papermill": {
     "duration": 0.010279,
     "end_time": "2024-02-22T00:48:27.724113",
     "exception": false,
     "start_time": "2024-02-22T00:48:27.713834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Freeze the orignal weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9ec41c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T00:48:27.746483Z",
     "iopub.status.busy": "2024-02-22T00:48:27.745787Z",
     "iopub.status.idle": "2024-02-22T00:48:27.752215Z",
     "shell.execute_reply": "2024-02-22T00:48:27.751365Z"
    },
    "papermill": {
     "duration": 0.019609,
     "end_time": "2024-02-22T00:48:27.754173",
     "exception": false,
     "start_time": "2024-02-22T00:48:27.734564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.m: True\n",
      "layers.0.linear.weight: False\n",
      "layers.0.linear.bias: False\n",
      "layers.0.lora.A: True\n",
      "layers.0.lora.B: True\n",
      "layers.2.m: True\n",
      "layers.2.linear.weight: False\n",
      "layers.2.linear.bias: False\n",
      "layers.2.lora.A: True\n",
      "layers.2.lora.B: True\n",
      "layers.4.m: True\n",
      "layers.4.linear.weight: False\n",
      "layers.4.linear.bias: False\n",
      "layers.4.lora.A: True\n",
      "layers.4.lora.B: True\n"
     ]
    }
   ],
   "source": [
    "def freeze_linear_layers(model):\n",
    "    for child in model.children():\n",
    "        if isinstance(child, nn.Linear):\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad=False\n",
    "        else:\n",
    "            # recursively freeze linear layers in children modules\n",
    "            freeze_linear_layers(child)\n",
    "\n",
    "freeze_linear_layers(model_dora)\n",
    "\n",
    "# check if linear layers are frozen\n",
    "for name, param in model_dora.named_parameters():\n",
    "    print(f'{name}: {param.requires_grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6178ec2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T00:48:27.776224Z",
     "iopub.status.busy": "2024-02-22T00:48:27.775959Z",
     "iopub.status.idle": "2024-02-22T00:51:04.326378Z",
     "shell.execute_reply": "2024-02-22T00:51:04.325224Z"
    },
    "papermill": {
     "duration": 156.563859,
     "end_time": "2024-02-22T00:51:04.328515",
     "exception": false,
     "start_time": "2024-02-22T00:48:27.764656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/010 | Batch 000/938 | Loss: 0.0049\n",
      "Epoch 001/010 | Batch 400/938 | Loss: 0.0406\n",
      "Epoch 001/010 | Batch 800/938 | Loss: 0.1579\n",
      "Epoch: 001/010 training accuracy: 98.90%\n",
      "Time elapsed: 0.26 min\n",
      "Epoch 002/010 | Batch 000/938 | Loss: 0.0279\n",
      "Epoch 002/010 | Batch 400/938 | Loss: 0.0279\n",
      "Epoch 002/010 | Batch 800/938 | Loss: 0.0810\n",
      "Epoch: 002/010 training accuracy: 98.96%\n",
      "Time elapsed: 0.52 min\n",
      "Epoch 003/010 | Batch 000/938 | Loss: 0.0214\n",
      "Epoch 003/010 | Batch 400/938 | Loss: 0.0106\n",
      "Epoch 003/010 | Batch 800/938 | Loss: 0.0505\n",
      "Epoch: 003/010 training accuracy: 99.12%\n",
      "Time elapsed: 0.78 min\n",
      "Epoch 004/010 | Batch 000/938 | Loss: 0.0062\n",
      "Epoch 004/010 | Batch 400/938 | Loss: 0.0302\n",
      "Epoch 004/010 | Batch 800/938 | Loss: 0.0102\n",
      "Epoch: 004/010 training accuracy: 98.98%\n",
      "Time elapsed: 1.04 min\n",
      "Epoch 005/010 | Batch 000/938 | Loss: 0.0135\n",
      "Epoch 005/010 | Batch 400/938 | Loss: 0.0144\n",
      "Epoch 005/010 | Batch 800/938 | Loss: 0.0662\n",
      "Epoch: 005/010 training accuracy: 99.08%\n",
      "Time elapsed: 1.30 min\n",
      "Epoch 006/010 | Batch 000/938 | Loss: 0.0159\n",
      "Epoch 006/010 | Batch 400/938 | Loss: 0.0178\n",
      "Epoch 006/010 | Batch 800/938 | Loss: 0.0528\n",
      "Epoch: 006/010 training accuracy: 99.11%\n",
      "Time elapsed: 1.56 min\n",
      "Epoch 007/010 | Batch 000/938 | Loss: 0.0064\n",
      "Epoch 007/010 | Batch 400/938 | Loss: 0.0160\n",
      "Epoch 007/010 | Batch 800/938 | Loss: 0.0817\n",
      "Epoch: 007/010 training accuracy: 99.17%\n",
      "Time elapsed: 1.82 min\n",
      "Epoch 008/010 | Batch 000/938 | Loss: 0.0030\n",
      "Epoch 008/010 | Batch 400/938 | Loss: 0.0152\n",
      "Epoch 008/010 | Batch 800/938 | Loss: 0.0297\n",
      "Epoch: 008/010 training accuracy: 98.98%\n",
      "Time elapsed: 2.07 min\n",
      "Epoch 009/010 | Batch 000/938 | Loss: 0.0019\n",
      "Epoch 009/010 | Batch 400/938 | Loss: 0.0088\n",
      "Epoch 009/010 | Batch 800/938 | Loss: 0.0357\n",
      "Epoch: 009/010 training accuracy: 99.17%\n",
      "Time elapsed: 2.33 min\n",
      "Epoch 010/010 | Batch 000/938 | Loss: 0.0031\n",
      "Epoch 010/010 | Batch 400/938 | Loss: 0.0072\n",
      "Epoch 010/010 | Batch 800/938 | Loss: 0.0200\n",
      "Epoch: 010/010 training accuracy: 99.16%\n",
      "Time elapsed: 2.59 min\n",
      "Total Training TIme: 2.59 min\n",
      "Test accuracy DoRA finetune: 97.62%\n"
     ]
    }
   ],
   "source": [
    "optimizer_dora=torch.optim.Adam(model_dora.parameters(), lr=learning_rate)\n",
    "train(num_epochs, model_dora, optimizer_dora, train_loader, DEVICE)\n",
    "print(f'Test accuracy DoRA finetune: {compute_accuracy(model_dora, test_loader, DEVICE):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58121e3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T00:51:04.356214Z",
     "iopub.status.busy": "2024-02-22T00:51:04.355883Z",
     "iopub.status.idle": "2024-02-22T00:51:06.568743Z",
     "shell.execute_reply": "2024-02-22T00:51:06.567839Z"
    },
    "papermill": {
     "duration": 2.229069,
     "end_time": "2024-02-22T00:51:06.570817",
     "exception": false,
     "start_time": "2024-02-22T00:51:04.341748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 97.19%\n",
      "Test accuracy DoRA finetune: 97.62%\n"
     ]
    }
   ],
   "source": [
    "print(f'Test accuracy: {compute_accuracy(model, test_loader, DEVICE):.2f}%')\n",
    "print(f'Test accuracy DoRA finetune: {compute_accuracy(model_dora, test_loader, DEVICE):.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2406f4c8",
   "metadata": {
    "papermill": {
     "duration": 0.012984,
     "end_time": "2024-02-22T00:51:06.597849",
     "exception": false,
     "start_time": "2024-02-22T00:51:06.584865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see the result of LoRA in notebook [LoRA From Scratch](https://www.kaggle.com/code/aisuko/lora-from-scratch) is $97.46\\%$. Comparing these results, DoRA seems like a effective extension of LoRA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b890cf59",
   "metadata": {
    "papermill": {
     "duration": 0.013093,
     "end_time": "2024-02-22T00:51:06.624090",
     "exception": false,
     "start_time": "2024-02-22T00:51:06.610997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Credit\n",
    "\n",
    "* https://magazine.sebastianraschka.com/p/lora-and-dora-from-scratch\n",
    "* https://arxiv.org/abs/2402.09353\n",
    "* https://arxiv.org/abs/2106.09685\n",
    "* https://github.com/rasbt/dora-from-scratch/blob/main/lora-dora-mlp.ipynb"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 313.183343,
   "end_time": "2024-02-22T00:51:07.958508",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-22T00:45:54.775165",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
