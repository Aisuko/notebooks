{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "137cbecf",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.006552,
     "end_time": "2024-01-24T10:36:20.590196",
     "exception": false,
     "start_time": "2024-01-24T10:36:20.583644",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "About Tensors see [What are tensors?](https://www.kaggle.com/code/aisuko/what-are-tensors)\n",
    "\n",
    "We are going to use the FashionMNIST dataset to train a new simple model and optimize it using PyTorch.\n",
    "\n",
    "Pytorch has two primitives to work with data:\n",
    "\n",
    "* `torch.utils.data.DataLoader`\n",
    "* `torch.utils.data.Daset.Dataset`\n",
    "\n",
    "They stores the samples and their corresponding labels, and `DataLoader` wraps an iterable around the `Dataset`.\n",
    "\n",
    "## TORCH.UTILS.DATA\n",
    "\n",
    "`torch.utils.data.DataLoader` class is the the heart of PyTorch data loading utility. It supports for:\n",
    "\n",
    "* map-style and iterable-style datasets\n",
    "* customizing data loading order\n",
    "* automatic batching\n",
    "* single-and multi-process data loading\n",
    "* automatic memory pining\n",
    "\n",
    "More detail in the notebook [DataLoader in PyTorch](https://pytorch.org/docs/stable/data.html).\n",
    "\n",
    "PyTorch offers domain-specific libraries such as:\n",
    "* TorchText\n",
    "* TorchVision\n",
    "* TorchAudio\n",
    "\n",
    "All of which include datasets. We wil be using a TorchVision dataset. The list of `torchvision.datasets` module contains in [here](https://pytorch.org/vision/stable/datasets.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3445d4",
   "metadata": {
    "papermill": {
     "duration": 0.005256,
     "end_time": "2024-01-24T10:36:20.601133",
     "exception": false,
     "start_time": "2024-01-24T10:36:20.595877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Download the dataset\n",
    "\n",
    "Every TorchVision `Dataset` includes two arguments:\n",
    "* `transform`\n",
    "* `target_transform`\n",
    "\n",
    "to modify the samples and lables respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81274a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T10:36:20.613696Z",
     "iopub.status.busy": "2024-01-24T10:36:20.613329Z",
     "iopub.status.idle": "2024-01-24T10:36:34.461954Z",
     "shell.execute_reply": "2024-01-24T10:36:34.460878Z"
    },
    "papermill": {
     "duration": 13.857765,
     "end_time": "2024-01-24T10:36:34.464608",
     "exception": false,
     "start_time": "2024-01-24T10:36:20.606843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:05<00:00, 4752474.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 197469.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:01<00:00, 3666688.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 3137956.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data=datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data=datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0814127c",
   "metadata": {
    "papermill": {
     "duration": 0.010394,
     "end_time": "2024-01-24T10:36:34.485775",
     "exception": false,
     "start_time": "2024-01-24T10:36:34.475381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading the dataset\n",
    "\n",
    "We pass the Dataset as an argument to DataLoader. This wraps an iterable over our dataset, and supports automatic batching, sampling, shuffling and multiprocess data loading. Here we define a batch size of 64, each element in the dataloader iterable will return a batch of 64 features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fc6476d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T10:36:34.508205Z",
     "iopub.status.busy": "2024-01-24T10:36:34.507797Z",
     "iopub.status.idle": "2024-01-24T10:36:35.595981Z",
     "shell.execute_reply": "2024-01-24T10:36:35.594979Z"
    },
    "papermill": {
     "duration": 1.106358,
     "end_time": "2024-01-24T10:36:35.602687",
     "exception": false,
     "start_time": "2024-01-24T10:36:34.496329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N,C,H,W]:torch.Size([16, 1, 28, 28])\n",
      "Shape of y: torch.Size([16]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "train_dataloader=DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader=DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N,C,H,W]:{X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e9ba08",
   "metadata": {
    "papermill": {
     "duration": 0.013037,
     "end_time": "2024-01-24T10:36:35.627942",
     "exception": false,
     "start_time": "2024-01-24T10:36:35.614905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define a Model\n",
    "\n",
    "To define a neural network in PyTorch, we create a class that inherits from [nn.Module](). We define the layers of the network in the `__init__` function and specify how data will pass through the network in the `forward` function. To accelerate operations in the neural network, we move it to the GPU or MPS if avaliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30cd717f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T10:36:35.654956Z",
     "iopub.status.busy": "2024-01-24T10:36:35.654103Z",
     "iopub.status.idle": "2024-01-24T10:36:35.711715Z",
     "shell.execute_reply": "2024-01-24T10:36:35.710723Z"
    },
    "papermill": {
     "duration": 0.072987,
     "end_time": "2024-01-24T10:36:35.713579",
     "exception": false,
     "start_time": "2024-01-24T10:36:35.640592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7826e7da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T10:36:35.738924Z",
     "iopub.status.busy": "2024-01-24T10:36:35.738635Z",
     "iopub.status.idle": "2024-01-24T10:36:35.896151Z",
     "shell.execute_reply": "2024-01-24T10:36:35.895284Z"
    },
    "papermill": {
     "duration": 0.172271,
     "end_time": "2024-01-24T10:36:35.898073",
     "exception": false,
     "start_time": "2024-01-24T10:36:35.725802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten=nn.Flatten()\n",
    "        self.linear_relu_stack=nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.flatten(x)\n",
    "        logits=self.linear_relu_stack(x)\n",
    "        return logits\n",
    "model=NeuralNetwork().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e028c6c",
   "metadata": {
    "papermill": {
     "duration": 0.011644,
     "end_time": "2024-01-24T10:36:35.922721",
     "exception": false,
     "start_time": "2024-01-24T10:36:35.911077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Optimizing the Model Parameters\n",
    "\n",
    "To train a model, we need a [loss function]() and [optimizer]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "056ebc9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T10:36:35.947853Z",
     "iopub.status.busy": "2024-01-24T10:36:35.947553Z",
     "iopub.status.idle": "2024-01-24T10:36:35.952089Z",
     "shell.execute_reply": "2024-01-24T10:36:35.951230Z"
    },
    "papermill": {
     "duration": 0.019112,
     "end_time": "2024-01-24T10:36:35.954008",
     "exception": false,
     "start_time": "2024-01-24T10:36:35.934896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3498e9b",
   "metadata": {
    "papermill": {
     "duration": 0.011362,
     "end_time": "2024-01-24T10:36:35.977076",
     "exception": false,
     "start_time": "2024-01-24T10:36:35.965714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training the model\n",
    "\n",
    "In a single training loop, the model maskes predictions on the training dataset(fed to it in batches), and backpropagates the prediction error to adjust the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1af35fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T10:36:36.001339Z",
     "iopub.status.busy": "2024-01-24T10:36:36.001097Z",
     "iopub.status.idle": "2024-01-24T10:36:36.007290Z",
     "shell.execute_reply": "2024-01-24T10:36:36.006474Z"
    },
    "papermill": {
     "duration": 0.020361,
     "end_time": "2024-01-24T10:36:36.009060",
     "exception": false,
     "start_time": "2024-01-24T10:36:35.988699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size=len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X,y =X.to(device), y.to(device)\n",
    "        \n",
    "        # compute prediction error\n",
    "        pred=model(X)\n",
    "        loss=loss_fn(pred,y)\n",
    "\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch%100==0:\n",
    "            loss,current=loss.item(), (batch+1) *len(X)\n",
    "            print(f\"loss:{loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364cfd08",
   "metadata": {
    "papermill": {
     "duration": 0.011465,
     "end_time": "2024-01-24T10:36:36.032041",
     "exception": false,
     "start_time": "2024-01-24T10:36:36.020576",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edd7565e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T10:36:36.056355Z",
     "iopub.status.busy": "2024-01-24T10:36:36.056099Z",
     "iopub.status.idle": "2024-01-24T10:36:36.062162Z",
     "shell.execute_reply": "2024-01-24T10:36:36.061349Z"
    },
    "papermill": {
     "duration": 0.020395,
     "end_time": "2024-01-24T10:36:36.063989",
     "exception": false,
     "start_time": "2024-01-24T10:36:36.043594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size=len(dataloader.dataset)\n",
    "    num_batches=len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct=0,0\n",
    "    with torch.no_grad():\n",
    "        for X,y in dataloader:\n",
    "            X,y =X.to(device), y.to(device)\n",
    "            pred=model(X)\n",
    "            test_loss+=loss_fn(pred, y).item()\n",
    "            correct+=(pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "    test_loss/=num_batches\n",
    "    correct/=size\n",
    "    print(f\"Test Error:\\n Accuracy: {(100*correct):>0.1f}%, Avg loss:{test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73421047",
   "metadata": {
    "papermill": {
     "duration": 0.011337,
     "end_time": "2024-01-24T10:36:36.086959",
     "exception": false,
     "start_time": "2024-01-24T10:36:36.075622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The training process is conducted over several iterations(epochs). During each epoch, the model learns parameters to make better predictions. We print the model's accuracy and loss at each spoch; we'd like to see the accuracy increase and the loss decrease with every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf074961",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T10:36:36.110961Z",
     "iopub.status.busy": "2024-01-24T10:36:36.110704Z",
     "iopub.status.idle": "2024-01-24T10:37:17.392191Z",
     "shell.execute_reply": "2024-01-24T10:37:17.391204Z"
    },
    "papermill": {
     "duration": 41.296101,
     "end_time": "2024-01-24T10:37:17.394490",
     "exception": false,
     "start_time": "2024-01-24T10:36:36.098389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "------------\n",
      "loss:2.309162 [   64/60000]\n",
      "loss:2.287271 [ 6464/60000]\n",
      "loss:2.270671 [12864/60000]\n",
      "loss:2.271568 [19264/60000]\n",
      "loss:2.250602 [25664/60000]\n",
      "loss:2.226507 [32064/60000]\n",
      "loss:2.242480 [38464/60000]\n",
      "loss:2.204216 [44864/60000]\n",
      "loss:2.207146 [51264/60000]\n",
      "loss:2.180778 [57664/60000]\n",
      "Test Error:\n",
      " Accuracy: 46.2%, Avg loss:2.166024 \n",
      "\n",
      "Epoch 2\n",
      "------------\n",
      "loss:2.184081 [   64/60000]\n",
      "loss:2.160520 [ 6464/60000]\n",
      "loss:2.106382 [12864/60000]\n",
      "loss:2.125067 [19264/60000]\n",
      "loss:2.069165 [25664/60000]\n",
      "loss:2.023327 [32064/60000]\n",
      "loss:2.053430 [38464/60000]\n",
      "loss:1.969500 [44864/60000]\n",
      "loss:1.982460 [51264/60000]\n",
      "loss:1.914750 [57664/60000]\n",
      "Test Error:\n",
      " Accuracy: 53.4%, Avg loss:1.900546 \n",
      "\n",
      "Epoch 3\n",
      "------------\n",
      "loss:1.942873 [   64/60000]\n",
      "loss:1.900106 [ 6464/60000]\n",
      "loss:1.780484 [12864/60000]\n",
      "loss:1.820999 [19264/60000]\n",
      "loss:1.712080 [25664/60000]\n",
      "loss:1.668019 [32064/60000]\n",
      "loss:1.694818 [38464/60000]\n",
      "loss:1.585313 [44864/60000]\n",
      "loss:1.619307 [51264/60000]\n",
      "loss:1.514308 [57664/60000]\n",
      "Test Error:\n",
      " Accuracy: 58.9%, Avg loss:1.522891 \n",
      "\n",
      "Epoch 4\n",
      "------------\n",
      "loss:1.597852 [   64/60000]\n",
      "loss:1.555665 [ 6464/60000]\n",
      "loss:1.397140 [12864/60000]\n",
      "loss:1.470597 [19264/60000]\n",
      "loss:1.351657 [25664/60000]\n",
      "loss:1.348909 [32064/60000]\n",
      "loss:1.366191 [38464/60000]\n",
      "loss:1.282378 [44864/60000]\n",
      "loss:1.326809 [51264/60000]\n",
      "loss:1.228824 [57664/60000]\n",
      "Test Error:\n",
      " Accuracy: 62.2%, Avg loss:1.250336 \n",
      "\n",
      "Epoch 5\n",
      "------------\n",
      "loss:1.330985 [   64/60000]\n",
      "loss:1.311579 [ 6464/60000]\n",
      "loss:1.137586 [12864/60000]\n",
      "loss:1.249430 [19264/60000]\n",
      "loss:1.121543 [25664/60000]\n",
      "loss:1.147011 [32064/60000]\n",
      "loss:1.172487 [38464/60000]\n",
      "loss:1.102679 [44864/60000]\n",
      "loss:1.151830 [51264/60000]\n",
      "loss:1.071661 [57664/60000]\n",
      "Test Error:\n",
      " Accuracy: 64.1%, Avg loss:1.087824 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs=5\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2820f89b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T10:37:17.427217Z",
     "iopub.status.busy": "2024-01-24T10:37:17.426919Z",
     "iopub.status.idle": "2024-01-24T10:37:17.439604Z",
     "shell.execute_reply": "2024-01-24T10:37:17.438746Z"
    },
    "papermill": {
     "duration": 0.030977,
     "end_time": "2024-01-24T10:37:17.441563",
     "exception": false,
     "start_time": "2024-01-24T10:37:17.410586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"simple_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad07a374",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T10:37:17.473494Z",
     "iopub.status.busy": "2024-01-24T10:37:17.473226Z",
     "iopub.status.idle": "2024-01-24T10:37:18.419834Z",
     "shell.execute_reply": "2024-01-24T10:37:18.418812Z"
    },
    "papermill": {
     "duration": 0.964931,
     "end_time": "2024-01-24T10:37:18.422169",
     "exception": false,
     "start_time": "2024-01-24T10:37:17.457238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  data  simple_model.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7890e71b",
   "metadata": {
    "papermill": {
     "duration": 0.015272,
     "end_time": "2024-01-24T10:37:18.453086",
     "exception": false,
     "start_time": "2024-01-24T10:37:18.437814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference\n",
    "\n",
    "The process of loading a model includes re-creating the model structure and loading the state dictionary into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fecfaec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T10:37:18.487808Z",
     "iopub.status.busy": "2024-01-24T10:37:18.487218Z",
     "iopub.status.idle": "2024-01-24T10:37:18.594548Z",
     "shell.execute_reply": "2024-01-24T10:37:18.593686Z"
    },
    "papermill": {
     "duration": 0.127509,
     "end_time": "2024-01-24T10:37:18.596533",
     "exception": false,
     "start_time": "2024-01-24T10:37:18.469024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2af7593a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T10:37:18.630352Z",
     "iopub.status.busy": "2024-01-24T10:37:18.630063Z",
     "iopub.status.idle": "2024-01-24T10:37:18.647295Z",
     "shell.execute_reply": "2024-01-24T10:37:18.646459Z"
    },
    "papermill": {
     "duration": 0.036295,
     "end_time": "2024-01-24T10:37:18.649196",
     "exception": false,
     "start_time": "2024-01-24T10:37:18.612901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"simple_model.pth\"))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f98d8fe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T10:37:18.681878Z",
     "iopub.status.busy": "2024-01-24T10:37:18.681592Z",
     "iopub.status.idle": "2024-01-24T10:37:18.701999Z",
     "shell.execute_reply": "2024-01-24T10:37:18.701216Z"
    },
    "papermill": {
     "duration": 0.03873,
     "end_time": "2024-01-24T10:37:18.703818",
     "exception": false,
     "start_time": "2024-01-24T10:37:18.665088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: Ankle boot, Actual: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "classes=[\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x,y=test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x=x.to(device)\n",
    "    pred=model(x)\n",
    "    predicted,actual=classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f\"Predicted: {predicted}, Actual: {actual}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 62.708085,
   "end_time": "2024-01-24T10:37:19.881774",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-24T10:36:17.173689",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
