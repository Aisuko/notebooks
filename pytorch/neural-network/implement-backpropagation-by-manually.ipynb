{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bb53e64",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.011,
     "end_time": "2024-08-04T01:41:22.448947",
     "exception": false,
     "start_time": "2024-08-04T01:41:22.437947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "Let's implement backpropgation manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb5aa149",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:41:22.472258Z",
     "iopub.status.busy": "2024-08-04T01:41:22.471814Z",
     "iopub.status.idle": "2024-08-04T01:41:27.566733Z",
     "shell.execute_reply": "2024-08-04T01:41:27.564776Z"
    },
    "papermill": {
     "duration": 5.110282,
     "end_time": "2024-08-04T01:41:27.569870",
     "exception": false,
     "start_time": "2024-08-04T01:41:22.459588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "# read in all the words\n",
    "with open('/kaggle/input/character-lm-without-framework/names.txt', 'r', encoding='utf-8') as f:\n",
    "    words=f.read()\n",
    "\n",
    "words=words.splitlines()\n",
    "\n",
    "# build the vocabulary of characters and \n",
    "chars=sorted(list(set(''.join(words))))\n",
    "\n",
    "stoi={s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.']=0\n",
    "itos={i:s for s,i in stoi.items()}\n",
    "vocab_size=len(itos)\n",
    "block_size=3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):\n",
    "    X,Y=[],[]\n",
    "    \n",
    "    for w in words:\n",
    "        context=[0]*block_size\n",
    "        for ch in w+'.':\n",
    "            ix=stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context=context[1:]+[ix] # crop and append\n",
    "            \n",
    "    X=torch.tensor(X)\n",
    "    Y=torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X,Y\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1=int(0.8*len(words))\n",
    "n2=int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr=build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev=build_dataset(words[n1:n2]) # 10%\n",
    "Xte, Yte=build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1ced464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:41:27.595114Z",
     "iopub.status.busy": "2024-08-04T01:41:27.594518Z",
     "iopub.status.idle": "2024-08-04T01:41:27.602138Z",
     "shell.execute_reply": "2024-08-04T01:41:27.600879Z"
    },
    "papermill": {
     "duration": 0.023162,
     "end_time": "2024-08-04T01:41:27.604798",
     "exception": false,
     "start_time": "2024-08-04T01:41:27.581636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt,t):\n",
    "    ex=torch.all(dt==t.grad).item() # make sure all the elements are exactly equal and then converting a single boolean value\n",
    "    # make sure they aren't exactly equal, they are approximately equal(there may some floating point issues: floating point arithmetic)\n",
    "    app=torch.allclose(dt, t.grad)\n",
    "    # check what is the highest difference \n",
    "    maxdiff=(dt-t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3482f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:41:27.629686Z",
     "iopub.status.busy": "2024-08-04T01:41:27.629266Z",
     "iopub.status.idle": "2024-08-04T01:41:27.680723Z",
     "shell.execute_reply": "2024-08-04T01:41:27.679393Z"
    },
    "papermill": {
     "duration": 0.067152,
     "end_time": "2024-08-04T01:41:27.683601",
     "exception": false,
     "start_time": "2024-08-04T01:41:27.616449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "# initialization\n",
    "n_embd=10 # the dimensionality of the character embedding vectors\n",
    "n_hidden=64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g=torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C=torch.randn((vocab_size, n_embd), generator=g) # embedding table for the characters\n",
    "# Layer 1\n",
    "W1=torch.randn((n_embd*block_size, n_hidden), generator=g)*(5/3)/((n_embd* block_size)**0.5)\n",
    "b1=torch.randn(n_hidden,            generator=g) # b1 is useless here, it aims for us to check if the implement is correct\n",
    "# Layer 2\n",
    "W2=torch.randn((n_hidden, vocab_size), generator=g)*0.1\n",
    "b2=torch.randn(vocab_size, generator=g)*0.1\n",
    "# batchnorm parameters\n",
    "bngain=torch.randn((1, n_hidden))*0.1+1.0\n",
    "bnbias=torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: we initializating many of thrse parameters in non-standard ways\n",
    "# becuase sometimes initializating with e.g all zeros coudl mask an incorrect implementation of the backward pass\n",
    "\n",
    "parameters=[C,W1,b1,W2,b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71760ad4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:41:27.707357Z",
     "iopub.status.busy": "2024-08-04T01:41:27.706904Z",
     "iopub.status.idle": "2024-08-04T01:41:27.729695Z",
     "shell.execute_reply": "2024-08-04T01:41:27.728365Z"
    },
    "papermill": {
     "duration": 0.03814,
     "end_time": "2024-08-04T01:41:27.732682",
     "exception": false,
     "start_time": "2024-08-04T01:41:27.694542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "n=batch_size\n",
    "# construct a minibatch\n",
    "ix=torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb=Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31b0da53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:41:27.756704Z",
     "iopub.status.busy": "2024-08-04T01:41:27.756258Z",
     "iopub.status.idle": "2024-08-04T01:41:27.883045Z",
     "shell.execute_reply": "2024-08-04T01:41:27.881634Z"
    },
    "papermill": {
     "duration": 0.142493,
     "end_time": "2024-08-04T01:41:27.886299",
     "exception": false,
     "start_time": "2024-08-04T01:41:27.743806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 10])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([30, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.3345, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb=C[Xb] # embed the characters into vectors\n",
    "print(emb.shape)\n",
    "embcat=emb.view(emb.shape[0],-1) # concatenate the vectors\n",
    "print(embcat.shape)\n",
    "print(W1.shape)\n",
    "# Linear layer 1\n",
    "hprebn=embcat@W1+b1 # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani=1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff=hprebn-bnmeani\n",
    "bndiff2=bndiff**2\n",
    "bnvar=1/(n-1)*(bndiff2).sum(0, keepdim=True)\n",
    "bnvar_inv=(bnvar+1e-5)**-0.5\n",
    "bnraw=bndiff*bnvar_inv\n",
    "hpreact=bngain*bnraw+bnbias\n",
    "# non-linearity\n",
    "h=torch.tanh(hpreact) # hidden layer\n",
    "# linear layer 2\n",
    "logits=h@W2+b2 # output layer\n",
    "\n",
    "\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "\n",
    "logit_maxes=logits.max(1, keepdim=True).values\n",
    "norm_logits=logits-logit_maxes # subtract max for nemerical stability\n",
    "counts=norm_logits.exp() # keep the logits on small values avoid numerical issues\n",
    "counts_sum=counts.sum(1, keepdims=True)\n",
    "\n",
    "\n",
    "# normalization all the counts to create our probabilities\n",
    "counts_sum_inv=counts_sum**-1 # if we use (1.0/counts_sum) instead then we can't get backprop to be bit exact...\n",
    "probs=counts*counts_sum_inv\n",
    "logprobs=probs.log()\n",
    "loss=-logprobs[range(n), Yb].mean()\n",
    "\n",
    "# pytorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad=None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, norm_logits, logit_maxes, logits, h, hpreact, bnraw, bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani, embcat, emb]:\n",
    "    t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da26cc87",
   "metadata": {
    "papermill": {
     "duration": 0.01129,
     "end_time": "2024-08-04T01:41:27.908843",
     "exception": false,
     "start_time": "2024-08-04T01:41:27.897553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Implement backprop manually\n",
    "\n",
    "`dlogprobs` will hold the derivative of the loss with respect to all the elements of log props. It should also be an array that size same to `logprobs` because we want the derivative loss with respect to all of its elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06ece9e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:41:27.934106Z",
     "iopub.status.busy": "2024-08-04T01:41:27.933666Z",
     "iopub.status.idle": "2024-08-04T01:41:27.942098Z",
     "shell.execute_reply": "2024-08-04T01:41:27.940606Z"
    },
    "papermill": {
     "duration": 0.023844,
     "end_time": "2024-08-04T01:41:27.944902",
     "exception": false,
     "start_time": "2024-08-04T01:41:27.921058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf29a7b",
   "metadata": {
    "papermill": {
     "duration": 0.011115,
     "end_time": "2024-08-04T01:41:27.967330",
     "exception": false,
     "start_time": "2024-08-04T01:41:27.956215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## How does log props influence the loss?\n",
    "\n",
    "We see the loss equal to `loss=-logprobs[range(n), Yb].mean()`. Yb here is an array includes all the correct indices. So, here each single row of logprobs, we are plucking out the index of column specified by the tensor `Yb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66aad5fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:41:27.992271Z",
     "iopub.status.busy": "2024-08-04T01:41:27.991200Z",
     "iopub.status.idle": "2024-08-04T01:41:27.999695Z",
     "shell.execute_reply": "2024-08-04T01:41:27.998364Z"
    },
    "papermill": {
     "duration": 0.024038,
     "end_time": "2024-08-04T01:41:28.002647",
     "exception": false,
     "start_time": "2024-08-04T01:41:27.978609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ee861f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:41:28.027891Z",
     "iopub.status.busy": "2024-08-04T01:41:28.027417Z",
     "iopub.status.idle": "2024-08-04T01:41:28.036701Z",
     "shell.execute_reply": "2024-08-04T01:41:28.035379Z"
    },
    "papermill": {
     "duration": 0.024903,
     "end_time": "2024-08-04T01:41:28.039324",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.014421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs[0, Yb[0]]==logprobs[0][Yb[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c24bed5",
   "metadata": {
    "papermill": {
     "duration": 0.011402,
     "end_time": "2024-08-04T01:41:28.062344",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.050942",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Here we plugs out all those log probabilities of the correct next character in a sequence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b2fdc76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:41:28.088286Z",
     "iopub.status.busy": "2024-08-04T01:41:28.087799Z",
     "iopub.status.idle": "2024-08-04T01:41:28.097406Z",
     "shell.execute_reply": "2024-08-04T01:41:28.096042Z"
    },
    "papermill": {
     "duration": 0.026016,
     "end_time": "2024-08-04T01:41:28.100223",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.074207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.9452, -3.1524, -3.6149, -3.2416, -4.1742, -3.4311, -3.0489, -4.1038,\n",
       "        -3.1676, -4.3305, -3.0685, -1.6791, -2.7507, -3.0032, -2.9551, -3.1773,\n",
       "        -3.7208, -3.0068, -3.4923, -3.3582, -2.8387, -3.0204, -4.3691, -4.0494,\n",
       "        -3.4407, -2.8786, -2.9188, -4.0382, -2.8562, -3.3521, -3.3506, -3.1698],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs[range(n), Yb]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b2650a",
   "metadata": {
    "papermill": {
     "duration": 0.01298,
     "end_time": "2024-08-04T01:41:28.125197",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.112217",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Deriviative represent in number\n",
    "\n",
    "`loss=-(a+b+c)/3=-1/3a+ -1/3b+-1/3c` and `dloss/da=-1/3` n is 3 here.\n",
    "\n",
    "Here, we have n=32(batch_size). So, `dloss/da=-1/n`.\n",
    "\n",
    "\n",
    "### What about the other elements inside logprobs?\n",
    "\n",
    "Here n is equal to `batch_size`, it is less than the length of logprobs(32,27). Only 32 of logprobs participate in the loss calculation.\n",
    "\n",
    "### What's the derivative of all the other most of elements that don't get plucked out here?\n",
    "\n",
    "Their gradient intuitively is zero because they didn't participate in the loss. So, the most of these numbers inside this tensor doesn't feed into the loss. And if you were to change these numbers then the loss doen't change which is the equivalent of way of the derovative of the loss with respect to them is zero. They don't impact it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96d860c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:41:28.160862Z",
     "iopub.status.busy": "2024-08-04T01:41:28.160252Z",
     "iopub.status.idle": "2024-08-04T01:41:28.172890Z",
     "shell.execute_reply": "2024-08-04T01:41:28.171632Z"
    },
    "papermill": {
     "duration": 0.034793,
     "end_time": "2024-08-04T01:41:28.177391",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.142598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "        -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of dlogprobs is always going to be equal to logprobs\n",
    "# don't hardcode the number\n",
    "dlogprobs=torch.zeros_like(logprobs)\n",
    "\n",
    "# set the dloss/da=-1/n inside exactly these locations.\n",
    "dlogprobs[range(n), Yb]=-1.0/n\n",
    "dlogprobs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0edd57",
   "metadata": {
    "papermill": {
     "duration": 0.013329,
     "end_time": "2024-08-04T01:41:28.207899",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.194570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Check if the value is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a32e804d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:41:28.233738Z",
     "iopub.status.busy": "2024-08-04T01:41:28.233280Z",
     "iopub.status.idle": "2024-08-04T01:41:28.249937Z",
     "shell.execute_reply": "2024-08-04T01:41:28.248201Z"
    },
    "papermill": {
     "duration": 0.032963,
     "end_time": "2024-08-04T01:41:28.252846",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.219883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# our result equal to what pytorch calculated to be lockprops.grad in its back propagation\n",
    "cmp('logprobs', dlogprobs, logprobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec0c64c",
   "metadata": {
    "papermill": {
     "duration": 0.016848,
     "end_time": "2024-08-04T01:41:28.282748",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.265900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Props of a lognode\n",
    "\n",
    "Based on `logprobs=probs.log()`, the props of the log node will be the **local derivative** of that individual operation log times the output(here is `dlogprobs`).\n",
    "\n",
    "Based on $\\frac{d}{dx}(log(x))=\\frac{1}{x}$, x here is probs.\n",
    "\n",
    "### Chain rule\n",
    "\n",
    "In calculus, it is a formula that express the derivative of the composition of two differentiable functions f and g in terms of the derivatives of f and g.\n",
    "\n",
    "if $h=f*g$ is the function such that $h(x)=f(g(x))$ for every x, then the chain rule is\n",
    "\n",
    "$$h'(x)=f'(g(x))g'(x)$$ or, equivalently\n",
    "\n",
    "$$h'=(f*g)'=(f'*g)*g'$$\n",
    "\n",
    "### Lagrange's notation\n",
    "\n",
    "If `f` is a function, then its derivative evaluated at `x` is written $f'(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48c55779",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:41:28.320665Z",
     "iopub.status.busy": "2024-08-04T01:41:28.319236Z",
     "iopub.status.idle": "2024-08-04T01:41:28.328671Z",
     "shell.execute_reply": "2024-08-04T01:41:28.326546Z"
    },
    "papermill": {
     "duration": 0.030869,
     "end_time": "2024-08-04T01:41:28.332227",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.301358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dlogprobs is chain rule\n",
    "dprobs=(1.0 /probs)*dlogprobs # if the probs is incorrect, we will boost the gradient thorugh this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "000a82df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:41:28.358557Z",
     "iopub.status.busy": "2024-08-04T01:41:28.358021Z",
     "iopub.status.idle": "2024-08-04T01:41:28.366661Z",
     "shell.execute_reply": "2024-08-04T01:41:28.365223Z"
    },
    "papermill": {
     "duration": 0.024508,
     "end_time": "2024-08-04T01:41:28.369153",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.344645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('probs', dprobs, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd17169",
   "metadata": {
    "papermill": {
     "duration": 0.011669,
     "end_time": "2024-08-04T01:41:28.392833",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.381164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Derivative the counts_sum_inv\n",
    "\n",
    "Be cautions of the shape of these tensors.\n",
    "\n",
    "```\n",
    "c=a*b, but with tensors:\n",
    "* a[3x3] b[3,1]\n",
    "* a11*b1 a12*b1 a13*b1\n",
    "* a21*b2 a22*b2 a23*b2\n",
    "* a31*b3 a32*b3 a33*b3\n",
    "* c[3x3]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56e4023d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:41:28.420036Z",
     "iopub.status.busy": "2024-08-04T01:41:28.418650Z",
     "iopub.status.idle": "2024-08-04T01:41:28.426917Z",
     "shell.execute_reply": "2024-08-04T01:41:28.425692Z"
    },
    "papermill": {
     "duration": 0.024864,
     "end_time": "2024-08-04T01:41:28.429671",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.404807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09661e16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:41:28.463320Z",
     "iopub.status.busy": "2024-08-04T01:41:28.462429Z",
     "iopub.status.idle": "2024-08-04T01:41:28.468925Z",
     "shell.execute_reply": "2024-08-04T01:41:28.467345Z"
    },
    "papermill": {
     "duration": 0.029185,
     "end_time": "2024-08-04T01:41:28.471970",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.442785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dcounts_sum_inv=(counts*dprobs).sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73ba4168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:41:28.506864Z",
     "iopub.status.busy": "2024-08-04T01:41:28.506368Z",
     "iopub.status.idle": "2024-08-04T01:41:28.513906Z",
     "shell.execute_reply": "2024-08-04T01:41:28.512593Z"
    },
    "papermill": {
     "duration": 0.027996,
     "end_time": "2024-08-04T01:41:28.516779",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.488783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2fcf09",
   "metadata": {
    "papermill": {
     "duration": 0.013118,
     "end_time": "2024-08-04T01:41:28.542954",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.529836",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Deriviative dcounts and dcounts_sum\n",
    "\n",
    "$$\\frac{d}{dx}(\\frac{1}{x})=-\\frac{1}{x^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "682b2e9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:41:28.572884Z",
     "iopub.status.busy": "2024-08-04T01:41:28.572394Z",
     "iopub.status.idle": "2024-08-04T01:41:28.578675Z",
     "shell.execute_reply": "2024-08-04T01:41:28.577467Z"
    },
    "papermill": {
     "duration": 0.02304,
     "end_time": "2024-08-04T01:41:28.581571",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.558531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dcounts=counts_sum_inv*dprobs\n",
    "dcounts_sum=(-counts_sum**-2)* dcounts_sum_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7161dec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:41:28.608493Z",
     "iopub.status.busy": "2024-08-04T01:41:28.608021Z",
     "iopub.status.idle": "2024-08-04T01:41:28.615551Z",
     "shell.execute_reply": "2024-08-04T01:41:28.614172Z"
    },
    "papermill": {
     "duration": 0.0241,
     "end_time": "2024-08-04T01:41:28.618246",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.594146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('counts_sum', dcounts_sum, counts_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508cbd83",
   "metadata": {
    "papermill": {
     "duration": 0.01212,
     "end_time": "2024-08-04T01:41:28.643696",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.631576",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Derivative counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a8dd4b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:41:28.670158Z",
     "iopub.status.busy": "2024-08-04T01:41:28.669709Z",
     "iopub.status.idle": "2024-08-04T01:41:28.675861Z",
     "shell.execute_reply": "2024-08-04T01:41:28.674650Z"
    },
    "papermill": {
     "duration": 0.022475,
     "end_time": "2024-08-04T01:41:28.678501",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.656026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dcounts+=torch.ones_like(counts)*dcounts_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25ae5bc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:41:28.705931Z",
     "iopub.status.busy": "2024-08-04T01:41:28.705404Z",
     "iopub.status.idle": "2024-08-04T01:41:28.712921Z",
     "shell.execute_reply": "2024-08-04T01:41:28.711430Z"
    },
    "papermill": {
     "duration": 0.024526,
     "end_time": "2024-08-04T01:41:28.715669",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.691143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('counts', dcounts, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3179249",
   "metadata": {
    "papermill": {
     "duration": 0.012579,
     "end_time": "2024-08-04T01:41:28.741279",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.728700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Derivative norm_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54c56966",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:41:28.768539Z",
     "iopub.status.busy": "2024-08-04T01:41:28.768102Z",
     "iopub.status.idle": "2024-08-04T01:41:28.773902Z",
     "shell.execute_reply": "2024-08-04T01:41:28.772577Z"
    },
    "papermill": {
     "duration": 0.022638,
     "end_time": "2024-08-04T01:41:28.776553",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.753915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dnorm_logits=(norm_logits.exp())\n",
    "dnorm_logits=counts*dcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8070bbf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:41:28.803841Z",
     "iopub.status.busy": "2024-08-04T01:41:28.803330Z",
     "iopub.status.idle": "2024-08-04T01:41:28.811664Z",
     "shell.execute_reply": "2024-08-04T01:41:28.809967Z"
    },
    "papermill": {
     "duration": 0.025027,
     "end_time": "2024-08-04T01:41:28.814537",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.789510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "cmp('norm_logits', dnorm_logits, norm_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b856c2a",
   "metadata": {
    "papermill": {
     "duration": 0.01485,
     "end_time": "2024-08-04T01:41:28.842313",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.827463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Derivative logits and logits_maxes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eefa65",
   "metadata": {
    "papermill": {
     "duration": 0.013821,
     "end_time": "2024-08-04T01:41:28.871694",
     "exception": false,
     "start_time": "2024-08-04T01:41:28.857873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Acknowledgement\n",
    "\n",
    "* https://en.wikipedia.org/wiki/Chain_rule\n",
    "* https://en.wikipedia.org/wiki/Notation_for_differentiation#Lagrange's_notation"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 187064505,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.605717,
   "end_time": "2024-08-04T01:41:29.810362",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-04T01:41:19.204645",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
