{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc7a60a7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.002196,
     "end_time": "2024-01-30T05:10:32.694336",
     "exception": false,
     "start_time": "2024-01-30T05:10:32.692140",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "> Note: If you overuse pinned memory, it can cause serious problems when running low on RAM, and you should be aware that pinning is often en expensive operation.\n",
    "\n",
    "Host to GPU copies are much fater when they originate from pinned(page-locked) memory. CPU tensors and storages expose a `pin_memory()` method, that returns a copy of the object, with data put in a pinned region.\n",
    "\n",
    "Once we pin a tensor or storage, we can use asynchronous GPU copies. Just pass an additional `non_blocking=True` argument to a `to()` or a `cuda()` call. This can be used to overlap data transfers with computation.\n",
    "\n",
    "For data loading, passing `pin_memory=True` to a DataLoader will automatically put the fecthed data Tensors in pinned memory, and thus enables faster data transfer to CUDA-enabled GPUs.\n",
    "\n",
    "The default memory pinning logic only recognizes Tensors and maps and iterables containing Tensors. By default, if the pinning logic sees a batch that is a custom type(which will occur if you gave a collate_fn that returns a custom batch type), or if each element of your batch is a custom type, the pinning logic will not recognize them, and it will return that batch(or those elements) without pinning the memory. To enable memeory pinning for custom batch or data type(s), define a `pin_memory()` mrthod on your custom type(s). \n",
    "\n",
    "\n",
    "See the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d16ed1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T05:10:32.699486Z",
     "iopub.status.busy": "2024-01-30T05:10:32.698777Z",
     "iopub.status.idle": "2024-01-30T05:10:36.402592Z",
     "shell.execute_reply": "2024-01-30T05:10:36.401483Z"
    },
    "papermill": {
     "duration": 3.709096,
     "end_time": "2024-01-30T05:10:36.405084",
     "exception": false,
     "start_time": "2024-01-30T05:10:32.695988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class SimpleCustomBatch:\n",
    "    def __init__(self, data):\n",
    "        transposed_data=list(zip(*data))\n",
    "        self.inp=torch.stack(transposed_data[0],0)\n",
    "        self.tgt=torch.stack(transposed_data[1],0)\n",
    "        \n",
    "    def pin_memory(self):\n",
    "        self.inp=self.inp.pin_memory()\n",
    "        self.tgt=self.tgt.pin_memory()\n",
    "        return self\n",
    "    \n",
    "def collate_wrapper(batch):\n",
    "    return SimpleCustomBatch(batch)\n",
    "\n",
    "inps=torch.arange(10*5, dtype=torch.float32).view(10,5)\n",
    "tgts=torch.arange(10*5, dtype=torch.float32).view(10,5)\n",
    "dataset=TensorDataset(inps, tgts)\n",
    "\n",
    "loader=DataLoader(dataset, batch_size=2, collate_fn=collate_wrapper, pin_memory=True)\n",
    "\n",
    "for batch_ndx, sample in enumerate(loader):\n",
    "    print(sample.inp.is_pinned())\n",
    "    print(sample.tgt.is_pinned())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.550466,
   "end_time": "2024-01-30T05:10:37.427907",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-30T05:10:29.877441",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
