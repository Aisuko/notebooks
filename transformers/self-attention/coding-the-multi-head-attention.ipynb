{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5123e1b9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.004354,
     "end_time": "2024-01-25T06:37:24.463029",
     "exception": false,
     "start_time": "2024-01-25T06:37:24.458675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "**Note: The images are from the Credit section**\n",
    "\n",
    "In the [Coding the Self-Attention Mechanism](https://www.kaggle.com/code/aisuko/coding-the-self-attention-mechanism) we implement self-attention machanim. And from [Encoder in Transformers Architecture](https://www.kaggle.com/code/aisuko/encoder-in-transformers-architecture), we can see that transformers use a module called **multi-head-attention**. In this notebook, we will talk about How does that relate to the self attention again by implementing it in code.\n",
    "\n",
    "In the scaled dot-product attention(self-attention), the input sequence was transformed using three matrices representingt the query, key and values. These three matrices can be considered as a single attention head in the conext of multi-head attention. The figure below summarizes this single attention head we covered in the previously notebook above.\n",
    "\n",
    "<div style=\"text-align: center\"><img src=\"https://files.mastodon.social/media_attachments/files/111/814/921/458/820/088/original/1fb77b4eb89e6718.png\" width=\"80%\" heigh=\"80%\" alt=\"Scaled-dot-product attention\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021c8cc3",
   "metadata": {
    "papermill": {
     "duration": 0.003487,
     "end_time": "2024-01-25T06:37:24.470509",
     "exception": false,
     "start_time": "2024-01-25T06:37:24.467022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Multi-Head Attention\n",
    "\n",
    "As its name implies, multi-head attention involves multiple such heads, each consisting of query, key, and value matrices. This concept is similar to the use of multiple kernels in convolutional neural networks.\n",
    "\n",
    "<div style=\"text-align: center\"><img src=\"https://files.mastodon.social/media_attachments/files/111/814/925/242/665/171/original/821c33b401832d5d.png\" width=\"80%\" heigh=\"80%\" alt=\"multi-head attention\"></div>\n",
    "\n",
    "Here the code from the previouly notebook below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29b4aa65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T06:37:24.480821Z",
     "iopub.status.busy": "2024-01-25T06:37:24.480063Z",
     "iopub.status.idle": "2024-01-25T06:37:28.257498Z",
     "shell.execute_reply": "2024-01-25T06:37:28.256530Z"
    },
    "papermill": {
     "duration": 3.785071,
     "end_time": "2024-01-25T06:37:28.259347",
     "exception": false,
     "start_time": "2024-01-25T06:37:24.474276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.1845, -3.4618, -2.5052, -3.4871, -2.2224, -3.4605, -3.9543, -4.4065,\n",
       "        -4.7564, -4.1877, -2.8166, -4.1730, -3.3587, -3.0407, -4.5513, -4.7335,\n",
       "        -1.3817, -2.6396, -2.3683, -2.7940, -3.4905, -4.4358, -5.2125, -4.3044,\n",
       "        -3.0761, -3.4201, -4.7494, -3.3475], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "inputs=\"According to the news, it it hard to say Melbourne is safe now\"\n",
    "d_q, d_k, d_v=24,24,28\n",
    "\n",
    "input_ids={s:i for i,s in enumerate(sorted(inputs.replace(',','').split()))}\n",
    "input_tokens=torch.tensor([input_ids[s] for s in inputs.replace(',','').split()])\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embed=torch.nn.Embedding(13,16)\n",
    "embedded_sentence=embed(input_tokens).detach()\n",
    "d=embedded_sentence.shape[1]\n",
    "\n",
    "# defining the Weight Matrices\n",
    "W_query=torch.nn.Parameter(torch.rand(d_q, d))\n",
    "W_key=torch.nn.Parameter(torch.rand(d_k, d))\n",
    "W_value=torch.nn.Parameter(torch.rand(d_v, d))\n",
    "\n",
    "# only computing the attention-vector for the second input element\n",
    "# In this example, the second input element acts as the query\n",
    "x_2 = embedded_sentence[1]\n",
    "query_2 = W_query.matmul(x_2)\n",
    "key_2 = W_key.matmul(x_2)\n",
    "value_2 = W_value.matmul(x_2)\n",
    "\n",
    "# computing the key and value for all inputs\n",
    "keys = W_key.matmul(embedded_sentence.T).T\n",
    "values = W_value.matmul(embedded_sentence.T).T\n",
    "\n",
    "# computing the unnormalized attention wieghts w\n",
    "\n",
    "# in this example, we compute the query and the 5th input element(the index position is 4) as follows\n",
    "w_2_4=query_2.dot(keys[4])\n",
    "\n",
    "# compute the unnormalized attention weight for all the input tokens\n",
    "w_2=query_2.matmul(keys.T)\n",
    "\n",
    "attention_weights_2=F.softmax(w_2/d_k**0.5, dim=0)\n",
    "\n",
    "# The final context vector(an attention-weighted version of the original query input x_2)\n",
    "context_vector_2=attention_weights_2.matmul(values)\n",
    "context_vector_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c604ec3a",
   "metadata": {
    "papermill": {
     "duration": 0.003661,
     "end_time": "2024-01-25T06:37:28.267058",
     "exception": false,
     "start_time": "2024-01-25T06:37:28.263397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "And To illustrate this in code, suppose we have 3 attention heads, so we now extend the $d^{'}*d$ dimensional weight matrices so $3*d^{'}*d$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5adbe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T06:37:28.277372Z",
     "iopub.status.busy": "2024-01-25T06:37:28.276702Z",
     "iopub.status.idle": "2024-01-25T06:37:28.281656Z",
     "shell.execute_reply": "2024-01-25T06:37:28.280976Z"
    },
    "papermill": {
     "duration": 0.012158,
     "end_time": "2024-01-25T06:37:28.283498",
     "exception": false,
     "start_time": "2024-01-25T06:37:28.271340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "h=3\n",
    "multihead_W_query=torch.nn.Parameter(torch.rand(h, d_q, d))\n",
    "multihead_W_key=torch.nn.Parameter(torch.rand(h, d_k, d))\n",
    "multihead_W_value=torch.nn.Parameter(torch.rand(h, d_v, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5066b5",
   "metadata": {
    "papermill": {
     "duration": 0.003635,
     "end_time": "2024-01-25T06:37:28.291270",
     "exception": false,
     "start_time": "2024-01-25T06:37:28.287635",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Consequently, each query element is now $3*d_{q}$ dimensional, where $d_{q}=24$ (here, let's keep the focus on the 3rd element corresponding to index position 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c964848b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T06:37:28.301196Z",
     "iopub.status.busy": "2024-01-25T06:37:28.300657Z",
     "iopub.status.idle": "2024-01-25T06:37:28.311194Z",
     "shell.execute_reply": "2024-01-25T06:37:28.309712Z"
    },
    "papermill": {
     "duration": 0.018777,
     "end_time": "2024-01-25T06:37:28.313928",
     "exception": false,
     "start_time": "2024-01-25T06:37:28.295151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.8033, -1.8514, -3.0982, -1.6475, -1.7888, -3.1605, -2.3619, -0.5279,\n",
       "         -3.6521, -3.4834, -3.6471, -3.2028, -0.6245, -1.6851, -1.0399, -3.3090,\n",
       "         -2.1283, -5.2142, -1.6018, -0.4544, -3.1030, -0.0287, -4.3965, -2.2998],\n",
       "        [-4.1517, -4.6697, -1.6747, -1.1715, -3.5441, -0.4090, -1.6129, -4.4261,\n",
       "         -2.1847, -2.9327, -2.6157, -3.1685, -1.9501, -2.9855, -3.1613, -1.2670,\n",
       "         -0.5295, -1.1895, -0.4661, -2.3916, -0.9902,  0.3367, -0.4596, -2.9863],\n",
       "        [-1.6977, -1.6078, -3.5137, -4.9699, -4.1886, -0.7016, -3.3832, -3.2597,\n",
       "         -2.1036, -4.3422, -1.9974, -1.7627, -2.9813, -1.5485,  0.0060, -1.7442,\n",
       "         -5.0369, -4.2576, -1.7272, -0.5214, -2.1458, -2.9699, -1.4175, -0.9593]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_query_2=multihead_W_query.matmul(x_2)\n",
    "multihead_query_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6f41b90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T06:37:28.324901Z",
     "iopub.status.busy": "2024-01-25T06:37:28.324435Z",
     "iopub.status.idle": "2024-01-25T06:37:28.331791Z",
     "shell.execute_reply": "2024-01-25T06:37:28.330231Z"
    },
    "papermill": {
     "duration": 0.015126,
     "end_time": "2024-01-25T06:37:28.333730",
     "exception": false,
     "start_time": "2024-01-25T06:37:28.318604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 24])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_query_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77b8449",
   "metadata": {
    "papermill": {
     "duration": 0.004133,
     "end_time": "2024-01-25T06:37:28.342978",
     "exception": false,
     "start_time": "2024-01-25T06:37:28.338845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's do the computing for keys and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3c883a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T06:37:28.353724Z",
     "iopub.status.busy": "2024-01-25T06:37:28.352531Z",
     "iopub.status.idle": "2024-01-25T06:37:28.357331Z",
     "shell.execute_reply": "2024-01-25T06:37:28.356555Z"
    },
    "papermill": {
     "duration": 0.012559,
     "end_time": "2024-01-25T06:37:28.359762",
     "exception": false,
     "start_time": "2024-01-25T06:37:28.347203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "multihead_key_2=multihead_W_key.matmul(x_2)\n",
    "multihead_value_2=multihead_W_value.matmul(x_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d969fe9",
   "metadata": {
    "papermill": {
     "duration": 0.00417,
     "end_time": "2024-01-25T06:37:28.368498",
     "exception": false,
     "start_time": "2024-01-25T06:37:28.364328",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, these ket and value elements are specific to the query element. But. similar to earlier, we will also need the values and keys for the other sequence elements in order to compute the attention scores for the query. We can do this by expanding the input sequence embeddings to size 3(the number of attention heads):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8be17615",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T06:37:28.379898Z",
     "iopub.status.busy": "2024-01-25T06:37:28.378433Z",
     "iopub.status.idle": "2024-01-25T06:37:28.384954Z",
     "shell.execute_reply": "2024-01-25T06:37:28.383921Z"
    },
    "papermill": {
     "duration": 0.014349,
     "end_time": "2024-01-25T06:37:28.387088",
     "exception": false,
     "start_time": "2024-01-25T06:37:28.372739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "072a1b40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T06:37:28.398514Z",
     "iopub.status.busy": "2024-01-25T06:37:28.397999Z",
     "iopub.status.idle": "2024-01-25T06:37:28.405284Z",
     "shell.execute_reply": "2024-01-25T06:37:28.403972Z"
    },
    "papermill": {
     "duration": 0.015916,
     "end_time": "2024-01-25T06:37:28.407617",
     "exception": false,
     "start_time": "2024-01-25T06:37:28.391701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stacked_inputs=embedded_sentence.T.repeat(3,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fddd1bfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T06:37:28.419270Z",
     "iopub.status.busy": "2024-01-25T06:37:28.418654Z",
     "iopub.status.idle": "2024-01-25T06:37:28.423543Z",
     "shell.execute_reply": "2024-01-25T06:37:28.422889Z"
    },
    "papermill": {
     "duration": 0.012989,
     "end_time": "2024-01-25T06:37:28.425372",
     "exception": false,
     "start_time": "2024-01-25T06:37:28.412383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 16, 13])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d692184",
   "metadata": {
    "papermill": {
     "duration": 0.004167,
     "end_time": "2024-01-25T06:37:28.434145",
     "exception": false,
     "start_time": "2024-01-25T06:37:28.429978",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we cam compute all the keys and values using `torch.bmm()` (batch matrix multiplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "288a684c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T06:37:28.445113Z",
     "iopub.status.busy": "2024-01-25T06:37:28.444527Z",
     "iopub.status.idle": "2024-01-25T06:37:28.456060Z",
     "shell.execute_reply": "2024-01-25T06:37:28.454335Z"
    },
    "papermill": {
     "duration": 0.019554,
     "end_time": "2024-01-25T06:37:28.458179",
     "exception": false,
     "start_time": "2024-01-25T06:37:28.438625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 24, 13])\n",
      "torch.Size([3, 28, 13])\n"
     ]
    }
   ],
   "source": [
    "multihead_keys=torch.bmm(multihead_W_key, stacked_inputs)\n",
    "multihead_values=torch.bmm(multihead_W_value, stacked_inputs)\n",
    "print(multihead_keys.shape)\n",
    "print(multihead_values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657fede0",
   "metadata": {
    "papermill": {
     "duration": 0.004279,
     "end_time": "2024-01-25T06:37:28.467125",
     "exception": false,
     "start_time": "2024-01-25T06:37:28.462846",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We now have tensors that represent the three attention heads in their first dimension. The third and second dimensions refer to the number of words and the embedding size, respectively. To make the values and keys more intuitive to interpret, we will swap the second and third dimensions, resulting in tensors with the same dimensional structure as the original input sequence, **embedded_sentence**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2be7dac2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T06:37:28.477690Z",
     "iopub.status.busy": "2024-01-25T06:37:28.477286Z",
     "iopub.status.idle": "2024-01-25T06:37:28.484262Z",
     "shell.execute_reply": "2024-01-25T06:37:28.482651Z"
    },
    "papermill": {
     "duration": 0.014701,
     "end_time": "2024-01-25T06:37:28.486258",
     "exception": false,
     "start_time": "2024-01-25T06:37:28.471557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 13, 24])\n",
      "torch.Size([3, 13, 28])\n"
     ]
    }
   ],
   "source": [
    "multihead_keys=multihead_keys.permute(0,2,1)\n",
    "multihead_values=multihead_values.permute(0,2,1)\n",
    "print(multihead_keys.shape)\n",
    "print(multihead_values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a951d00f",
   "metadata": {
    "papermill": {
     "duration": 0.004576,
     "end_time": "2024-01-25T06:37:28.495630",
     "exception": false,
     "start_time": "2024-01-25T06:37:28.491054",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We follow the same steps as previously to compute the unscaled attention weights $w$ and attention weights $\\alpha$, followed the scaled-softmax computation to obtain an $h*d_{v}$(here $3*d_{v}$) dimensional context vector $z$ for the input element $x^{(2)}$."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.583398,
   "end_time": "2024-01-25T06:37:29.323168",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-25T06:37:21.739770",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
