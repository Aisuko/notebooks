{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1435b5c3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.003952,
     "end_time": "2024-01-25T00:49:55.157290",
     "exception": false,
     "start_time": "2024-01-25T00:49:55.153338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "Please check the [Encoder In Transformers architecture](https://www.kaggle.com/code/aisuko/encoder-in-transformers-architecture) and [Decoder In Transformers architecture](https://www.kaggle.com/code/aisuko/decoder-in-transformers-architecture) to familar **self-attention** in transformers architecture.\n",
    "\n",
    "In this notebook, we focus on the scaled-dot product attention mechanism(referred to as self-attention), which remains the most populat and most widely used attention mechanism in practice. And there are existed other types of attention machanisms, like [2020 Efficient Transformers: A Survey](https://arxiv.org/abs/2009.06732) and the [2023 A Survey on Effcient Training of Transformers](https://arxiv.org/abs/2302.01107) review and the [FlashAttention](https://arxiv.org/abs/2205.14135) paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1c04d8",
   "metadata": {
    "papermill": {
     "duration": 0.003397,
     "end_time": "2024-01-25T00:49:55.164448",
     "exception": false,
     "start_time": "2024-01-25T00:49:55.161051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Embedding an Input Sentence\n",
    "\n",
    "Through the \"Encoder in Transformers architecture\", we know the first steps is tokenization and embedding the tokenzes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f60f977",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T00:49:55.173836Z",
     "iopub.status.busy": "2024-01-25T00:49:55.173039Z",
     "iopub.status.idle": "2024-01-25T00:49:55.189939Z",
     "shell.execute_reply": "2024-01-25T00:49:55.188921Z"
    },
    "papermill": {
     "duration": 0.024784,
     "end_time": "2024-01-25T00:49:55.192725",
     "exception": false,
     "start_time": "2024-01-25T00:49:55.167941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'According': 0,\n",
       " 'Melbourne': 1,\n",
       " 'hard': 2,\n",
       " 'is': 3,\n",
       " 'it': 5,\n",
       " 'news': 6,\n",
       " 'now': 7,\n",
       " 'safe': 8,\n",
       " 'say': 9,\n",
       " 'the': 10,\n",
       " 'to': 12}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs=\"According to the news, it it hard to say Melbourne is safe now\"\n",
    "\n",
    "input_ids={s:i for i,s in enumerate(sorted(inputs.replace(',','').split()))}\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9876094f",
   "metadata": {
    "papermill": {
     "duration": 0.003523,
     "end_time": "2024-01-25T00:49:55.199887",
     "exception": false,
     "start_time": "2024-01-25T00:49:55.196364",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's convert them to the tokens(assign an integer index to each word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d06e61d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T00:49:55.209404Z",
     "iopub.status.busy": "2024-01-25T00:49:55.208422Z",
     "iopub.status.idle": "2024-01-25T00:49:59.616984Z",
     "shell.execute_reply": "2024-01-25T00:49:59.615353Z"
    },
    "papermill": {
     "duration": 4.41705,
     "end_time": "2024-01-25T00:49:59.620512",
     "exception": false,
     "start_time": "2024-01-25T00:49:55.203462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 12, 10,  6,  5,  5,  2, 12,  9,  1,  3,  8,  7])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "input_tokens=torch.tensor([input_ids[s] for s in inputs.replace(',','').split()])\n",
    "input_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87de6de",
   "metadata": {
    "papermill": {
     "duration": 0.003874,
     "end_time": "2024-01-25T00:49:59.628890",
     "exception": false,
     "start_time": "2024-01-25T00:49:59.625016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, using the integer-vector reoresentation of the input sentence, we can use an embedding layer to **encode the inputs** into a real vector embedding. Here, we will use a 16-dimensional embedding such that each input word is represented by a 16-dimensional vector. Since the sentence consists of 13 words, this will result in a 13x16-dimentional embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43f38b18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T00:49:59.640003Z",
     "iopub.status.busy": "2024-01-25T00:49:59.639258Z",
     "iopub.status.idle": "2024-01-25T00:49:59.759172Z",
     "shell.execute_reply": "2024-01-25T00:49:59.757630Z"
    },
    "papermill": {
     "duration": 0.12943,
     "end_time": "2024-01-25T00:49:59.762576",
     "exception": false,
     "start_time": "2024-01-25T00:49:59.633146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.3737e-01, -1.7778e-01, -3.0353e-01, -5.8801e-01,  3.4861e-01,\n",
       "          6.6034e-01, -2.1964e-01, -3.7917e-01,  7.6711e-01, -1.1925e+00,\n",
       "          6.9835e-01, -1.4097e+00,  1.7938e-01,  1.8951e+00,  4.9545e-01,\n",
       "          2.6920e-01],\n",
       "        [-9.7969e-01, -2.1126e+00, -2.7214e-01, -3.5100e-01,  1.1152e+00,\n",
       "         -6.1722e-01, -2.2708e+00, -1.3819e+00,  1.1721e+00, -4.3716e-01,\n",
       "         -4.0527e-01,  7.0864e-01,  9.5331e-01, -1.3035e-02, -1.3009e-01,\n",
       "         -8.7660e-02],\n",
       "        [ 6.8508e-01,  2.0024e+00, -5.4688e-01,  1.6014e+00, -2.2577e+00,\n",
       "         -1.8009e+00,  7.0147e-01,  5.7028e-01, -1.1766e+00, -2.0524e+00,\n",
       "          1.1318e-01,  1.4353e+00,  8.8307e-02, -1.2037e+00,  1.0964e+00,\n",
       "          2.4210e+00],\n",
       "        [-2.2150e+00, -1.3193e+00, -2.0915e+00,  9.6285e-01, -3.1861e-02,\n",
       "         -4.7896e-01,  7.6681e-01,  2.7468e-02,  1.9929e+00,  1.3708e+00,\n",
       "         -5.0087e-01, -2.7928e-01, -2.0628e+00,  6.3745e-03, -9.8955e-01,\n",
       "          7.0161e-01],\n",
       "        [ 2.5529e-01, -5.4963e-01,  1.0042e+00,  8.2723e-01, -3.9481e-01,\n",
       "          4.8923e-01, -2.1681e-01, -1.7472e+00, -1.6025e+00, -1.0764e+00,\n",
       "          9.0315e-01, -7.2184e-01, -5.9508e-01, -7.1122e-01,  6.2296e-01,\n",
       "         -1.3729e+00],\n",
       "        [ 2.5529e-01, -5.4963e-01,  1.0042e+00,  8.2723e-01, -3.9481e-01,\n",
       "          4.8923e-01, -2.1681e-01, -1.7472e+00, -1.6025e+00, -1.0764e+00,\n",
       "          9.0315e-01, -7.2184e-01, -5.9508e-01, -7.1122e-01,  6.2296e-01,\n",
       "         -1.3729e+00],\n",
       "        [-1.3250e+00,  1.7843e-01, -2.1338e+00,  1.0524e+00, -3.8848e-01,\n",
       "         -9.3435e-01, -4.9914e-01, -1.0867e+00,  8.8054e-01,  1.5542e+00,\n",
       "          6.2662e-01, -1.7549e-01,  9.8284e-02, -9.3507e-02,  2.6621e-01,\n",
       "         -5.8504e-01],\n",
       "        [-9.7969e-01, -2.1126e+00, -2.7214e-01, -3.5100e-01,  1.1152e+00,\n",
       "         -6.1722e-01, -2.2708e+00, -1.3819e+00,  1.1721e+00, -4.3716e-01,\n",
       "         -4.0527e-01,  7.0864e-01,  9.5331e-01, -1.3035e-02, -1.3009e-01,\n",
       "         -8.7660e-02],\n",
       "        [-1.2743e+00,  4.5128e-01, -2.2801e-01,  9.2238e-01,  2.0561e-01,\n",
       "         -4.9696e-01,  5.8206e-01,  2.0532e-01, -3.0177e-01, -6.7030e-01,\n",
       "         -6.1710e-01, -8.3339e-01,  4.8387e-01, -1.3493e-01,  2.1187e-01,\n",
       "         -8.7140e-01],\n",
       "        [-7.7020e-02, -1.0205e+00, -1.6896e-01,  9.1776e-01,  1.5810e+00,\n",
       "          1.3010e+00,  1.2753e+00, -2.0095e-01,  4.9647e-01, -1.5723e+00,\n",
       "          9.6657e-01, -1.1481e+00, -1.1589e+00,  3.2547e-01, -6.3151e-01,\n",
       "         -2.8400e+00],\n",
       "        [ 8.7684e-01,  1.6221e+00, -1.4779e+00,  1.1331e+00, -1.2203e+00,\n",
       "          1.3139e+00,  1.0533e+00,  1.3881e-01,  2.2473e+00, -8.0364e-01,\n",
       "         -2.8084e-01,  7.6968e-01, -6.5956e-01, -7.9793e-01,  1.8383e-01,\n",
       "          2.2935e-01],\n",
       "        [-2.5822e-01, -2.0407e+00, -8.0156e-01, -8.1830e-01, -1.1820e+00,\n",
       "         -2.8774e-01, -6.0430e-01,  6.0024e-01, -1.4053e+00, -5.9217e-01,\n",
       "         -2.5479e-01,  1.1517e+00, -1.7858e-02,  4.2640e-01, -7.6574e-01,\n",
       "         -5.4514e-02],\n",
       "        [-9.4053e-01, -4.6806e-01,  1.0322e+00, -2.8300e-01,  4.9275e-01,\n",
       "         -1.4078e-02, -2.7466e-01, -7.6409e-01,  1.3966e+00, -9.9491e-01,\n",
       "         -1.5822e-03,  1.2471e+00, -7.7105e-02,  1.2774e+00, -1.4596e+00,\n",
       "         -2.1595e+00]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the same seed to keep the same result\n",
    "torch.manual_seed(123)\n",
    "embed=torch.nn.Embedding(13,16)\n",
    "embedded_sentence=embed(input_tokens).detach()\n",
    "embedded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "569782ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T00:49:59.774060Z",
     "iopub.status.busy": "2024-01-25T00:49:59.773492Z",
     "iopub.status.idle": "2024-01-25T00:49:59.783806Z",
     "shell.execute_reply": "2024-01-25T00:49:59.782108Z"
    },
    "papermill": {
     "duration": 0.019702,
     "end_time": "2024-01-25T00:49:59.786875",
     "exception": false,
     "start_time": "2024-01-25T00:49:59.767173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 16])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentence.shape"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.550919,
   "end_time": "2024-01-25T00:50:02.115308",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-25T00:49:51.564389",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
