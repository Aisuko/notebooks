{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32d2cd9b",
   "metadata": {
    "papermill": {
     "duration": 0.005193,
     "end_time": "2024-09-25T08:43:46.888435",
     "exception": false,
     "start_time": "2024-09-25T08:43:46.883242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This note implement the concept in https://towardsdatascience.com/gguf-quantization-with-imatrix-and-k-quantization-to-run-llms-on-your-cpu-02356b531926\n",
    "\n",
    "This note will quantize Meta-Llama with Imatrix and K-quantization will llama.cpp\n",
    "\n",
    "# Install llama.cpp\n",
    "\n",
    "we use llama-cpp-python binding instead of the directly using llama-cpp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a28f310",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T08:43:46.899184Z",
     "iopub.status.busy": "2024-09-25T08:43:46.898808Z",
     "iopub.status.idle": "2024-09-25T09:05:46.045167Z",
     "shell.execute_reply": "2024-09-25T09:05:46.043871Z"
    },
    "papermill": {
     "duration": 1319.154982,
     "end_time": "2024-09-25T09:05:46.048030",
     "exception": false,
     "start_time": "2024-09-25T08:43:46.893048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'llama.cpp'...\r\n",
      "remote: Enumerating objects: 34659, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (6377/6377), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (258/258), done.\u001b[K\r\n",
      "remote: Total 34659 (delta 6243), reused 6141 (delta 6119), pack-reused 28282 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (34659/34659), 56.26 MiB | 27.03 MiB/s, done.\r\n",
      "Resolving deltas: 100% (25162/25162), done.\r\n",
      "/kaggle/working/llama.cpp\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ggerganov/llama.cpp\n",
    "%cd llama.cpp\n",
    "# !export GGML_CUDA=1 \n",
    "!cp -r /usr/local/cuda-12.3/targets /usr/local/nvidia/ \n",
    "!make GGML_CUDA=1 CUDA_PATH=/usr/local/nvidia  > make.log 2>&1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3373d34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T09:05:46.072597Z",
     "iopub.status.busy": "2024-09-25T09:05:46.072264Z",
     "iopub.status.idle": "2024-09-25T09:05:47.052478Z",
     "shell.execute_reply": "2024-09-25T09:05:47.051603Z"
    },
    "papermill": {
     "duration": 0.994692,
     "end_time": "2024-09-25T09:05:47.054602",
     "exception": false,
     "start_time": "2024-09-25T09:05:46.059910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/nvidia/include -I/usr/local/nvidia/targets/x86_64-linux/include  -c examples/cvector-generator/cvector-generator.cpp -o examples/cvector-generator/cvector-generator.o\r\n",
      "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/nvidia/include -I/usr/local/nvidia/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/cvector-generator/cvector-generator.o -o llama-cvector-generator -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/nvidia/lib64 -L/usr/lib64 -L/usr/local/nvidia/targets/x86_64-linux/lib -L/usr/local/nvidia/lib64/stubs -L/usr/lib/wsl/lib \r\n",
      "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/nvidia/include -I/usr/local/nvidia/targets/x86_64-linux/include  -c examples/gen-docs/gen-docs.cpp -o examples/gen-docs/gen-docs.o\r\n",
      "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/nvidia/include -I/usr/local/nvidia/targets/x86_64-linux/include  ggml/src/llamafile/sgemm.o ggml/src/ggml-cuda.o ggml/src/ggml-cuda/acc.o ggml/src/ggml-cuda/arange.o ggml/src/ggml-cuda/argsort.o ggml/src/ggml-cuda/binbcast.o ggml/src/ggml-cuda/clamp.o ggml/src/ggml-cuda/concat.o ggml/src/ggml-cuda/conv-transpose-1d.o ggml/src/ggml-cuda/convert.o ggml/src/ggml-cuda/cpy.o ggml/src/ggml-cuda/cross-entropy-loss.o ggml/src/ggml-cuda/diagmask.o ggml/src/ggml-cuda/dmmv.o ggml/src/ggml-cuda/fattn-tile-f16.o ggml/src/ggml-cuda/fattn-tile-f32.o ggml/src/ggml-cuda/fattn.o ggml/src/ggml-cuda/getrows.o ggml/src/ggml-cuda/im2col.o ggml/src/ggml-cuda/mmq.o ggml/src/ggml-cuda/mmvq.o ggml/src/ggml-cuda/norm.o ggml/src/ggml-cuda/opt-step-adamw.o ggml/src/ggml-cuda/out-prod.o ggml/src/ggml-cuda/pad.o ggml/src/ggml-cuda/pool2d.o ggml/src/ggml-cuda/quantize.o ggml/src/ggml-cuda/rope.o ggml/src/ggml-cuda/rwkv-wkv.o ggml/src/ggml-cuda/scale.o ggml/src/ggml-cuda/softmax.o ggml/src/ggml-cuda/sum.o ggml/src/ggml-cuda/sumrows.o ggml/src/ggml-cuda/tsembd.o ggml/src/ggml-cuda/unary.o ggml/src/ggml-cuda/upscale.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.o ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.o ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.o ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.o ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.o ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.o ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o src/llama.o src/llama-vocab.o src/llama-grammar.o src/llama-sampling.o src/unicode.o src/unicode-data.o common/common.o common/arg.o common/log.o common/console.o common/ngram-cache.o common/sampling.o common/train.o common/build-info.o common/json-schema-to-grammar.o examples/gen-docs/gen-docs.o -o llama-gen-docs -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/nvidia/lib64 -L/usr/lib64 -L/usr/local/nvidia/targets/x86_64-linux/lib -L/usr/local/nvidia/lib64/stubs -L/usr/lib/wsl/lib \r\n",
      "cc -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/nvidia/include -I/usr/local/nvidia/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion  -c tests/test-c.c -o tests/test-c.o\r\n",
      "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/nvidia/include -I/usr/local/nvidia/targets/x86_64-linux/include  -c examples/deprecation-warning/deprecation-warning.cpp -o examples/deprecation-warning/deprecation-warning.o\r\n",
      "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/nvidia/include -I/usr/local/nvidia/targets/x86_64-linux/include  examples/deprecation-warning/deprecation-warning.o -o main -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/nvidia/lib64 -L/usr/lib64 -L/usr/local/nvidia/targets/x86_64-linux/lib -L/usr/local/nvidia/lib64/stubs -L/usr/lib/wsl/lib \r\n",
      "NOTICE: The 'main' binary is deprecated. Please use 'llama-cli' instead.\r\n",
      "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_CUDA -DGGML_CUDA_USE_GRAPHS -I/usr/local/nvidia/include -I/usr/local/nvidia/targets/x86_64-linux/include  examples/deprecation-warning/deprecation-warning.o -o server -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/nvidia/lib64 -L/usr/lib64 -L/usr/local/nvidia/targets/x86_64-linux/lib -L/usr/local/nvidia/lib64/stubs -L/usr/lib/wsl/lib \r\n",
      "NOTICE: The 'server' binary is deprecated. Please use 'llama-server' instead.\r\n"
     ]
    }
   ],
   "source": [
    "!tail make.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9b49528",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T09:05:47.078772Z",
     "iopub.status.busy": "2024-09-25T09:05:47.078464Z",
     "iopub.status.idle": "2024-09-25T09:07:29.791533Z",
     "shell.execute_reply": "2024-09-25T09:07:29.790419Z"
    },
    "papermill": {
     "duration": 102.727755,
     "end_time": "2024-09-25T09:07:29.793821",
     "exception": false,
     "start_time": "2024-09-25T09:05:47.066066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/llama.cpp\r\n",
      "pointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "rapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.8.1 which is incompatible.\r\n",
      "rmm 24.8.2 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\r\n",
      "s3fs 2024.6.1 requires fsspec==2024.6.1.*, but you have fsspec 2024.9.0 which is incompatible.\r\n",
      "spaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.5 which is incompatible.\r\n",
      "tensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.5 which is incompatible.\r\n",
      "ydata-profiling 4.9.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 certifi-2024.8.30 charset-normalizer-3.3.2 filelock-3.16.1 fsspec-2024.6.1 gguf-0.10.0 huggingface-hub-0.25.1 idna-3.10 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 numpy-1.26.4 packaging-24.1 protobuf-4.25.3 pyyaml-6.0.2 regex-2024.9.11 requests-2.32.3 safetensors-0.4.5 sentencepiece-0.2.0 sympy-1.13.3 tokenizers-0.19.1 torch-2.2.2+cpu tqdm-4.66.5 transformers-4.44.2 typing-extensions-4.12.2 urllib3-2.2.1\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!pip install --force-reinstall -r requirements.txt > pip_install.log 2>&1\n",
    "!tail pip_install.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f230b9c",
   "metadata": {
    "papermill": {
     "duration": 0.011073,
     "end_time": "2024-09-25T09:07:29.816468",
     "exception": false,
     "start_time": "2024-09-25T09:07:29.805395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Download model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbca436e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T09:07:29.841205Z",
     "iopub.status.busy": "2024-09-25T09:07:29.840412Z",
     "iopub.status.idle": "2024-09-25T09:07:31.809807Z",
     "shell.execute_reply": "2024-09-25T09:07:31.808754Z"
    },
    "papermill": {
     "duration": 1.984457,
     "end_time": "2024-09-25T09:07:31.812279",
     "exception": false,
     "start_time": "2024-09-25T09:07:29.827822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/llama.cpp\r\n",
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "%cd ..\n",
    "!mkdir \"./quantized_model_gemma2-2b/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "442f1df6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T09:07:31.837742Z",
     "iopub.status.busy": "2024-09-25T09:07:31.836977Z",
     "iopub.status.idle": "2024-09-25T09:07:53.253696Z",
     "shell.execute_reply": "2024-09-25T09:07:53.252752Z"
    },
    "papermill": {
     "duration": 21.432125,
     "end_time": "2024-09-25T09:07:53.256268",
     "exception": false,
     "start_time": "2024-09-25T09:07:31.824143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1204: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
      "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82457a046f9342c8ae9332189dc86bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0760031692e4f69a21c1cdaff3ee552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/241M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8c588094764bafb18fdfe7d7b27d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/24.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5630b2e2594646929395041f38b9c4fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "795c8dc9ccdf4730b476dfea07b228b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.57k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1877866267c74655b389f933ef09e407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7543143f55f4f7682d9c7e062a43b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/838 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf5467e2f3c4afb9c9976cc341c4ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/29.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5635d8fe36c4962a64664f0ae5df17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78ec818538f4436a448f52b3a7df197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28be1307767b4b60a960105c760469a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/47.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0d08341d074f93ba96e48b1db93083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/original_model_gemma2-2b'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "os.environ[\"HF_TOKEN\"]=user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "os.environ[\"WANDB_API_KEY\"]=user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "os.environ[\"MODEL_NAME\"] = \"google/gemma-2-2b-it\"\n",
    "os.environ[\"DATASET\"] = \"HuggingFaceH4/ultrafeedback_binarized\"\n",
    "\n",
    "login(os.environ[\"HF_TOKEN\"])\n",
    "\n",
    "model_name = \"google/gemma-2-2b-it\" # the model we want to quantize\n",
    "methods = ['Q4_K_S','Q4_K_M'] #the methods to be used for quantization\n",
    "base_model = \"./original_model_gemma2-2b/\" # where the FP16 GGUF model will be stored\n",
    "quantized_path = \"./quantized_model_gemma2-2b/\" #where the quantized GGUF model will be stored\n",
    "original_model = quantized_path + 'FP16.gguf'\n",
    "\n",
    "snapshot_download(repo_id=model_name, local_dir=base_model , local_dir_use_symlinks=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879005d8",
   "metadata": {
    "papermill": {
     "duration": 0.046136,
     "end_time": "2024-09-25T09:08:01.163733",
     "exception": false,
     "start_time": "2024-09-25T09:08:01.117597",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Convert model to gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "976b715a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T09:08:01.660145Z",
     "iopub.status.busy": "2024-09-25T09:08:01.659617Z",
     "iopub.status.idle": "2024-09-25T09:08:32.916985Z",
     "shell.execute_reply": "2024-09-25T09:08:32.915984Z"
    },
    "papermill": {
     "duration": 41.479851,
     "end_time": "2024-09-25T09:08:42.662436",
     "exception": false,
     "start_time": "2024-09-25T09:08:01.182585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing: 100%|███████████████████████████| 5.23G/5.23G [00:22<00:00, 234Mbyte/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python llama.cpp/convert_hf_to_gguf.py \"./original_model_gemma2-2b/\" --outfile \"./quantized_model_gemma2-2b/FP16.gguf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c0a4f",
   "metadata": {
    "papermill": {
     "duration": 0.039906,
     "end_time": "2024-09-25T09:08:42.842577",
     "exception": false,
     "start_time": "2024-09-25T09:08:42.802671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Download the datasets that will be used for calibration and evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20872455",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T09:08:42.888487Z",
     "iopub.status.busy": "2024-09-25T09:08:42.888105Z",
     "iopub.status.idle": "2024-09-25T09:09:28.598908Z",
     "shell.execute_reply": "2024-09-25T09:09:28.597777Z"
    },
    "papermill": {
     "duration": 45.736126,
     "end_time": "2024-09-25T09:09:28.600888",
     "exception": false,
     "start_time": "2024-09-25T09:08:42.864762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-25 09:08:43--  https://object.pouta.csc.fi/OPUS-Wikipedia/v1.0/mono/en.txt.gz\r\n",
      "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.19, 86.50.254.18\r\n",
      "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.19|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 532958396 (508M) [application/gzip]\r\n",
      "Saving to: 'en.txt.gz'\r\n",
      "\r\n",
      "en.txt.gz           100%[===================>] 508.27M  20.0MB/s    in 27s     \r\n",
      "\r\n",
      "2024-09-25 09:09:11 (18.8 MB/s) - 'en.txt.gz' saved [532958396/532958396]\r\n",
      "\r\n",
      "--2024-09-25 09:09:27--  https://huggingface.co/datasets/ggml-org/ci/resolve/main/wikitext-2-raw-v1.zip\r\n",
      "Resolving huggingface.co (huggingface.co)... 3.165.160.11, 3.165.160.59, 3.165.160.61, ...\r\n",
      "Connecting to huggingface.co (huggingface.co)|3.165.160.11|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://cdn-lfs-us-1.huggingface.co/repos/c6/78/c67802fcd48fa6f6a86773410b21cc6db1c5c546b20683b6c30b95f327a66922/ef7edb566e3e2b2d31b29c1fdb0c89a4cc683597484c3dc2517919c615435a11?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27wikitext-2-raw-v1.zip%3B+filename%3D%22wikitext-2-raw-v1.zip%22%3B&response-content-type=application%2Fzip&Expires=1727514567&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNzUxNDU2N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2M2Lzc4L2M2NzgwMmZjZDQ4ZmE2ZjZhODY3NzM0MTBiMjFjYzZkYjFjNWM1NDZiMjA2ODNiNmMzMGI5NWYzMjdhNjY5MjIvZWY3ZWRiNTY2ZTNlMmIyZDMxYjI5YzFmZGIwYzg5YTRjYzY4MzU5NzQ4NGMzZGMyNTE3OTE5YzYxNTQzNWExMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=L-iwFPkZSk%7Ez%7ELccsGOfiPfRMn5exRhWli2cC2GPjdCjYsCMElmkoiBAzZvBrm2v2sSCZR%7Ez97jHxLsfC1vziQQqcFvTGC64nTFP6m-Aau6zt%7EqbLfusfeljG%7Ejm-aNceVHbUNzEtTCoPvm2rb3YhlhQRBzO2CAiY6jsvXV8FyNq8c7dURLKh-oRHl26AhyoMwaZpck8QsXcOblHZ5%7EFl8fI2iq-%7ElqBh6HjIyTKrRcQEoa%7EHKxZrlVS%7EWhKX9%7ENCYUFA7623ChuFfJlsQfZ13vl4WCHuSvsANx6VNKVR5iJkZjDVDbTs5lgZUMVtRdok2fHHHvyS4OSDfNfBniYrw__&Key-Pair-Id=K24J24Z295AEI9 [following]\r\n",
      "--2024-09-25 09:09:27--  https://cdn-lfs-us-1.huggingface.co/repos/c6/78/c67802fcd48fa6f6a86773410b21cc6db1c5c546b20683b6c30b95f327a66922/ef7edb566e3e2b2d31b29c1fdb0c89a4cc683597484c3dc2517919c615435a11?response-content-disposition=inline%3B+filename*%3DUTF-8''wikitext-2-raw-v1.zip%3B+filename%3D%22wikitext-2-raw-v1.zip%22%3B&response-content-type=application%2Fzip&Expires=1727514567&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNzUxNDU2N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2M2Lzc4L2M2NzgwMmZjZDQ4ZmE2ZjZhODY3NzM0MTBiMjFjYzZkYjFjNWM1NDZiMjA2ODNiNmMzMGI5NWYzMjdhNjY5MjIvZWY3ZWRiNTY2ZTNlMmIyZDMxYjI5YzFmZGIwYzg5YTRjYzY4MzU5NzQ4NGMzZGMyNTE3OTE5YzYxNTQzNWExMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=L-iwFPkZSk~z~LccsGOfiPfRMn5exRhWli2cC2GPjdCjYsCMElmkoiBAzZvBrm2v2sSCZR~z97jHxLsfC1vziQQqcFvTGC64nTFP6m-Aau6zt~qbLfusfeljG~jm-aNceVHbUNzEtTCoPvm2rb3YhlhQRBzO2CAiY6jsvXV8FyNq8c7dURLKh-oRHl26AhyoMwaZpck8QsXcOblHZ5~Fl8fI2iq-~lqBh6HjIyTKrRcQEoa~HKxZrlVS~WhKX9~NCYUFA7623ChuFfJlsQfZ13vl4WCHuSvsANx6VNKVR5iJkZjDVDbTs5lgZUMVtRdok2fHHHvyS4OSDfNfBniYrw__&Key-Pair-Id=K24J24Z295AEI9\r\n",
      "Resolving cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)... 3.163.189.127, 3.163.189.28, 3.163.189.91, ...\r\n",
      "Connecting to cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)|3.163.189.127|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 4721645 (4.5M) [application/zip]\r\n",
      "Saving to: 'wikitext-2-raw-v1.zip'\r\n",
      "\r\n",
      "wikitext-2-raw-v1.z 100%[===================>]   4.50M  17.3MB/s    in 0.3s    \r\n",
      "\r\n",
      "2024-09-25 09:09:28 (17.3 MB/s) - 'wikitext-2-raw-v1.zip' saved [4721645/4721645]\r\n",
      "\r\n",
      "Archive:  wikitext-2-raw-v1.zip\r\n",
      "   creating: wikitext-2-raw/\r\n",
      "  inflating: wikitext-2-raw/wiki.test.raw  \r\n",
      "  inflating: wikitext-2-raw/wiki.valid.raw  \r\n",
      "  inflating: wikitext-2-raw/wiki.train.raw  \r\n",
      "Usage:\r\n",
      "\r\n",
      "  ./llama-perplexity -m model.gguf -f wikitext-2-raw/wiki.test.raw [other params]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://object.pouta.csc.fi/OPUS-Wikipedia/v1.0/mono/en.txt.gz\n",
    "!gunzip en.txt.gz\n",
    "!head -n 10000 en.txt > en-h10000.txt\n",
    "!sh llama.cpp/scripts/get-wikitext-2.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adac09a0",
   "metadata": {
    "papermill": {
     "duration": 0.030041,
     "end_time": "2024-09-25T09:09:28.661703",
     "exception": false,
     "start_time": "2024-09-25T09:09:28.631662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Compute the importance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27607e8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T09:09:28.724806Z",
     "iopub.status.busy": "2024-09-25T09:09:28.724435Z",
     "iopub.status.idle": "2024-09-25T09:26:09.090556Z",
     "shell.execute_reply": "2024-09-25T09:26:09.089520Z"
    },
    "papermill": {
     "duration": 1000.401411,
     "end_time": "2024-09-25T09:26:09.092972",
     "exception": false,
     "start_time": "2024-09-25T09:09:28.691561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build: 3823 (3d6bf691) with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\r\n",
      "llama_model_loader: loaded meta data with 38 key-value pairs and 288 tensors from ./quantized_model_gemma2-2b/FP16.gguf (version GGUF V3 (latest))\r\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\r\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = gemma2\r\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\r\n",
      "llama_model_loader: - kv   2:                               general.name str              = Original_Model_Gemma2 2b\r\n",
      "llama_model_loader: - kv   3:                           general.basename str              = original_model_gemma2\r\n",
      "llama_model_loader: - kv   4:                         general.size_label str              = 2B\r\n",
      "llama_model_loader: - kv   5:                            general.license str              = gemma\r\n",
      "llama_model_loader: - kv   6:                   general.base_model.count u32              = 1\r\n",
      "llama_model_loader: - kv   7:                  general.base_model.0.name str              = Gemma 2 2b\r\n",
      "llama_model_loader: - kv   8:          general.base_model.0.organization str              = Google\r\n",
      "llama_model_loader: - kv   9:              general.base_model.0.repo_url str              = https://huggingface.co/google/gemma-2-2b\r\n",
      "llama_model_loader: - kv  10:                               general.tags arr[str,2]       = [\"conversational\", \"text-generation\"]\r\n",
      "llama_model_loader: - kv  11:                      gemma2.context_length u32              = 8192\r\n",
      "llama_model_loader: - kv  12:                    gemma2.embedding_length u32              = 2304\r\n",
      "llama_model_loader: - kv  13:                         gemma2.block_count u32              = 26\r\n",
      "llama_model_loader: - kv  14:                 gemma2.feed_forward_length u32              = 9216\r\n",
      "llama_model_loader: - kv  15:                gemma2.attention.head_count u32              = 8\r\n",
      "llama_model_loader: - kv  16:             gemma2.attention.head_count_kv u32              = 4\r\n",
      "llama_model_loader: - kv  17:    gemma2.attention.layer_norm_rms_epsilon f32              = 0.000001\r\n",
      "llama_model_loader: - kv  18:                gemma2.attention.key_length u32              = 256\r\n",
      "llama_model_loader: - kv  19:              gemma2.attention.value_length u32              = 256\r\n",
      "llama_model_loader: - kv  20:                          general.file_type u32              = 1\r\n",
      "llama_model_loader: - kv  21:              gemma2.attn_logit_softcapping f32              = 50.000000\r\n",
      "llama_model_loader: - kv  22:             gemma2.final_logit_softcapping f32              = 30.000000\r\n",
      "llama_model_loader: - kv  23:            gemma2.attention.sliding_window u32              = 4096\r\n",
      "llama_model_loader: - kv  24:                       tokenizer.ggml.model str              = llama\r\n",
      "llama_model_loader: - kv  25:                         tokenizer.ggml.pre str              = default\r\n",
      "llama_model_loader: - kv  26:                      tokenizer.ggml.tokens arr[str,256000]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\r\n",
      "llama_model_loader: - kv  27:                      tokenizer.ggml.scores arr[f32,256000]  = [-1000.000000, -1000.000000, -1000.00...\r\n",
      "llama_model_loader: - kv  28:                  tokenizer.ggml.token_type arr[i32,256000]  = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\r\n",
      "llama_model_loader: - kv  29:                tokenizer.ggml.bos_token_id u32              = 2\r\n",
      "llama_model_loader: - kv  30:                tokenizer.ggml.eos_token_id u32              = 1\r\n",
      "llama_model_loader: - kv  31:            tokenizer.ggml.unknown_token_id u32              = 3\r\n",
      "llama_model_loader: - kv  32:            tokenizer.ggml.padding_token_id u32              = 0\r\n",
      "llama_model_loader: - kv  33:               tokenizer.ggml.add_bos_token bool             = true\r\n",
      "llama_model_loader: - kv  34:               tokenizer.ggml.add_eos_token bool             = false\r\n",
      "llama_model_loader: - kv  35:                    tokenizer.chat_template str              = {{ bos_token }}{% if messages[0]['rol...\r\n",
      "llama_model_loader: - kv  36:            tokenizer.ggml.add_space_prefix bool             = false\r\n",
      "llama_model_loader: - kv  37:               general.quantization_version u32              = 2\r\n",
      "llama_model_loader: - type  f32:  105 tensors\r\n",
      "llama_model_loader: - type  f16:  183 tensors\r\n",
      "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\r\n",
      "llm_load_vocab: special tokens cache size = 249\r\n",
      "llm_load_vocab: token to piece cache size = 1.6014 MB\r\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\r\n",
      "llm_load_print_meta: arch             = gemma2\r\n",
      "llm_load_print_meta: vocab type       = SPM\r\n",
      "llm_load_print_meta: n_vocab          = 256000\r\n",
      "llm_load_print_meta: n_merges         = 0\r\n",
      "llm_load_print_meta: vocab_only       = 0\r\n",
      "llm_load_print_meta: n_ctx_train      = 8192\r\n",
      "llm_load_print_meta: n_embd           = 2304\r\n",
      "llm_load_print_meta: n_layer          = 26\r\n",
      "llm_load_print_meta: n_head           = 8\r\n",
      "llm_load_print_meta: n_head_kv        = 4\r\n",
      "llm_load_print_meta: n_rot            = 256\r\n",
      "llm_load_print_meta: n_swa            = 4096\r\n",
      "llm_load_print_meta: n_embd_head_k    = 256\r\n",
      "llm_load_print_meta: n_embd_head_v    = 256\r\n",
      "llm_load_print_meta: n_gqa            = 2\r\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\r\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\r\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\r\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\r\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\r\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\r\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\r\n",
      "llm_load_print_meta: n_ff             = 9216\r\n",
      "llm_load_print_meta: n_expert         = 0\r\n",
      "llm_load_print_meta: n_expert_used    = 0\r\n",
      "llm_load_print_meta: causal attn      = 1\r\n",
      "llm_load_print_meta: pooling type     = 0\r\n",
      "llm_load_print_meta: rope type        = 2\r\n",
      "llm_load_print_meta: rope scaling     = linear\r\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\r\n",
      "llm_load_print_meta: freq_scale_train = 1\r\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 8192\r\n",
      "llm_load_print_meta: rope_finetuned   = unknown\r\n",
      "llm_load_print_meta: ssm_d_conv       = 0\r\n",
      "llm_load_print_meta: ssm_d_inner      = 0\r\n",
      "llm_load_print_meta: ssm_d_state      = 0\r\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\r\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\r\n",
      "llm_load_print_meta: model type       = 2B\r\n",
      "llm_load_print_meta: model ftype      = F16\r\n",
      "llm_load_print_meta: model params     = 2.61 B\r\n",
      "llm_load_print_meta: model size       = 4.87 GiB (16.00 BPW) \r\n",
      "llm_load_print_meta: general.name     = Original_Model_Gemma2 2b\r\n",
      "llm_load_print_meta: BOS token        = 2 '<bos>'\r\n",
      "llm_load_print_meta: EOS token        = 1 '<eos>'\r\n",
      "llm_load_print_meta: UNK token        = 3 '<unk>'\r\n",
      "llm_load_print_meta: PAD token        = 0 '<pad>'\r\n",
      "llm_load_print_meta: LF token         = 227 '<0x0A>'\r\n",
      "llm_load_print_meta: EOT token        = 107 '<end_of_turn>'\r\n",
      "llm_load_print_meta: EOG token        = 1 '<eos>'\r\n",
      "llm_load_print_meta: EOG token        = 107 '<end_of_turn>'\r\n",
      "llm_load_print_meta: max token length = 48\r\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\r\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\r\n",
      "ggml_cuda_init: found 1 CUDA devices:\r\n",
      "  Device 0: Tesla P100-PCIE-16GB, compute capability 6.0, VMM: yes\r\n",
      "llm_load_tensors: ggml ctx size =    0.26 MiB\r\n",
      "llm_load_tensors: offloading 26 repeating layers to GPU\r\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\r\n",
      "llm_load_tensors: offloaded 27/27 layers to GPU\r\n",
      "llm_load_tensors:        CPU buffer size =  1125.00 MiB\r\n",
      "llm_load_tensors:      CUDA0 buffer size =  4986.92 MiB\r\n",
      "..................................................................\r\n",
      "llama_new_context_with_model: n_ctx      = 512\r\n",
      "llama_new_context_with_model: n_batch    = 512\r\n",
      "llama_new_context_with_model: n_ubatch   = 512\r\n",
      "llama_new_context_with_model: flash_attn = 0\r\n",
      "llama_new_context_with_model: freq_base  = 10000.0\r\n",
      "llama_new_context_with_model: freq_scale = 1\r\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =    52.00 MiB\r\n",
      "llama_new_context_with_model: KV self size  =   52.00 MiB, K (f16):   26.00 MiB, V (f16):   26.00 MiB\r\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.98 MiB\r\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   504.50 MiB\r\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =     6.51 MiB\r\n",
      "llama_new_context_with_model: graph nodes  = 1050\r\n",
      "llama_new_context_with_model: graph splits = 2\r\n",
      "\r\n",
      "system_info: n_threads = 2 (n_threads_batch = 2) / 4 | AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \r\n",
      "compute_imatrix: tokenizing the input ..\r\n",
      "compute_imatrix: tokenization took 2504.72 ms\r\n",
      "compute_imatrix: computing over 696 chunks with batch_size 512\r\n",
      "compute_imatrix: 1.55 seconds per pass - ETA 18.00 minutes\r\n",
      "[1]8.6770,[2]12.3273,[3]16.5609,[4]21.8836,[5]20.4886,[6]19.0793,[7]17.1510,[8]15.8433,[9]16.3802,\r\n",
      "save_imatrix: stored collected data after 10 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[10]15.8274,[11]15.8316,[12]15.7493,[13]15.5668,[14]14.7952,[15]15.7660,[16]16.0228,[17]15.8303,[18]15.2348,[19]15.0015,\r\n",
      "save_imatrix: stored collected data after 20 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[20]13.7488,[21]13.9516,[22]13.5287,[23]13.6752,[24]13.4761,[25]13.6356,[26]13.3252,[27]13.1602,[28]13.0602,[29]12.7336,\r\n",
      "save_imatrix: stored collected data after 30 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[30]12.4564,[31]12.6380,[32]12.6140,[33]12.4972,[34]12.1728,[35]12.2149,[36]12.2531,[37]12.2916,[38]12.2690,[39]12.3680,\r\n",
      "save_imatrix: stored collected data after 40 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[40]12.3018,[41]12.1604,[42]12.2772,[43]12.2023,[44]12.2840,[45]12.1491,[46]12.3551,[47]12.2668,[48]12.2038,[49]12.1995,\r\n",
      "save_imatrix: stored collected data after 50 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[50]12.3215,[51]12.2419,[52]12.2102,[53]12.2107,[54]12.1225,[55]12.1210,[56]12.1935,[57]12.1855,[58]12.2019,[59]12.1583,\r\n",
      "save_imatrix: stored collected data after 60 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[60]11.8310,[61]11.5849,[62]11.4720,[63]11.5315,[64]11.4517,[65]11.4914,[66]11.4232,[67]11.4489,[68]11.5094,[69]11.5301,\r\n",
      "save_imatrix: stored collected data after 70 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[70]11.4260,[71]11.4387,[72]11.4396,[73]11.3928,[74]11.3414,[75]11.4019,[76]11.4182,[77]11.4747,[78]11.4849,[79]11.4182,\r\n",
      "save_imatrix: stored collected data after 80 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[80]11.3828,[81]11.3250,[82]11.3236,[83]11.3472,[84]11.2685,[85]11.2809,[86]11.2589,[87]11.1906,[88]11.1792,[89]11.2110,\r\n",
      "save_imatrix: stored collected data after 90 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[90]11.1672,[91]11.1862,[92]11.2088,[93]11.1563,[94]11.1740,[95]11.0856,[96]11.0484,[97]11.0520,[98]11.0137,[99]11.0172,\r\n",
      "save_imatrix: stored collected data after 100 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[100]11.0779,[101]11.0905,[102]10.9605,[103]10.8199,[104]10.6662,[105]10.5691,[106]10.6100,[107]10.6241,[108]10.6722,[109]10.6712,\r\n",
      "save_imatrix: stored collected data after 110 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[110]10.6946,[111]10.7639,[112]10.8148,[113]10.7595,[114]10.6559,[115]10.7006,[116]10.8286,[117]10.9089,[118]10.8973,[119]10.9121,\r\n",
      "save_imatrix: stored collected data after 120 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[120]10.9889,[121]11.0909,[122]11.1301,[123]11.1878,[124]11.2451,[125]11.2474,[126]11.2318,[127]11.2432,[128]11.2033,[129]11.2606,\r\n",
      "save_imatrix: stored collected data after 130 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[130]11.2382,[131]11.2586,[132]11.2770,[133]11.3357,[134]11.3350,[135]11.3879,[136]11.3942,[137]11.4180,[138]11.3672,[139]11.3168,\r\n",
      "save_imatrix: stored collected data after 140 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[140]11.3021,[141]11.1918,[142]11.1930,[143]11.1992,[144]11.2292,[145]11.2587,[146]11.1915,[147]11.2177,[148]11.2350,[149]11.2465,\r\n",
      "save_imatrix: stored collected data after 150 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[150]11.2193,[151]11.2516,[152]11.2739,[153]11.2838,[154]11.3009,[155]11.2815,[156]11.3158,[157]11.2802,[158]11.3005,[159]11.3176,\r\n",
      "save_imatrix: stored collected data after 160 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[160]11.2517,[161]11.2288,[162]11.2319,[163]11.2720,[164]11.2566,[165]11.2112,[166]11.1702,[167]11.1581,[168]11.1399,[169]11.1556,\r\n",
      "save_imatrix: stored collected data after 170 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[170]11.1574,[171]11.1146,[172]11.1572,[173]11.1547,[174]11.1600,[175]11.1771,[176]11.2209,[177]11.2123,[178]11.2253,[179]11.2332,\r\n",
      "save_imatrix: stored collected data after 180 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[180]11.2162,[181]11.2158,[182]11.2128,[183]11.1709,[184]11.1605,[185]11.1686,[186]11.1387,[187]11.0874,[188]11.1002,[189]11.1242,\r\n",
      "save_imatrix: stored collected data after 190 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[190]11.1744,[191]11.2189,[192]11.2542,[193]11.2542,[194]11.2713,[195]11.2648,[196]11.2421,[197]11.2036,[198]11.2389,[199]11.2467,\r\n",
      "save_imatrix: stored collected data after 200 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[200]11.2043,[201]11.2300,[202]11.2387,[203]11.2467,[204]11.2584,[205]11.2946,[206]11.3204,[207]11.3345,[208]11.3525,[209]11.3738,\r\n",
      "save_imatrix: stored collected data after 210 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[210]11.3823,[211]11.3677,[212]11.3686,[213]11.3804,[214]11.3707,[215]11.3538,[216]11.3968,[217]11.4375,[218]11.4577,[219]11.4530,\r\n",
      "save_imatrix: stored collected data after 220 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[220]11.4345,[221]11.4188,[222]11.4088,[223]11.4092,[224]11.4272,[225]11.4332,[226]11.4197,[227]11.4396,[228]11.4339,[229]11.4368,\r\n",
      "save_imatrix: stored collected data after 230 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[230]11.4394,[231]11.4224,[232]11.3942,[233]11.3812,[234]11.3780,[235]11.3851,[236]11.4332,[237]11.4912,[238]11.4910,[239]11.4829,\r\n",
      "save_imatrix: stored collected data after 240 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[240]11.4629,[241]11.4408,[242]11.4247,[243]11.4272,[244]11.4300,[245]11.4595,[246]11.4720,[247]11.4728,[248]11.4625,[249]11.4777,\r\n",
      "save_imatrix: stored collected data after 250 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[250]11.5188,[251]11.5714,[252]11.5777,[253]11.5415,[254]11.5145,[255]11.5605,[256]11.5867,[257]11.5668,[258]11.5945,[259]11.5956,\r\n",
      "save_imatrix: stored collected data after 260 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[260]11.6058,[261]11.6133,[262]11.6177,[263]11.6174,[264]11.6182,[265]11.5916,[266]11.5685,[267]11.5811,[268]11.6043,[269]11.6081,\r\n",
      "save_imatrix: stored collected data after 270 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[270]11.6055,[271]11.5940,[272]11.5927,[273]11.5727,[274]11.6031,[275]11.5879,[276]11.5799,[277]11.5975,[278]11.6109,[279]11.6164,\r\n",
      "save_imatrix: stored collected data after 280 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[280]11.6278,[281]11.6459,[282]11.6507,[283]11.6448,[284]11.6378,[285]11.6594,[286]11.6598,[287]11.6520,[288]11.6434,[289]11.6516,\r\n",
      "save_imatrix: stored collected data after 290 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[290]11.6494,[291]11.6613,[292]11.6420,[293]11.6506,[294]11.6787,[295]11.6945,[296]11.6965,[297]11.6741,[298]11.7053,[299]11.7081,\r\n",
      "save_imatrix: stored collected data after 300 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[300]11.7165,[301]11.7351,[302]11.7321,[303]11.7321,[304]11.7589,[305]11.7398,[306]11.7368,[307]11.7341,[308]11.6939,[309]11.6907,\r\n",
      "save_imatrix: stored collected data after 310 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[310]11.6360,[311]11.5738,[312]11.5930,[313]11.5961,[314]11.6286,[315]11.6203,[316]11.6331,[317]11.6251,[318]11.6236,[319]11.5986,\r\n",
      "save_imatrix: stored collected data after 320 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[320]11.5782,[321]11.5488,[322]11.5066,[323]11.4933,[324]11.4845,[325]11.4733,[326]11.4444,[327]11.4021,[328]11.3680,[329]11.3347,\r\n",
      "save_imatrix: stored collected data after 330 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[330]11.2936,[331]11.2658,[332]11.2285,[333]11.2160,[334]11.2086,[335]11.1733,[336]11.1493,[337]11.1423,[338]11.1416,[339]11.1474,\r\n",
      "save_imatrix: stored collected data after 340 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[340]11.1491,[341]11.1148,[342]11.1091,[343]11.1086,[344]11.1089,[345]11.1099,[346]11.1357,[347]11.1175,[348]11.1240,[349]11.1226,\r\n",
      "save_imatrix: stored collected data after 350 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[350]11.0897,[351]11.0824,[352]11.0702,[353]11.0563,[354]11.0927,[355]11.0727,[356]11.0776,[357]11.0948,[358]11.1037,[359]11.1224,\r\n",
      "save_imatrix: stored collected data after 360 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[360]11.1183,[361]11.1099,[362]11.1191,[363]11.1417,[364]11.1378,[365]11.1432,[366]11.1690,[367]11.1781,[368]11.1936,[369]11.1958,\r\n",
      "save_imatrix: stored collected data after 370 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[370]11.1987,[371]11.1745,[372]11.1787,[373]11.1928,[374]11.1865,[375]11.2022,[376]11.2118,[377]11.2176,[378]11.2201,[379]11.2083,\r\n",
      "save_imatrix: stored collected data after 380 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[380]11.1883,[381]11.1845,[382]11.2023,[383]11.2058,[384]11.2186,[385]11.2394,[386]11.2524,[387]11.2637,[388]11.2608,[389]11.2537,\r\n",
      "save_imatrix: stored collected data after 390 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[390]11.2593,[391]11.2478,[392]11.2511,[393]11.2355,[394]11.2122,[395]11.2076,[396]11.2143,[397]11.1925,[398]11.2003,[399]11.1762,\r\n",
      "save_imatrix: stored collected data after 400 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[400]11.1826,[401]11.1659,[402]11.1566,[403]11.1496,[404]11.1502,[405]11.1630,[406]11.1528,[407]11.1604,[408]11.1801,[409]11.1966,\r\n",
      "save_imatrix: stored collected data after 410 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[410]11.1873,[411]11.1950,[412]11.2118,[413]11.2209,[414]11.2470,[415]11.2625,[416]11.2954,[417]11.2904,[418]11.2864,[419]11.2941,\r\n",
      "save_imatrix: stored collected data after 420 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[420]11.2810,[421]11.2737,[422]11.2704,[423]11.2849,[424]11.2848,[425]11.2819,[426]11.2793,[427]11.2708,[428]11.2669,[429]11.2893,\r\n",
      "save_imatrix: stored collected data after 430 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[430]11.3036,[431]11.3407,[432]11.3416,[433]11.3448,[434]11.3445,[435]11.3588,[436]11.3540,[437]11.3639,[438]11.3732,[439]11.3755,\r\n",
      "save_imatrix: stored collected data after 440 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[440]11.3638,[441]11.3689,[442]11.3776,[443]11.3812,[444]11.3828,[445]11.3819,[446]11.3906,[447]11.3828,[448]11.3704,[449]11.3594,\r\n",
      "save_imatrix: stored collected data after 450 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[450]11.3558,[451]11.3481,[452]11.3681,[453]11.3522,[454]11.3416,[455]11.3414,[456]11.3373,[457]11.3293,[458]11.3557,[459]11.3591,\r\n",
      "save_imatrix: stored collected data after 460 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[460]11.3586,[461]11.3649,[462]11.3757,[463]11.3796,[464]11.3809,[465]11.3756,[466]11.3657,[467]11.3686,[468]11.3691,[469]11.3663,\r\n",
      "save_imatrix: stored collected data after 470 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[470]11.3454,[471]11.3397,[472]11.3288,[473]11.3533,[474]11.3608,[475]11.3707,[476]11.3681,[477]11.3754,[478]11.3925,[479]11.4037,\r\n",
      "save_imatrix: stored collected data after 480 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[480]11.4087,[481]11.4090,[482]11.3937,[483]11.3918,[484]11.3954,[485]11.4062,[486]11.3856,[487]11.3698,[488]11.3459,[489]11.3413,\r\n",
      "save_imatrix: stored collected data after 490 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[490]11.3359,[491]11.3421,[492]11.3498,[493]11.3497,[494]11.3584,[495]11.3840,[496]11.3742,[497]11.3797,[498]11.3950,[499]11.3998,\r\n",
      "save_imatrix: stored collected data after 500 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[500]11.4050,[501]11.4164,[502]11.4369,[503]11.4281,[504]11.4164,[505]11.4178,[506]11.3874,[507]11.3769,[508]11.3872,[509]11.3874,\r\n",
      "save_imatrix: stored collected data after 510 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[510]11.3921,[511]11.3882,[512]11.3812,[513]11.3888,[514]11.3965,[515]11.4192,[516]11.4192,[517]11.4090,[518]11.4095,[519]11.3788,\r\n",
      "save_imatrix: stored collected data after 520 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[520]11.3790,[521]11.3833,[522]11.3932,[523]11.3858,[524]11.3899,[525]11.4011,[526]11.4091,[527]11.4081,[528]11.4106,[529]11.4103,\r\n",
      "save_imatrix: stored collected data after 530 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[530]11.4058,[531]11.3926,[532]11.3918,[533]11.3950,[534]11.3880,[535]11.3740,[536]11.3696,[537]11.3601,[538]11.3542,[539]11.3421,\r\n",
      "save_imatrix: stored collected data after 540 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[540]11.3463,[541]11.3516,[542]11.3404,[543]11.3082,[544]11.3021,[545]11.2915,[546]11.2995,[547]11.2911,[548]11.3026,[549]11.3114,\r\n",
      "save_imatrix: stored collected data after 550 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[550]11.3301,[551]11.3288,[552]11.3465,[553]11.3479,[554]11.3662,[555]11.3783,[556]11.3951,[557]11.3996,[558]11.4106,[559]11.4266,\r\n",
      "save_imatrix: stored collected data after 560 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[560]11.4391,[561]11.4534,[562]11.4625,[563]11.4668,[564]11.4515,[565]11.4441,[566]11.4369,[567]11.4341,[568]11.4345,[569]11.4252,\r\n",
      "save_imatrix: stored collected data after 570 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[570]11.4236,[571]11.4498,[572]11.4515,[573]11.4578,[574]11.4608,[575]11.4714,[576]11.4817,[577]11.4874,[578]11.4779,[579]11.4657,\r\n",
      "save_imatrix: stored collected data after 580 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[580]11.4573,[581]11.4515,[582]11.4473,[583]11.4486,[584]11.4634,[585]11.4726,[586]11.4733,[587]11.4665,[588]11.4716,[589]11.4863,\r\n",
      "save_imatrix: stored collected data after 590 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[590]11.4839,[591]11.4793,[592]11.4797,[593]11.4859,[594]11.4832,[595]11.4843,[596]11.4868,[597]11.4931,[598]11.4798,[599]11.4636,\r\n",
      "save_imatrix: stored collected data after 600 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[600]11.4661,[601]11.4704,[602]11.4702,[603]11.4665,[604]11.4836,[605]11.4813,[606]11.4815,[607]11.4552,[608]11.4719,[609]11.4477,\r\n",
      "save_imatrix: stored collected data after 610 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[610]11.4297,[611]11.4062,[612]11.4072,[613]11.4123,[614]11.4106,[615]11.4152,[616]11.4092,[617]11.4066,[618]11.4077,[619]11.4133,\r\n",
      "save_imatrix: stored collected data after 620 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[620]11.4216,[621]11.4196,[622]11.4089,[623]11.4036,[624]11.3952,[625]11.3927,[626]11.3791,[627]11.3767,[628]11.3612,[629]11.3588,\r\n",
      "save_imatrix: stored collected data after 630 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[630]11.3694,[631]11.3731,[632]11.3763,[633]11.3829,[634]11.3913,[635]11.3846,[636]11.3875,[637]11.3793,[638]11.3986,[639]11.4114,\r\n",
      "save_imatrix: stored collected data after 640 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[640]11.4213,[641]11.4253,[642]11.4263,[643]11.4324,[644]11.4421,[645]11.4296,[646]11.4134,[647]11.4171,[648]11.4240,[649]11.4293,\r\n",
      "save_imatrix: stored collected data after 650 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[650]11.4357,[651]11.4354,[652]11.4412,[653]11.4410,[654]11.4447,[655]11.4532,[656]11.4531,[657]11.4506,[658]11.4441,[659]11.4450,\r\n",
      "save_imatrix: stored collected data after 660 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[660]11.4535,[661]11.4492,[662]11.4736,[663]11.4770,[664]11.4757,[665]11.4820,[666]11.4742,[667]11.4754,[668]11.4876,[669]11.4874,\r\n",
      "save_imatrix: stored collected data after 670 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[670]11.4773,[671]11.4738,[672]11.4736,[673]11.4719,[674]11.4666,[675]11.4704,[676]11.4729,[677]11.4620,[678]11.4633,[679]11.4670,\r\n",
      "save_imatrix: stored collected data after 680 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[680]11.4617,[681]11.4598,[682]11.4657,[683]11.4680,[684]11.4723,[685]11.4788,[686]11.4749,[687]11.4646,[688]11.4674,[689]11.4536,\r\n",
      "save_imatrix: stored collected data after 690 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "[690]11.4614,[691]11.4601,[692]11.4658,[693]11.4778,[694]11.4685,[695]11.4574,[696]11.4733,\r\n",
      "Final estimate: PPL = 11.4733 +/- 0.08400\r\n",
      "\r\n",
      "save_imatrix: stored collected data after 696 chunks in quantized_model_gemma2-2b/imatrix.dat\r\n",
      "\r\n",
      "llama_perf_context_print:        load time =    6476.43 ms\r\n",
      "llama_perf_context_print: prompt eval time =  786971.75 ms / 356352 tokens (    2.21 ms per token,   452.81 tokens per second)\r\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\r\n",
      "llama_perf_context_print:       total time =  998656.73 ms / 356353 tokens\r\n"
     ]
    }
   ],
   "source": [
    "!./llama.cpp/llama-imatrix -m \"./quantized_model_gemma2-2b/FP16.gguf\"  -f en-h10000.txt -o quantized_model_gemma2-2b/imatrix.dat --verbosity 1 -ngl 99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e872293f",
   "metadata": {
    "papermill": {
     "duration": 0.089326,
     "end_time": "2024-09-25T09:26:09.273861",
     "exception": false,
     "start_time": "2024-09-25T09:26:09.184535",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Quantize the model with K-Quants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "332bdbbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T09:26:09.456603Z",
     "iopub.status.busy": "2024-09-25T09:26:09.456191Z",
     "iopub.status.idle": "2024-09-25T09:29:27.823928Z",
     "shell.execute_reply": "2024-09-25T09:29:27.822776Z"
    },
    "papermill": {
     "duration": 198.461173,
     "end_time": "2024-09-25T09:29:27.826572",
     "exception": false,
     "start_time": "2024-09-25T09:26:09.365399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_imatrix: imatrix dataset='en-h10000.txt'\r\n",
      "load_imatrix: loaded 182 importance matrix entries from ./quantized_model_gemma2-2b/imatrix.dat computed on 696 chunks\r\n",
      "prepare_imatrix: have 182 importance matrix entries\r\n",
      "main: build = 3823 (3d6bf691)\r\n",
      "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\r\n",
      "main: quantizing './quantized_model_gemma2-2b/FP16.gguf' to './quantized_model_gemma2-2b/FP16_I.gguf' as Q4_K_S\r\n",
      "llama_model_loader: loaded meta data with 38 key-value pairs and 288 tensors from ./quantized_model_gemma2-2b/FP16.gguf (version GGUF V3 (latest))\r\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\r\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = gemma2\r\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\r\n",
      "llama_model_loader: - kv   2:                               general.name str              = Original_Model_Gemma2 2b\r\n",
      "llama_model_loader: - kv   3:                           general.basename str              = original_model_gemma2\r\n",
      "llama_model_loader: - kv   4:                         general.size_label str              = 2B\r\n",
      "llama_model_loader: - kv   5:                            general.license str              = gemma\r\n",
      "llama_model_loader: - kv   6:                   general.base_model.count u32              = 1\r\n",
      "llama_model_loader: - kv   7:                  general.base_model.0.name str              = Gemma 2 2b\r\n",
      "llama_model_loader: - kv   8:          general.base_model.0.organization str              = Google\r\n",
      "llama_model_loader: - kv   9:              general.base_model.0.repo_url str              = https://huggingface.co/google/gemma-2-2b\r\n",
      "llama_model_loader: - kv  10:                               general.tags arr[str,2]       = [\"conversational\", \"text-generation\"]\r\n",
      "llama_model_loader: - kv  11:                      gemma2.context_length u32              = 8192\r\n",
      "llama_model_loader: - kv  12:                    gemma2.embedding_length u32              = 2304\r\n",
      "llama_model_loader: - kv  13:                         gemma2.block_count u32              = 26\r\n",
      "llama_model_loader: - kv  14:                 gemma2.feed_forward_length u32              = 9216\r\n",
      "llama_model_loader: - kv  15:                gemma2.attention.head_count u32              = 8\r\n",
      "llama_model_loader: - kv  16:             gemma2.attention.head_count_kv u32              = 4\r\n",
      "llama_model_loader: - kv  17:    gemma2.attention.layer_norm_rms_epsilon f32              = 0.000001\r\n",
      "llama_model_loader: - kv  18:                gemma2.attention.key_length u32              = 256\r\n",
      "llama_model_loader: - kv  19:              gemma2.attention.value_length u32              = 256\r\n",
      "llama_model_loader: - kv  20:                          general.file_type u32              = 1\r\n",
      "llama_model_loader: - kv  21:              gemma2.attn_logit_softcapping f32              = 50.000000\r\n",
      "llama_model_loader: - kv  22:             gemma2.final_logit_softcapping f32              = 30.000000\r\n",
      "llama_model_loader: - kv  23:            gemma2.attention.sliding_window u32              = 4096\r\n",
      "llama_model_loader: - kv  24:                       tokenizer.ggml.model str              = llama\r\n",
      "llama_model_loader: - kv  25:                         tokenizer.ggml.pre str              = default\r\n",
      "llama_model_loader: - kv  26:                      tokenizer.ggml.tokens arr[str,256000]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\r\n",
      "llama_model_loader: - kv  27:                      tokenizer.ggml.scores arr[f32,256000]  = [-1000.000000, -1000.000000, -1000.00...\r\n",
      "llama_model_loader: - kv  28:                  tokenizer.ggml.token_type arr[i32,256000]  = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\r\n",
      "llama_model_loader: - kv  29:                tokenizer.ggml.bos_token_id u32              = 2\r\n",
      "llama_model_loader: - kv  30:                tokenizer.ggml.eos_token_id u32              = 1\r\n",
      "llama_model_loader: - kv  31:            tokenizer.ggml.unknown_token_id u32              = 3\r\n",
      "llama_model_loader: - kv  32:            tokenizer.ggml.padding_token_id u32              = 0\r\n",
      "llama_model_loader: - kv  33:               tokenizer.ggml.add_bos_token bool             = true\r\n",
      "llama_model_loader: - kv  34:               tokenizer.ggml.add_eos_token bool             = false\r\n",
      "llama_model_loader: - kv  35:                    tokenizer.chat_template str              = {{ bos_token }}{% if messages[0]['rol...\r\n",
      "llama_model_loader: - kv  36:            tokenizer.ggml.add_space_prefix bool             = false\r\n",
      "llama_model_loader: - kv  37:               general.quantization_version u32              = 2\r\n",
      "llama_model_loader: - type  f32:  105 tensors\r\n",
      "llama_model_loader: - type  f16:  183 tensors\r\n",
      "================================ Have weights data with 182 entries\r\n",
      "[   1/ 288]                    token_embd.weight - [ 2304, 256000,     1,     1], type =    f16, \r\n",
      "====== llama_model_quantize_internal: did not find weights for token_embd.weight\r\n",
      "converting to q6_K .. size =  1125.00 MiB ->   461.43 MiB\r\n",
      "[   2/ 288]               blk.0.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[   3/ 288]                blk.0.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\r\n",
      "[   4/ 288]                blk.0.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[   5/ 288]                  blk.0.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[   6/ 288]     blk.0.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[   7/ 288]           blk.0.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[   8/ 288]                blk.0.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[   9/ 288]                  blk.0.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[  10/ 288]             blk.0.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[  11/ 288]                  blk.0.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[  12/ 288]                  blk.0.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\r\n",
      "[  13/ 288]               blk.1.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  14/ 288]                blk.1.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\r\n",
      "[  15/ 288]                blk.1.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[  16/ 288]                  blk.1.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[  17/ 288]     blk.1.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  18/ 288]           blk.1.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  19/ 288]                blk.1.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  20/ 288]                  blk.1.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[  21/ 288]             blk.1.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[  22/ 288]                  blk.1.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[  23/ 288]                  blk.1.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\r\n",
      "[  24/ 288]              blk.10.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  25/ 288]               blk.10.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\r\n",
      "[  26/ 288]               blk.10.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[  27/ 288]                 blk.10.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[  28/ 288]    blk.10.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  29/ 288]          blk.10.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  30/ 288]               blk.10.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  31/ 288]                 blk.10.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[  32/ 288]            blk.10.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[  33/ 288]                 blk.10.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[  34/ 288]                 blk.10.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\r\n",
      "[  35/ 288]              blk.11.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  36/ 288]               blk.11.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[  37/ 288]               blk.11.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[  38/ 288]                 blk.11.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[  39/ 288]    blk.11.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  40/ 288]          blk.11.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  41/ 288]               blk.11.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  42/ 288]                 blk.11.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[  43/ 288]            blk.11.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[  44/ 288]                 blk.11.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[  45/ 288]                 blk.11.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\r\n",
      "[  46/ 288]              blk.12.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  47/ 288]               blk.12.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[  48/ 288]               blk.12.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[  49/ 288]                 blk.12.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[  50/ 288]    blk.12.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  51/ 288]          blk.12.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  52/ 288]               blk.12.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  53/ 288]                 blk.12.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[  54/ 288]            blk.12.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[  55/ 288]                 blk.12.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[  56/ 288]                 blk.12.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[  57/ 288]              blk.13.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  58/ 288]               blk.13.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[  59/ 288]               blk.13.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[  60/ 288]                 blk.13.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[  61/ 288]    blk.13.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  62/ 288]          blk.13.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  63/ 288]               blk.13.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  64/ 288]                 blk.13.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[  65/ 288]            blk.13.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[  66/ 288]                 blk.13.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[  67/ 288]                 blk.13.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[  68/ 288]              blk.14.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  69/ 288]               blk.14.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[  70/ 288]               blk.14.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[  71/ 288]                 blk.14.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[  72/ 288]    blk.14.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  73/ 288]          blk.14.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  74/ 288]               blk.14.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  75/ 288]                 blk.14.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[  76/ 288]            blk.14.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[  77/ 288]                 blk.14.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[  78/ 288]                 blk.14.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[  79/ 288]              blk.15.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  80/ 288]               blk.15.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[  81/ 288]               blk.15.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[  82/ 288]                 blk.15.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[  83/ 288]    blk.15.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  84/ 288]          blk.15.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  85/ 288]               blk.15.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  86/ 288]                 blk.15.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[  87/ 288]            blk.15.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[  88/ 288]                 blk.15.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[  89/ 288]                 blk.15.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[  90/ 288]              blk.16.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  91/ 288]               blk.16.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[  92/ 288]               blk.16.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[  93/ 288]                 blk.16.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[  94/ 288]    blk.16.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  95/ 288]          blk.16.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  96/ 288]               blk.16.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[  97/ 288]                 blk.16.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[  98/ 288]            blk.16.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[  99/ 288]                 blk.16.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 100/ 288]                 blk.16.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 101/ 288]              blk.17.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 102/ 288]               blk.17.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 103/ 288]               blk.17.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 104/ 288]                 blk.17.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 105/ 288]    blk.17.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 106/ 288]          blk.17.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 107/ 288]               blk.17.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 108/ 288]                 blk.17.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 109/ 288]            blk.17.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 110/ 288]                 blk.17.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 111/ 288]                 blk.17.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 112/ 288]              blk.18.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 113/ 288]               blk.18.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 114/ 288]               blk.18.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 115/ 288]                 blk.18.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 116/ 288]    blk.18.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 117/ 288]          blk.18.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 118/ 288]               blk.18.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 119/ 288]                 blk.18.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 120/ 288]            blk.18.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 121/ 288]                 blk.18.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 122/ 288]                 blk.18.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 123/ 288]              blk.19.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 124/ 288]               blk.19.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 125/ 288]               blk.19.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 126/ 288]                 blk.19.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 127/ 288]    blk.19.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 128/ 288]          blk.19.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 129/ 288]               blk.19.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 130/ 288]                 blk.19.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 131/ 288]            blk.19.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 132/ 288]                 blk.19.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 133/ 288]                 blk.19.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 134/ 288]               blk.2.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 135/ 288]                blk.2.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 136/ 288]                blk.2.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 137/ 288]                  blk.2.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 138/ 288]     blk.2.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 139/ 288]           blk.2.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 140/ 288]                blk.2.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 141/ 288]                  blk.2.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 142/ 288]             blk.2.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 143/ 288]                  blk.2.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 144/ 288]                  blk.2.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 145/ 288]              blk.20.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 146/ 288]               blk.20.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 147/ 288]               blk.20.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 148/ 288]                 blk.20.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 149/ 288]    blk.20.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 150/ 288]          blk.20.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 151/ 288]               blk.20.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 152/ 288]                 blk.20.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 153/ 288]            blk.20.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 154/ 288]                 blk.20.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 155/ 288]                 blk.20.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 156/ 288]              blk.21.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 157/ 288]               blk.21.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 158/ 288]               blk.21.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 159/ 288]                 blk.21.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 160/ 288]    blk.21.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 161/ 288]          blk.21.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 162/ 288]               blk.21.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 163/ 288]                 blk.21.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 164/ 288]            blk.21.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 165/ 288]                 blk.21.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 166/ 288]                 blk.21.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 167/ 288]              blk.22.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 168/ 288]               blk.22.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 169/ 288]               blk.22.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 170/ 288]                 blk.22.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 171/ 288]    blk.22.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 172/ 288]          blk.22.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 173/ 288]               blk.22.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 174/ 288]                 blk.22.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 175/ 288]            blk.22.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 176/ 288]                 blk.22.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 177/ 288]                 blk.22.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 178/ 288]              blk.23.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 179/ 288]               blk.23.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 180/ 288]               blk.23.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 181/ 288]                 blk.23.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 182/ 288]    blk.23.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 183/ 288]          blk.23.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 184/ 288]               blk.23.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 185/ 288]                 blk.23.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 186/ 288]            blk.23.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 187/ 288]                 blk.23.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 188/ 288]                 blk.23.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 189/ 288]               blk.24.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 190/ 288]                 blk.24.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 191/ 288]            blk.24.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 192/ 288]                 blk.24.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 193/ 288]                 blk.24.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 194/ 288]               blk.3.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 195/ 288]                blk.3.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 196/ 288]                blk.3.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 197/ 288]                  blk.3.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 198/ 288]     blk.3.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 199/ 288]           blk.3.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 200/ 288]                blk.3.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 201/ 288]                  blk.3.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 202/ 288]             blk.3.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 203/ 288]                  blk.3.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 204/ 288]                  blk.3.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 205/ 288]               blk.4.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 206/ 288]                blk.4.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 207/ 288]                blk.4.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 208/ 288]                  blk.4.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 209/ 288]     blk.4.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 210/ 288]           blk.4.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 211/ 288]                blk.4.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 212/ 288]                  blk.4.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 213/ 288]             blk.4.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 214/ 288]                  blk.4.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 215/ 288]                  blk.4.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 216/ 288]               blk.5.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 217/ 288]                blk.5.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 218/ 288]                blk.5.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 219/ 288]                  blk.5.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 220/ 288]     blk.5.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 221/ 288]           blk.5.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 222/ 288]                blk.5.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 223/ 288]                  blk.5.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 224/ 288]             blk.5.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 225/ 288]                  blk.5.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 226/ 288]                  blk.5.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 227/ 288]               blk.6.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 228/ 288]                blk.6.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 229/ 288]                blk.6.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 230/ 288]                  blk.6.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 231/ 288]     blk.6.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 232/ 288]           blk.6.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 233/ 288]                blk.6.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 234/ 288]                  blk.6.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 235/ 288]             blk.6.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 236/ 288]                  blk.6.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 237/ 288]                  blk.6.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 238/ 288]               blk.7.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 239/ 288]                blk.7.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 240/ 288]                blk.7.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 241/ 288]                  blk.7.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 242/ 288]     blk.7.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 243/ 288]           blk.7.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 244/ 288]                blk.7.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 245/ 288]                  blk.7.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 246/ 288]             blk.7.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 247/ 288]                  blk.7.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 248/ 288]                  blk.7.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 249/ 288]               blk.8.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 250/ 288]                blk.8.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 251/ 288]                blk.8.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 252/ 288]                  blk.8.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 253/ 288]     blk.8.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 254/ 288]           blk.8.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 255/ 288]                blk.8.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 256/ 288]                  blk.8.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 257/ 288]             blk.8.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 258/ 288]                  blk.8.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 259/ 288]                  blk.8.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 260/ 288]               blk.9.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 261/ 288]                blk.9.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 262/ 288]                blk.9.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 263/ 288]                  blk.9.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 264/ 288]     blk.9.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 265/ 288]           blk.9.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 266/ 288]                blk.9.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 267/ 288]                  blk.9.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 268/ 288]             blk.9.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 269/ 288]                  blk.9.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 270/ 288]                  blk.9.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 271/ 288]              blk.24.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 272/ 288]               blk.24.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 273/ 288]                 blk.24.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 274/ 288]    blk.24.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 275/ 288]          blk.24.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 276/ 288]               blk.24.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 277/ 288]              blk.25.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 278/ 288]               blk.25.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 279/ 288]               blk.25.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 280/ 288]                 blk.25.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\r\n",
      "[ 281/ 288]    blk.25.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 282/ 288]          blk.25.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 283/ 288]               blk.25.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "[ 284/ 288]                 blk.25.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 285/ 288]            blk.25.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 286/ 288]                 blk.25.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\r\n",
      "[ 287/ 288]                 blk.25.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\r\n",
      "[ 288/ 288]                   output_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\r\n",
      "llama_model_quantize_internal: model size  =  4986.92 MB\r\n",
      "llama_model_quantize_internal: quant size  =  1556.97 MB\r\n",
      "\r\n",
      "main: quantize time = 197234.98 ms\r\n",
      "main:    total time = 197234.98 ms\r\n"
     ]
    }
   ],
   "source": [
    "!./llama.cpp/llama-quantize --imatrix ./quantized_model_gemma2-2b/imatrix.dat \"./quantized_model_gemma2-2b/FP16.gguf\"  \"./quantized_model_gemma2-2b/FP16_I.gguf\" \"Q4_K_S\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a360435",
   "metadata": {
    "papermill": {
     "duration": 0.108297,
     "end_time": "2024-09-25T09:29:28.047581",
     "exception": false,
     "start_time": "2024-09-25T09:29:27.939284",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save result model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12ea97a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T09:29:28.265895Z",
     "iopub.status.busy": "2024-09-25T09:29:28.265501Z",
     "iopub.status.idle": "2024-09-25T09:30:37.896462Z",
     "shell.execute_reply": "2024-09-25T09:30:37.895138Z"
    },
    "papermill": {
     "duration": 69.742435,
     "end_time": "2024-09-25T09:30:37.899145",
     "exception": false,
     "start_time": "2024-09-25T09:29:28.156710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\r\n",
      "total 6.5G\r\n",
      "-rw-r--r-- 1 root root 4.9G Sep 25 09:08 FP16.gguf\r\n",
      "-rw-r--r-- 1 root root 1.6G Sep 25 09:29 FP16_I.gguf\r\n",
      "-rw-r--r-- 1 root root 2.3M Sep 25 09:26 imatrix.dat\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls -lh quantized_model_gemma2-2b/\n",
    "!gzip quantized_model_gemma2-2b/FP16_I.gguf"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2814.201675,
   "end_time": "2024-09-25T09:30:38.330566",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-25T08:43:44.128891",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00df0aa7fc424062a4502f752dbd8b2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fec7d43446dc4e64b3f243a7a8e7d3ce",
       "placeholder": "​",
       "style": "IPY_MODEL_9a1a5160052c4aa98727dd08b9f95897",
       "value": " 241M/241M [00:02&lt;00:00, 184MB/s]"
      }
     },
     "045989550fe04b04815d5b454d75ae72": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "08f95ecab96f43a8b967dfcb464179cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0b4f13bf87734ea0a894a08d3713aac6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_28d95d181e4d40b684a60c7c46b7d149",
       "placeholder": "​",
       "style": "IPY_MODEL_224be5cc610946b99c0080ab6bb8f351",
       "value": " 4.24M/4.24M [00:00&lt;00:00, 54.4MB/s]"
      }
     },
     "0c3ae7c0388f427dad243e3e92e4a1a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a345fdf1fdc7453e8cb847cd609efca3",
       "max": 46996.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_93c61673de9748ccbae0d7b779a4a4e2",
       "value": 46996.0
      }
     },
     "0dc089d7471247aebcd91d7e5515afea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0dd79e210c9b44088855ddd152f83470": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_69477e7992b14bd1ab1d3a7be2534828",
       "placeholder": "​",
       "style": "IPY_MODEL_cf1af19a7714451b93167b539708eaf1",
       "value": "tokenizer_config.json: 100%"
      }
     },
     "0f9d310ec7ae4bbba7ee9365a1e89ba2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1085da3219984dd4b5adb9f4a1162148": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "13d5591e27c24361b5030ccf2e5b911d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4ba4b8a12c644f78a906d8e4fbba9f31",
       "max": 187.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3ef8a1ed074140e4a478becb44a1e900",
       "value": 187.0
      }
     },
     "1548faa8c1054c9a9af7bffb75bb44d4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1877866267c74655b389f933ef09e407": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_58a93c1ba84a48e382ad40f46e18b7aa",
        "IPY_MODEL_13d5591e27c24361b5030ccf2e5b911d",
        "IPY_MODEL_38ba2d281e524cac83272e9f75e05450"
       ],
       "layout": "IPY_MODEL_fa544234704143838173aac35d04deff"
      }
     },
     "1ee8d04bcfbb4ede89b63e260679fb5c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1f8b9e47b95b4a48994cc0bd4d9ce1a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1fcef3b75373431cb3dfc5961ca14bd1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f0eb16ebf00c421e8dcba0ff3f4c3b2a",
       "placeholder": "​",
       "style": "IPY_MODEL_db93da9402f343b9b4e60b90eaabd7d0",
       "value": "model-00001-of-00002.safetensors: 100%"
      }
     },
     "224be5cc610946b99c0080ab6bb8f351": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "25c4f6b976104bfba4acac733645ada9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "27fbde09dd0f4e09b6abf9676ce83d20": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cc27bd4094a340198f7fea90fb987832",
       "placeholder": "​",
       "style": "IPY_MODEL_25c4f6b976104bfba4acac733645ada9",
       "value": " 4.99G/4.99G [00:20&lt;00:00, 305MB/s]"
      }
     },
     "28be1307767b4b60a960105c760469a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0dd79e210c9b44088855ddd152f83470",
        "IPY_MODEL_0c3ae7c0388f427dad243e3e92e4a1a3",
        "IPY_MODEL_eae5e5dafa11401bb88443e174a6d806"
       ],
       "layout": "IPY_MODEL_3a7a76499eed4a3f9773c9c184b0ef54"
      }
     },
     "28cd4409d7db463abc94b3fa07f1dfa2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "28d95d181e4d40b684a60c7c46b7d149": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2bf0634d2fde48039d02ce9134ad7c0d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2e17bca988844d88a09714bc49ad103e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e82245db9a6543aeae94ccb08a17480a",
       "placeholder": "​",
       "style": "IPY_MODEL_4c30d9819fc94749bb356337839ce88e",
       "value": " 636/636 [00:00&lt;00:00, 23.3kB/s]"
      }
     },
     "30586d840a5f48d9a47f6850ca3a98cc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "31a22a5761484dc0932acfa8243871a3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "31c2a3807b794e79a52914ac3f970822": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "32f0f4536ddb4cc1a736e6fdebb97615": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "333f9c3a17404fccbbe1752427a502ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "336203aeb2bb49b5ac179490b3e45fea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "33bf158f88ae4c50b864468bd91d098c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_db7bcb01c65f4c8dbc4040f2559d49bb",
       "max": 4988025760.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b7e39d989e904b83b8dd25e20b1d81e1",
       "value": 4988025760.0
      }
     },
     "34faaf58ab5a437dafd27e83fe0f61dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "371cf8f42ec042d0a3da2f425deb3a42": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "38ba2d281e524cac83272e9f75e05450": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fe4fe9ae1c6b43278a5fe95c382077f8",
       "placeholder": "​",
       "style": "IPY_MODEL_eb83ac77b95e481289d1d513c426f1bb",
       "value": " 187/187 [00:00&lt;00:00, 10.2kB/s]"
      }
     },
     "3a46bce3004d4260bf4470928d2a6218": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3f75a6d78fa244248b51a0a6258fe25e",
       "max": 838.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_940e482e201446d2972f57db8e8efb00",
       "value": 838.0
      }
     },
     "3a7a76499eed4a3f9773c9c184b0ef54": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3cf5467e2f3c4afb9c9976cc341c4ed3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b82fc1ea36164813a92fb3c9027be7a9",
        "IPY_MODEL_6c347f14b797404e8258e70500b3b06b",
        "IPY_MODEL_b5b9dd9b6f2b4154a02eb596f491d86f"
       ],
       "layout": "IPY_MODEL_1ee8d04bcfbb4ede89b63e260679fb5c"
      }
     },
     "3d4b1953db5845ce835987ef7a996681": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6fb1c2f4d709442686bc40302e0d5d58",
       "max": 4241003.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ed82df70ccb54aa2bc2daf6e1db0107b",
       "value": 4241003.0
      }
     },
     "3ef8a1ed074140e4a478becb44a1e900": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3f75a6d78fa244248b51a0a6258fe25e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4a0d08341d074f93ba96e48b1db93083": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c92a470618fd4ba386c97a41ad54de48",
        "IPY_MODEL_3d4b1953db5845ce835987ef7a996681",
        "IPY_MODEL_0b4f13bf87734ea0a894a08d3713aac6"
       ],
       "layout": "IPY_MODEL_908a1472665a4d09b57f62b47a505f6b"
      }
     },
     "4ba4b8a12c644f78a906d8e4fbba9f31": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4c30d9819fc94749bb356337839ce88e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5002cc5ff9c74674b595143b4fe18a6b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5039ef64753944d48cc6d2f85ad3bdb5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "52e3a38c23134fb7a41453d8d0d09fbf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_30586d840a5f48d9a47f6850ca3a98cc",
       "max": 11.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0dc089d7471247aebcd91d7e5515afea",
       "value": 11.0
      }
     },
     "5630b2e2594646929395041f38b9c4fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f9b52534cd3a4fd69b415bf0306d895a",
        "IPY_MODEL_842ec11ecc36472583a6179a1bc7beb3",
        "IPY_MODEL_2e17bca988844d88a09714bc49ad103e"
       ],
       "layout": "IPY_MODEL_77bb785b7fcd4545b15749ad7b13d530"
      }
     },
     "57d30bd9ccc04835b91d0a134d52da41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "58a93c1ba84a48e382ad40f46e18b7aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f463b313c633405ea14472a731cd6145",
       "placeholder": "​",
       "style": "IPY_MODEL_31c2a3807b794e79a52914ac3f970822",
       "value": "generation_config.json: 100%"
      }
     },
     "58b92ea75bb84cbf8c0a86a41a9cdcc0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5abeec8d2536450c9de90fd0f59a6bd8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5bb8983863124fbd8d6a9e85724db85e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5abeec8d2536450c9de90fd0f59a6bd8",
       "placeholder": "​",
       "style": "IPY_MODEL_1f8b9e47b95b4a48994cc0bd4d9ce1a4",
       "value": "model-00002-of-00002.safetensors: 100%"
      }
     },
     "5cf470d408174abd9f4b8e78fe255102": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_718c66c600fa47ecb17da2acc33f94e2",
       "placeholder": "​",
       "style": "IPY_MODEL_6e1f18107a1c4b9b984be757e3396d77",
       "value": "model.safetensors.index.json: 100%"
      }
     },
     "5fae161c5acd4d52a1ddc0da4964d96c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "60d0c7339e984aa2868694767b123064": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_da01f86c10ca4aa5a3844d32e8c6f1e9",
       "placeholder": "​",
       "style": "IPY_MODEL_ffb369db78434f7d908824ed9de51c4b",
       "value": " 11/11 [00:20&lt;00:00,  4.84s/it]"
      }
     },
     "618af346c72b4e4991646ddcd09442f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "622c879d16b248f785cb16d1b17fb761": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "63cd759c3315470ba71c9b037cfbe979": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "64b1a41dcc884a568c8ef8ca020bda1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_045989550fe04b04815d5b454d75ae72",
       "max": 1570.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_73b5f5e4a280455587934d2d1349ddac",
       "value": 1570.0
      }
     },
     "69477e7992b14bd1ab1d3a7be2534828": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "695f0ad9194245938c1247e4715a8535": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6c347f14b797404e8258e70500b3b06b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_34faaf58ab5a437dafd27e83fe0f61dd",
       "max": 29091.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_28cd4409d7db463abc94b3fa07f1dfa2",
       "value": 29091.0
      }
     },
     "6e1f18107a1c4b9b984be757e3396d77": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6fb1c2f4d709442686bc40302e0d5d58": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "718c66c600fa47ecb17da2acc33f94e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "73b5f5e4a280455587934d2d1349ddac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "757e8b4ce7584620a3e181e70d5aa211": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7cdccc5b0f1946e88722a0382c087ce2",
       "placeholder": "​",
       "style": "IPY_MODEL_b9c6efa105b34c8199981525b4d99d36",
       "value": ".gitattributes: 100%"
      }
     },
     "77bb785b7fcd4545b15749ad7b13d530": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "78a021dc26c5448ba91e0b1c9f206f24": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "795c8dc9ccdf4730b476dfea07b228b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_757e8b4ce7584620a3e181e70d5aa211",
        "IPY_MODEL_64b1a41dcc884a568c8ef8ca020bda1e",
        "IPY_MODEL_ca8064789f0248f5aeee0ac275100ebf"
       ],
       "layout": "IPY_MODEL_7def739bf8ee4cf5906cb6ae805efa38"
      }
     },
     "7c461cac0a3d4f3c97e15727dd600250": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7cdccc5b0f1946e88722a0382c087ce2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7def739bf8ee4cf5906cb6ae805efa38": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "80905cf81c904fafa4d302cc4445269f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9ee583c718604bcba381c3ef2b59d8f8",
       "placeholder": "​",
       "style": "IPY_MODEL_a2fc0b1af1c1431f8aad1b9f919e5c57",
       "value": " 838/838 [00:00&lt;00:00, 8.61kB/s]"
      }
     },
     "82457a046f9342c8ae9332189dc86bdf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a017eca3e90f4f8c91352ca43f96f006",
        "IPY_MODEL_52e3a38c23134fb7a41453d8d0d09fbf",
        "IPY_MODEL_60d0c7339e984aa2868694767b123064"
       ],
       "layout": "IPY_MODEL_5002cc5ff9c74674b595143b4fe18a6b"
      }
     },
     "842ec11ecc36472583a6179a1bc7beb3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_57d30bd9ccc04835b91d0a134d52da41",
       "max": 636.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_695f0ad9194245938c1247e4715a8535",
       "value": 636.0
      }
     },
     "880f0f7f97d441afba8bb7164f4e1c13": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8ba480f308a0471da140c34cd712864b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8e036d49e7364683918a1bbaa5e95b97": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "908a1472665a4d09b57f62b47a505f6b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9267b86b6ef74429839fe3b7f2d58ec9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "93c61673de9748ccbae0d7b779a4a4e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "940e482e201446d2972f57db8e8efb00": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9a1a5160052c4aa98727dd08b9f95897": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9c7baac67a0e4b35bb4845c86e787705": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bd112220b24d47c3afff367e4974617e",
       "max": 240691728.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_58b92ea75bb84cbf8c0a86a41a9cdcc0",
       "value": 240691728.0
      }
     },
     "9ee583c718604bcba381c3ef2b59d8f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a017eca3e90f4f8c91352ca43f96f006": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5fae161c5acd4d52a1ddc0da4964d96c",
       "placeholder": "​",
       "style": "IPY_MODEL_e657176d6d5a412cbc778f6d72967900",
       "value": "Fetching 11 files: 100%"
      }
     },
     "a2fc0b1af1c1431f8aad1b9f919e5c57": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a345fdf1fdc7453e8cb847cd609efca3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a3cb78855e924fa3a02e0a7649f7707d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a710404e79b84a47b454eab8ddc65ef2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "acfbb03f35644267aede28102acc093b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9267b86b6ef74429839fe3b7f2d58ec9",
       "placeholder": "​",
       "style": "IPY_MODEL_336203aeb2bb49b5ac179490b3e45fea",
       "value": "tokenizer.json: 100%"
      }
     },
     "ad40f1b3cfda4b82b37786125159602f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "afd3a2c5d2ce483ca9f0fed1dfe6482a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a3cb78855e924fa3a02e0a7649f7707d",
       "max": 17525357.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_cb85610e536945218d38c1c89e3a7d38",
       "value": 17525357.0
      }
     },
     "b5635d8fe36c4962a64664f0ae5df17c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1fcef3b75373431cb3dfc5961ca14bd1",
        "IPY_MODEL_33bf158f88ae4c50b864468bd91d098c",
        "IPY_MODEL_27fbde09dd0f4e09b6abf9676ce83d20"
       ],
       "layout": "IPY_MODEL_bca5981a5c284d3e9a46caecfc4081e7"
      }
     },
     "b5b9dd9b6f2b4154a02eb596f491d86f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0f9d310ec7ae4bbba7ee9365a1e89ba2",
       "placeholder": "​",
       "style": "IPY_MODEL_78a021dc26c5448ba91e0b1c9f206f24",
       "value": " 29.1k/29.1k [00:00&lt;00:00, 324kB/s]"
      }
     },
     "b7e39d989e904b83b8dd25e20b1d81e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b82fc1ea36164813a92fb3c9027be7a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f038d94910e94743967e69dc0df9f762",
       "placeholder": "​",
       "style": "IPY_MODEL_08f95ecab96f43a8b967dfcb464179cb",
       "value": "README.md: 100%"
      }
     },
     "b9c6efa105b34c8199981525b4d99d36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ba1f9835855a45fd9a52acc73e9050dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bca5981a5c284d3e9a46caecfc4081e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bd112220b24d47c3afff367e4974617e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c78ec818538f4436a448f52b3a7df197": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_acfbb03f35644267aede28102acc093b",
        "IPY_MODEL_afd3a2c5d2ce483ca9f0fed1dfe6482a",
        "IPY_MODEL_f3bbb533a217482c93df1dd7b55a29e2"
       ],
       "layout": "IPY_MODEL_622c879d16b248f785cb16d1b17fb761"
      }
     },
     "c92a470618fd4ba386c97a41ad54de48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5039ef64753944d48cc6d2f85ad3bdb5",
       "placeholder": "​",
       "style": "IPY_MODEL_333f9c3a17404fccbbe1752427a502ec",
       "value": "tokenizer.model: 100%"
      }
     },
     "ca8064789f0248f5aeee0ac275100ebf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_880f0f7f97d441afba8bb7164f4e1c13",
       "placeholder": "​",
       "style": "IPY_MODEL_ad40f1b3cfda4b82b37786125159602f",
       "value": " 1.57k/1.57k [00:00&lt;00:00, 74.4kB/s]"
      }
     },
     "cb85610e536945218d38c1c89e3a7d38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "cc27bd4094a340198f7fea90fb987832": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cdb83d027b7749be976f6d12c78d1c4a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8e036d49e7364683918a1bbaa5e95b97",
       "max": 24223.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_618af346c72b4e4991646ddcd09442f8",
       "value": 24223.0
      }
     },
     "cf1af19a7714451b93167b539708eaf1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d486ace19ab849e3b19115c8cf2f75bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d51a290846b045638e1058ca93de6a5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_de2b3873637f4fc0845829312b8711d8",
       "placeholder": "​",
       "style": "IPY_MODEL_8ba480f308a0471da140c34cd712864b",
       "value": " 24.2k/24.2k [00:00&lt;00:00, 1.53MB/s]"
      }
     },
     "da01f86c10ca4aa5a3844d32e8c6f1e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "db7bcb01c65f4c8dbc4040f2559d49bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "db93da9402f343b9b4e60b90eaabd7d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "de2b3873637f4fc0845829312b8711d8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dfcc244222c449f7942c9043c8afb36d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_31a22a5761484dc0932acfa8243871a3",
       "placeholder": "​",
       "style": "IPY_MODEL_ba1f9835855a45fd9a52acc73e9050dd",
       "value": "config.json: 100%"
      }
     },
     "e657176d6d5a412cbc778f6d72967900": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e7543143f55f4f7682d9c7e062a43b21": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_dfcc244222c449f7942c9043c8afb36d",
        "IPY_MODEL_3a46bce3004d4260bf4470928d2a6218",
        "IPY_MODEL_80905cf81c904fafa4d302cc4445269f"
       ],
       "layout": "IPY_MODEL_63cd759c3315470ba71c9b037cfbe979"
      }
     },
     "e82245db9a6543aeae94ccb08a17480a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eae5e5dafa11401bb88443e174a6d806": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1548faa8c1054c9a9af7bffb75bb44d4",
       "placeholder": "​",
       "style": "IPY_MODEL_1085da3219984dd4b5adb9f4a1162148",
       "value": " 47.0k/47.0k [00:00&lt;00:00, 2.71MB/s]"
      }
     },
     "eb83ac77b95e481289d1d513c426f1bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ed82df70ccb54aa2bc2daf6e1db0107b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f038d94910e94743967e69dc0df9f762": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f0760031692e4f69a21c1cdaff3ee552": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5bb8983863124fbd8d6a9e85724db85e",
        "IPY_MODEL_9c7baac67a0e4b35bb4845c86e787705",
        "IPY_MODEL_00df0aa7fc424062a4502f752dbd8b2b"
       ],
       "layout": "IPY_MODEL_32f0f4536ddb4cc1a736e6fdebb97615"
      }
     },
     "f0eb16ebf00c421e8dcba0ff3f4c3b2a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f3bbb533a217482c93df1dd7b55a29e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7c461cac0a3d4f3c97e15727dd600250",
       "placeholder": "​",
       "style": "IPY_MODEL_a710404e79b84a47b454eab8ddc65ef2",
       "value": " 17.5M/17.5M [00:01&lt;00:00, 12.1MB/s]"
      }
     },
     "f463b313c633405ea14472a731cd6145": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f9b52534cd3a4fd69b415bf0306d895a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2bf0634d2fde48039d02ce9134ad7c0d",
       "placeholder": "​",
       "style": "IPY_MODEL_d486ace19ab849e3b19115c8cf2f75bb",
       "value": "special_tokens_map.json: 100%"
      }
     },
     "fa544234704143838173aac35d04deff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fe4fe9ae1c6b43278a5fe95c382077f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fec7d43446dc4e64b3f243a7a8e7d3ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ff8c588094764bafb18fdfe7d7b27d31": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5cf470d408174abd9f4b8e78fe255102",
        "IPY_MODEL_cdb83d027b7749be976f6d12c78d1c4a",
        "IPY_MODEL_d51a290846b045638e1058ca93de6a5d"
       ],
       "layout": "IPY_MODEL_371cf8f42ec042d0a3da2f425deb3a42"
      }
     },
     "ffb369db78434f7d908824ed9de51c4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
