{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview\n\nNo sure why AWQ cannot work in this time in this notebook.","metadata":{}},{"cell_type":"code","source":"!nvcc --version","metadata":{"execution":{"iopub.status.busy":"2024-02-16T05:53:48.574058Z","iopub.execute_input":"2024-02-16T05:53:48.574410Z","iopub.status.idle":"2024-02-16T05:53:49.567944Z","shell.execute_reply.started":"2024-02-16T05:53:48.574380Z","shell.execute_reply":"2024-02-16T05:53:49.566708Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2023 NVIDIA Corporation\nBuilt on Mon_Apr__3_17:16:06_PDT_2023\nCuda compilation tools, release 12.1, V12.1.105\nBuild cuda_12.1.r12.1/compiler.32688072_0\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture --no-stder\n# There are several libraries for quantizing models with the AWQ algorithm\n# like llm-awq, here we use autoawq\n!pip install triton==2.2.0\n!pip install autoawq==0.2.0","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-16T05:53:49.571511Z","iopub.execute_input":"2024-02-16T05:53:49.571961Z","iopub.status.idle":"2024-02-16T05:54:21.370030Z","shell.execute_reply.started":"2024-02-16T05:53:49.571915Z","shell.execute_reply":"2024-02-16T05:54:21.368928Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting triton==2.2.0\n  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton==2.2.0) (3.13.1)\nDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton\nSuccessfully installed triton-2.2.0\nCollecting autoawq==0.2.0\n  Downloading autoawq-0.2.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (14 kB)\nRequirement already satisfied: torch>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from autoawq==0.2.0) (2.1.2)\nRequirement already satisfied: transformers>=4.35.0 in /opt/conda/lib/python3.10/site-packages (from autoawq==0.2.0) (4.37.0)\nRequirement already satisfied: tokenizers>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from autoawq==0.2.0) (0.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from autoawq==0.2.0) (4.9.0)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from autoawq==0.2.0) (0.26.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from autoawq==0.2.0) (2.1.0)\nRequirement already satisfied: zstandard in /opt/conda/lib/python3.10/site-packages (from autoawq==0.2.0) (0.22.0)\nCollecting autoawq-kernels (from autoawq==0.2.0)\n  Downloading autoawq_kernels-0.0.4-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.0 kB)\nRequirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers>=0.12.1->autoawq==0.2.0) (0.20.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.2.0) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.2.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.2.0) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.2.0) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->autoawq==0.2.0) (2023.12.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.2.0) (1.24.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.2.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.2.0) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.2.0) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.2.0) (2.31.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.2.0) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.2.0) (4.66.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->autoawq==0.2.0) (5.9.3)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->autoawq==0.2.0) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets->autoawq==0.2.0) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->autoawq==0.2.0) (2.1.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->autoawq==0.2.0) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->autoawq==0.2.0) (0.70.15)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->autoawq==0.2.0) (3.9.1)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->autoawq==0.2.0) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->autoawq==0.2.0) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->autoawq==0.2.0) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->autoawq==0.2.0) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->autoawq==0.2.0) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->autoawq==0.2.0) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->autoawq==0.2.0) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.35.0->autoawq==0.2.0) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.35.0->autoawq==0.2.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.35.0->autoawq==0.2.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.35.0->autoawq==0.2.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.35.0->autoawq==0.2.0) (2023.11.17)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.0.1->autoawq==0.2.0) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->autoawq==0.2.0) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->autoawq==0.2.0) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->autoawq==0.2.0) (2023.4)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.0.1->autoawq==0.2.0) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->autoawq==0.2.0) (1.16.0)\nDownloading autoawq-0.2.0-cp310-cp310-manylinux2014_x86_64.whl (79 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.0/79.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autoawq_kernels-0.0.4-cp310-cp310-manylinux2014_x86_64.whl (29.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: autoawq-kernels, autoawq\nSuccessfully installed autoawq-0.2.0 autoawq-kernels-0.0.4\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\n\nlogin(token=user_secrets.get_secret(\"HUGGINGFACE_TOKEN\"))","metadata":{"execution":{"iopub.status.busy":"2024-02-16T05:54:21.371703Z","iopub.execute_input":"2024-02-16T05:54:21.372464Z","iopub.status.idle":"2024-02-16T05:54:22.310325Z","shell.execute_reply.started":"2024-02-16T05:54:21.372423Z","shell.execute_reply":"2024-02-16T05:54:22.309453Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"markdown","source":"It is a quantization method similar to GPTQ. There are several differences between AWQ and GPTQ as methods but the most important one is that AWQ assumes that not all weights are equally important for an LLM's performance. In other words, there is a small fraction of weights that will be skipped during quantization which helps with the quantization loss.\n\nLoading an AWQ-quantized model automatically sets other weights to fp16 by default for performance reasons. If you want to load these other weights in a different format, use the `torch_dtype` parameter","metadata":{}},{"cell_type":"code","source":"from awq import AutoAWQForCausalLM\nfrom transformers import AutoTokenizer\n\nmodel_path = \"facebook/opt-125m\"\nquant_path = \"opt-125m-awq\"\nquant_config = {\"zero_point\": True, \"q_group_size\": 128, \"w_bit\": 4, \"version\":\"GEMM\"}\n\n# Load model\nmodel = AutoAWQForCausalLM.from_pretrained(model_path, safetensors=True, device_map='auto', trust_remote_code=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T05:54:22.312985Z","iopub.execute_input":"2024-02-16T05:54:22.313907Z","iopub.status.idle":"2024-02-16T05:54:42.616483Z","shell.execute_reply.started":"2024-02-16T05:54:22.313877Z","shell.execute_reply":"2024-02-16T05:54:42.614592Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-02-16 05:54:29.328236: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-16 05:54:29.328339: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-16 05:54:29.451853: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/651 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13272cd827e2406fb46fe0f757d3cc46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78549bf91723470fb3e00404e80f2e76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abf7dbb121344aefb6c4a2a36280150c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"LICENSE.md:   0%|          | 0.00/11.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0b3e34b4d2e42a1aed50420307ef71c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/7.10k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe277ca6068f49368bbb46687303e047"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a8ee578b4c74e3ca00b6398f7a20034"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75d360645b51415f93a7b0d3bba45023"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40e77e20a784413287bad164f8684083"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c022ae1b8ff4d5ca734bcc0fba97109"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/1.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eeac81212d9e43069cf5d4caf58d0b2c"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m quant_config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero_point\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq_group_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m128\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw_bit\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGEMM\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoAWQForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/awq/models/auto.py:59\u001b[0m, in \u001b[0;36mAutoAWQForCausalLM.from_pretrained\u001b[0;34m(self, model_path, trust_remote_code, safetensors, device_map, **model_init_kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_init_kwargs,\n\u001b[1;32m     54\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseAWQForCausalLM:\n\u001b[1;32m     55\u001b[0m     model_type \u001b[38;5;241m=\u001b[39m check_and_get_model_type(\n\u001b[1;32m     56\u001b[0m         model_path, trust_remote_code, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_init_kwargs\n\u001b[1;32m     57\u001b[0m     )\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAWQ_CAUSAL_LM_MODEL_MAP\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_init_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/awq/models/base.py:308\u001b[0m, in \u001b[0;36mBaseAWQForCausalLM.from_pretrained\u001b[0;34m(self, model_path, model_type, torch_dtype, trust_remote_code, safetensors, device_map, **model_init_kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m     processor: CLIPImageProcessor \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mimage_processor\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# If not quantized, must load with AutoModelForCausalLM\u001b[39;00m\n\u001b[0;32m--> 308\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_weights_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_init_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(\n\u001b[1;32m    320\u001b[0m     model,\n\u001b[1;32m    321\u001b[0m     model_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    325\u001b[0m     processor\u001b[38;5;241m=\u001b[39mprocessor,\n\u001b[1;32m    326\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:3335\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3329\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   3330\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError no file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found in directory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3331\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but there is a file for Flax weights. Use `from_flax=True`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3332\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to load this model from those weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3333\u001b[0m     )\n\u001b[1;32m   3334\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m use_safetensors:\n\u001b[0;32m-> 3335\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   3336\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError no file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(SAFE_WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found in directory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3337\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3338\u001b[0m     )\n\u001b[1;32m   3339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   3341\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError no file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF2_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3342\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF_WEIGHTS_NAME\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFLAX_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found in directory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3343\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3344\u001b[0m     )\n","\u001b[0;31mOSError\u001b[0m: Error no file named model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--opt-125m/snapshots/27dcfa74d334bc871f3234de431e71c6eeba5dd6."],"ename":"OSError","evalue":"Error no file named model.safetensors found in directory /root/.cache/huggingface/hub/models--facebook--opt-125m/snapshots/27dcfa74d334bc871f3234de431e71c6eeba5dd6.","output_type":"error"}]},{"cell_type":"code","source":"!rm -rf /root/.cache huggingface","metadata":{"execution":{"iopub.status.busy":"2024-02-16T05:54:42.617536Z","iopub.status.idle":"2024-02-16T05:54:42.617913Z","shell.execute_reply.started":"2024-02-16T05:54:42.617739Z","shell.execute_reply":"2024-02-16T05:54:42.617754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\ntokenizer","metadata":{"execution":{"iopub.status.busy":"2024-02-16T05:54:42.619157Z","iopub.status.idle":"2024-02-16T05:54:42.619519Z","shell.execute_reply.started":"2024-02-16T05:54:42.619357Z","shell.execute_reply":"2024-02-16T05:54:42.619371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Quantize\nmodel.quantize(tokenizer, quant_config=quant_config)\nmodel","metadata":{"execution":{"iopub.status.busy":"2024-02-16T05:54:42.620754Z","iopub.status.idle":"2024-02-16T05:54:42.621094Z","shell.execute_reply.started":"2024-02-16T05:54:42.620929Z","shell.execute_reply":"2024-02-16T05:54:42.620943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"quant_config","metadata":{"execution":{"iopub.status.busy":"2024-02-16T05:54:42.622785Z","iopub.status.idle":"2024-02-16T05:54:42.623160Z","shell.execute_reply.started":"2024-02-16T05:54:42.622990Z","shell.execute_reply":"2024-02-16T05:54:42.623005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AwqConfig, AutoConfig\n\n# modify the config file so that it is compatible with transformers integration\nquantization_config = AwqConfig(\n    bits=quant_config[\"w_bit\"],\n    group_size=quant_config[\"q_group_size\"],\n    zero_point=quant_config[\"zero_point\"],\n    version=quant_config[\"version\"].lower(),\n).to_dict()\n\n# the pretrained transformers model is stored in the model attribute + we need to pass a dict\nmodel.model.config.quantization_config = quantization_config\n# a second solution would be to use Autoconfig and push to hub (what we do at llm-awq)\n\n\n# save model weights\nmodel.save_quantized(quant_path)\ntokenizer.save_pretrained(quant_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T05:54:42.624572Z","iopub.status.idle":"2024-02-16T05:54:42.624913Z","shell.execute_reply.started":"2024-02-16T05:54:42.624743Z","shell.execute_reply":"2024-02-16T05:54:42.624757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import HfApi\n\nos.environ[\"AWQ_MODEL\"]=\"aisuko/opt-125m-awq\"\n\napi = HfApi()\napi.create_repo(repo_id=os.getenv('AWQ_MODEL'),exist_ok=True,repo_type=\"model\")\n\napi.upload_folder(\n    folder_path=\"opt-125m-awq\",\n    repo_id=os.getenv('AWQ_MODEL'),\n    repo_type=\"model\",\n)\ntokenizer.push_to_hub(\"aisuko/opt-125m-awq\")","metadata":{"execution":{"iopub.status.busy":"2024-02-16T05:54:42.626492Z","iopub.status.idle":"2024-02-16T05:54:42.626827Z","shell.execute_reply.started":"2024-02-16T05:54:42.626664Z","shell.execute_reply":"2024-02-16T05:54:42.626677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\n\n# Use the device_map parameter to specify where to place the model\nmodel=AutoModelForCausalLM.from_pretrained(\n    os.getenv(\"AWQ_MODEL\"),\n#     attn_implementation=\"flash_attention_2\",\n    device_map=\"auto\",\n)\n\nmodel.get_memory_footprint()","metadata":{"execution":{"iopub.status.busy":"2024-02-16T05:54:42.628700Z","iopub.status.idle":"2024-02-16T05:54:42.629042Z","shell.execute_reply.started":"2024-02-16T05:54:42.628875Z","shell.execute_reply":"2024-02-16T05:54:42.628889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.config.quantization_config","metadata":{"execution":{"iopub.status.busy":"2024-02-16T05:54:42.630308Z","iopub.status.idle":"2024-02-16T05:54:42.630651Z","shell.execute_reply.started":"2024-02-16T05:54:42.630491Z","shell.execute_reply":"2024-02-16T05:54:42.630505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(os.getenv('AWQ_MODEL'))\nmodel = AutoModelForCausalLM.from_pretrained(os.getenv('AWQ_MODEL')).to(0)\n\ntext = \"Hello my name is\"\ninputs = tokenizer(text, return_tensors=\"pt\").to(0)\n\nout = model.generate(**inputs, max_new_tokens=5)\nprint(tokenizer.decode(out[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2024-02-16T05:54:42.632368Z","iopub.status.idle":"2024-02-16T05:54:42.632878Z","shell.execute_reply.started":"2024-02-16T05:54:42.632617Z","shell.execute_reply":"2024-02-16T05:54:42.632638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Credit\n\n* https://colab.research.google.com/drive/1HzZH89yAXJaZgwJDhQj9LqSBux932BvY#scrollTo=RWIh6iUR_i5P","metadata":{}}]}