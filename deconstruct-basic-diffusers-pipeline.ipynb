{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Overview\nIn the example above, the pipline contains a [UNe2DModel](https://huggingface.co/docs/diffusers/v0.17.1/en/api/models#diffusers.UNet2DModel) model and a [DDPMScheduler](https://huggingface.co/docs/diffusers/v0.17.1/en/api/schedulers/ddpm#diffusers.DDPMScheduler). The pipline [denoises an image](https://app.gitbook.com/o/V2I20JSLdpI7S91XG35d/s/qm1WfU7McQ1hgBrDXi90/ai-techniques/stable-diffusion/denoising-strength) by taking random noise the size of the derired output and passing it through the model several times. Ar each timestep, the mkodel predicts the noise residual and the scheduler uses it to [predict](https://app.gitbook.com/o/V2I20JSLdpI7S91XG35d/s/qm1WfU7McQ1hgBrDXi90/ai-techniques/stable-diffusion/diffusion-in-image#noise-predictor) a less noisy image. The pipline repaetas this process until it reaches the end of the specified number of inference steps.","metadata":{}},{"cell_type":"markdown","source":"## Installing the requirements","metadata":{}},{"cell_type":"code","source":"!pip install diffusers[\"torch\",\"flax\"] transformers --upgrade","metadata":{"execution":{"iopub.status.busy":"2023-06-28T10:21:14.539868Z","iopub.execute_input":"2023-06-28T10:21:14.540202Z","iopub.status.idle":"2023-06-28T10:21:36.454831Z","shell.execute_reply.started":"2023-06-28T10:21:14.540173Z","shell.execute_reply":"2023-06-28T10:21:36.453736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The entire denoising process","metadata":{}},{"cell_type":"code","source":"# check the paltform, Apple Silicon or Linux\nimport os, platform\n\ntorch_device=\"cpu\"\n\nif 'kaggle' in os.environ.get('KAGGLE_URL_BASE','localhost'):\n    torch_device = 'cuda'\nelse:\n    torch_device = 'mps' if platform.system() == 'Darwin' else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2023-06-28T10:21:45.320609Z","iopub.execute_input":"2023-06-28T10:21:45.320985Z","iopub.status.idle":"2023-06-28T10:21:45.327349Z","shell.execute_reply.started":"2023-06-28T10:21:45.320949Z","shell.execute_reply":"2023-06-28T10:21:45.326395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch_device","metadata":{"execution":{"iopub.status.busy":"2023-06-28T10:21:48.320945Z","iopub.execute_input":"2023-06-28T10:21:48.321294Z","iopub.status.idle":"2023-06-28T10:21:48.327388Z","shell.execute_reply.started":"2023-06-28T10:21:48.321267Z","shell.execute_reply":"2023-06-28T10:21:48.326544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.Load the model and scheduler","metadata":{}},{"cell_type":"code","source":"from diffusers import DDPMScheduler, UNet2DModel\n# load the model and scheduler\nscheduler = DDPMScheduler.from_pretrained('google/ddpm-cat-256')\nmodel = UNet2DModel.from_pretrained('google/ddpm-cat-256').to(torch_device)","metadata":{"execution":{"iopub.status.busy":"2023-06-28T10:21:50.976234Z","iopub.execute_input":"2023-06-28T10:21:50.976688Z","iopub.status.idle":"2023-06-28T10:22:11.228141Z","shell.execute_reply.started":"2023-06-28T10:21:50.976651Z","shell.execute_reply":"2023-06-28T10:22:11.227193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Setting the scheduler timtsteps creates a tensor with evenly spaced elements in it. 25 in this case. Each element corresponds to a timestep in at which the model denoises an image. When you create the denoising loop later, you will iterate over this tensor to denoise an image:","metadata":{}},{"cell_type":"code","source":"# Set the number of timesteps to run the denoising process\nscheduler.set_timesteps(25)\nscheduler.timesteps","metadata":{"execution":{"iopub.status.busy":"2023-06-28T10:22:45.985599Z","iopub.execute_input":"2023-06-28T10:22:45.986584Z","iopub.status.idle":"2023-06-28T10:22:45.999420Z","shell.execute_reply.started":"2023-06-28T10:22:45.986540Z","shell.execute_reply":"2023-06-28T10:22:45.998281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.Create some random noise with the same shape as the desited output","metadata":{}},{"cell_type":"code","source":"import torch\nsample_size =model.config.sample_size\n# If here use Apple Silicon, please use to(\"mps\")\nnoise = torch.randn((1, 3, sample_size, sample_size)).to(torch_device)","metadata":{"execution":{"iopub.status.busy":"2023-06-28T10:22:48.694566Z","iopub.execute_input":"2023-06-28T10:22:48.695283Z","iopub.status.idle":"2023-06-28T10:22:48.710124Z","shell.execute_reply.started":"2023-06-28T10:22:48.695240Z","shell.execute_reply":"2023-06-28T10:22:48.708833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.A loop to iterate over the timesteps\n\nAt each timestep, the model does a UNet2DModel.forward() pass and returns the noisy residual. The scheduler's step() method takes the noisy residual, timestep, and input and it predicts the image at the previous timestep. This output becomes the next input to the model in the denoising loop, and it'll repeat until it reaches the end of the timesteps array.","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\ninput = noise\nfor t in tqdm(scheduler.timesteps):\n    with torch.no_grad():\n        noisy_residual=model(input, t).sample\n    previous_noisy_sample = scheduler.step(noisy_residual, t, input).prev_sample\n    input = previous_noisy_sample","metadata":{"execution":{"iopub.status.busy":"2023-06-28T10:22:54.376600Z","iopub.execute_input":"2023-06-28T10:22:54.377148Z","iopub.status.idle":"2023-06-28T10:23:00.632970Z","shell.execute_reply.started":"2023-06-28T10:22:54.377098Z","shell.execute_reply":"2023-06-28T10:23:00.631495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.Convert the denoised output into an image","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\n\nimage = (input /2 + 0.5).clamp(0, 1)\nimage=image.cpu().permute(0, 2, 3, 1).numpy()[0]\nimage = Image.fromarray((image * 255).round().astype(np.uint8))\nimage","metadata":{"execution":{"iopub.status.busy":"2023-06-28T10:23:02.671210Z","iopub.execute_input":"2023-06-28T10:23:02.671572Z","iopub.status.idle":"2023-06-28T10:23:02.730202Z","shell.execute_reply.started":"2023-06-28T10:23:02.671544Z","shell.execute_reply":"2023-06-28T10:23:02.729271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Conclusion\nIn summary, we `initialize the necessary component`s, and `set` the `number of timesteps` to `create a timestep array`. The `timestep array` is used in the `denoising loop`, and for `each element in this array`, the model `predicts a less noisy image`. The `denoising loop` iterates over the timestep's, and at each timestep, it outputs `a noist residual` and `the scheduler` uses it to `predict a less noisy image` at the `previous timestep`. The process is `repated` until you `reach the end of the timestep array`.","metadata":{}}]}